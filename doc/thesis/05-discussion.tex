\chapter{Discussion}\label{\positionnumber}

\section{Limitations}
voxel- patch - volume pro-con\\
Statistical power \\
model size/speed \\
learned vs. closed-form/deduced/analytical transformation \\
igh frequency features and gan loss (show diff maps) \\
Augmentation \\
error propagation of denorm to scalars \\
masks \& probsegs imperfect, currently regenerated w freesurfer by svenja k \\
registration for bssfp for many subject difficult \\

\section{Future Work}
\subsection{Modular Deep Learning}
Pretrain .\\
LDM for latent translation\\
GAN \& Stable diffusion, control flow matching, latent diffusion models\\
phase cycle und miller \\
predict t2ws to establish better comparability wrt. scalars \\
multi res, multi input, multi output/foundation model \\

\subsection{Conv Transf.}
New kid on the block\\

\subsection{Neural Arch Search}
DiNTS

\chapter{Acknowledgements}
Rahel, Flo, Qi, Klaus
