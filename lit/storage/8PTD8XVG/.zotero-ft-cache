
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2202.08937

Help | Advanced Search
Search
Computer Science > Machine Learning
(cs)
[Submitted on 17 Feb 2022 ( v1 ), last revised 10 Mar 2022 (this version, v2)]
Title: When, Why, and Which Pretrained GANs Are Useful?
Authors: Timofey Grigoryev , Andrey Voynov , Artem Babenko
View a PDF of the paper titled When, Why, and Which Pretrained GANs Are Useful?, by Timofey Grigoryev and 2 other authors
View PDF

    Abstract: The literature has proposed several methods to finetune pretrained GANs on new datasets, which typically results in higher performance compared to training from scratch, especially in the limited-data regime. However, despite the apparent empirical benefits of GAN pretraining, its inner mechanisms were not analyzed in-depth, and understanding of its role is not entirely clear. Moreover, the essential practical details, e.g., selecting a proper pretrained GAN checkpoint, currently do not have rigorous grounding and are typically determined by trial and error.
    This work aims to dissect the process of GAN finetuning. First, we show that initializing the GAN training process by a pretrained checkpoint primarily affects the model's coverage rather than the fidelity of individual samples. Second, we explicitly describe how pretrained generators and discriminators contribute to the finetuning process and explain the previous evidence on the importance of pretraining both of them. Finally, as an immediate practical benefit of our analysis, we describe a simple recipe to choose an appropriate GAN checkpoint that is the most suitable for finetuning to a particular target task. Importantly, for most of the target tasks, Imagenet-pretrained GAN, despite having poor visual quality, appears to be an excellent starting point for finetuning, resembling the typical pretraining scenario of discriminative computer vision models. 

Subjects: 	Machine Learning (cs.LG) ; Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2202.08937 [cs.LG]
  	(or arXiv:2202.08937v2 [cs.LG] for this version)
  	https://doi.org/10.48550/arXiv.2202.08937
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Andrey Voynov [ view email ]
[v1] Thu, 17 Feb 2022 23:38:01 UTC (9,151 KB)
[v2] Thu, 10 Mar 2022 12:55:30 UTC (9,151 KB)
Full-text links:
Access Paper:

    View a PDF of the paper titled When, Why, and Which Pretrained GANs Are Useful?, by Timofey Grigoryev and 2 other authors
    View PDF
    TeX Source
    Other Formats 

view license
Current browse context:
cs.LG
< prev   |   next >
new | recent | 2202
Change to browse by:
cs
cs.CV
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

