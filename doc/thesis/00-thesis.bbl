% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nty/global//global/global}
    \entry{noauthor_augmentation_nodate}{misc}{}
      \list{language}{1}{%
        {en}%
      }
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labeltitlesource}{title}
      \field{abstract}{Augmentation transforms generate different results every time they are called. Augmented image Base class: RandomTransform: Composition: Compose: OneOf: Spatial: RandomFlip: RandomAffine: RandomEla...}
      \field{journaltitle}{TorchIO}
      \field{title}{Augmentation}
      \field{urlday}{12}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb https://torchio.readthedocs.io/transforms/transforms/augmentation.html
      \endverb
      \verb{url}
      \verb https://torchio.readthedocs.io/transforms/transforms/augmentation.html
      \endverb
    \endentry
    \entry{ba_layer_2016}{misc}{}
      \name{author}{3}{}{%
        {{hash=750bb29ebaf655e36626e464041edb6d}{%
           family={Ba},
           familyi={B\bibinitperiod},
           given={Jimmy\bibnamedelima Lei},
           giveni={J\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=9ce51427604561924b91aa544c9c1b2a}{%
           family={Kiros},
           familyi={K\bibinitperiod},
           given={Jamie\bibnamedelima Ryan},
           giveni={J\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=813bd95fe553e6079cd53a567b238287}{%
           family={Hinton},
           familyi={H\bibinitperiod},
           given={Geoffrey\bibnamedelima E.},
           giveni={G\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{059348b2d0b3fe9a67209502c14057d1}
      \strng{fullhash}{059348b2d0b3fe9a67209502c14057d1}
      \strng{bibnamehash}{059348b2d0b3fe9a67209502c14057d1}
      \strng{authorbibnamehash}{059348b2d0b3fe9a67209502c14057d1}
      \strng{authornamehash}{059348b2d0b3fe9a67209502c14057d1}
      \strng{authorfullhash}{059348b2d0b3fe9a67209502c14057d1}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.}
      \field{month}{7}
      \field{note}{arXiv:1607.06450 [cs, stat]}
      \field{title}{Layer {Normalization}}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1607.06450
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/CL6YSWPY/Ba et al. - 2016 - Layer Normalization.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/436S2AVW/1607.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1607.06450
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1607.06450
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{bernstein_handbook_2004}{book}{}
      \name{author}{3}{}{%
        {{hash=4ee01bb1cd3c065a0509f3e46d6d62c0}{%
           family={Bernstein},
           familyi={B\bibinitperiod},
           given={Matt\bibnamedelima A.},
           giveni={M\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=936fc94dc9826c5633f94421bc8c2014}{%
           family={King},
           familyi={K\bibinitperiod},
           given={Kevin\bibnamedelima F.},
           giveni={K\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
        {{hash=8d030d9400c1a834cfb297d75c3499e9}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Xiaohong\bibnamedelima Joe},
           giveni={X\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {Elsevier}%
      }
      \strng{namehash}{cb9063c2b68295fd7c32c79c6da17548}
      \strng{fullhash}{cb9063c2b68295fd7c32c79c6da17548}
      \strng{bibnamehash}{cb9063c2b68295fd7c32c79c6da17548}
      \strng{authorbibnamehash}{cb9063c2b68295fd7c32c79c6da17548}
      \strng{authornamehash}{cb9063c2b68295fd7c32c79c6da17548}
      \strng{authorfullhash}{cb9063c2b68295fd7c32c79c6da17548}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Magnetic Resonance Imaging (MRI) is among the most important medical imaging techniques available today. There is an installed base of approximately 15,000 MRI scanners worldwide. Each of these scanners is capable of running many different "pulse sequences", which are governed by physics and engineering principles, and implemented by software programs that control the MRI hardware. To utilize an MRI scanner to the fullest extent, a conceptual understanding of its pulse sequences is crucial. Handbook of MRI Pulse Sequences offers a complete guide that can help the scientists, engineers, clinicians, and technologists in the field of MRI understand and better employ their scanner. Explains pulse sequences, their components, and the associated image reconstruction methods commonly used in MRI Provides self-contained sections for individual techniques Can be used as a quick reference guide or as a resource for deeper study Includes both non-mathematical and mathematical descriptions Contains numerous figures, tables, references, and worked example problems}
      \field{isbn}{978-0-08-053312-4}
      \field{month}{9}
      \field{note}{Google-Books-ID: d6PLHcyejEIC}
      \field{title}{Handbook of {MRI} {Pulse} {Sequences}}
      \field{year}{2004}
      \verb{file}
      \verb Bernstein et al. - 2004 - Handbook of MRI Pulse Sequences.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/4ZU5262P/Bernstein et al. - 2004 - Handbook of MRI Pulse Sequences.pdf:application/pdf
      \endverb
      \keyw{Computers / Data Science / Bioinformatics,Mathematics / Applied,Medical / Diagnostic Imaging / General}
    \endentry
    \entry{bieri_fundamentals_2013}{article}{}
      \name{author}{2}{}{%
        {{hash=bb41146c4a8c0507581de495e5654324}{%
           family={Bieri},
           familyi={B\bibinitperiod},
           given={Oliver},
           giveni={O\bibinitperiod}}}%
        {{hash=d32aa293ed7ed32a40025c81e59197f9}{%
           family={Scheffler},
           familyi={S\bibinitperiod},
           given={Klaus},
           giveni={K\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{8bcee23086810902331aa775f5bad71f}
      \strng{fullhash}{8bcee23086810902331aa775f5bad71f}
      \strng{bibnamehash}{8bcee23086810902331aa775f5bad71f}
      \strng{authorbibnamehash}{8bcee23086810902331aa775f5bad71f}
      \strng{authornamehash}{8bcee23086810902331aa775f5bad71f}
      \strng{authorfullhash}{8bcee23086810902331aa775f5bad71f}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Balanced steady state free precession (balanced SSFP) has become increasingly popular for research and clinical applications, offering a very high signal-to-noise ratio and a T2/T1-weighted image contrast. This review article gives an overview on the basic principles of this fast imaging technique as well as possibilities for contrast modification. The first part focuses on the fundamental principles of balanced SSFP signal formation in the transient phase and in the steady state. In the second part, balanced SSFP imaging, contrast, and basic mechanisms for contrast modification are revisited and contemporary clinical applications are discussed. J. Magn. Reson. Imaging 2013;38:2–11. © 2013 Wiley Periodicals, Inc.}
      \field{issn}{1522-2586}
      \field{journaltitle}{Journal of Magnetic Resonance Imaging}
      \field{number}{1}
      \field{title}{Fundamentals of balanced steady state free precession {MRI}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{38}
      \field{year}{2013}
      \field{urldateera}{ce}
      \true{nocite}
      \field{pages}{2\bibrangedash 11}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1002/jmri.24163
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/WAEJGVVN/Bieri and Scheffler - 2013 - Fundamentals of balanced steady state free precess.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/N8MS4SB5/jmri.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.24163
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.24163
      \endverb
      \keyw{contrast,preparation,steady state,transient phase}
    \endentry
    \entry{birk_high-resolution_2022}{article}{}
      \name{author}{7}{}{%
        {{hash=fd18615fa40f7e79fd0ab4fb8e667a42}{%
           family={Birk},
           familyi={B\bibinitperiod},
           given={Florian},
           giveni={F\bibinitperiod}}}%
        {{hash=adeef8b26d878dcb79c12f127ce314fc}{%
           family={Glang},
           familyi={G\bibinitperiod},
           given={Felix},
           giveni={F\bibinitperiod}}}%
        {{hash=6ab9c778c840a0a5b5ab9f855d6807cf}{%
           family={Loktyushin},
           familyi={L\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=b8f4c6f589f60e9ebdf91e8d3f50a81e}{%
           family={Birkl},
           familyi={B\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod}}}%
        {{hash=7c7ed7ee0f554eb27b47d044c2e3c6a5}{%
           family={Ehses},
           familyi={E\bibinitperiod},
           given={Philipp},
           giveni={P\bibinitperiod}}}%
        {{hash=d32aa293ed7ed32a40025c81e59197f9}{%
           family={Scheffler},
           familyi={S\bibinitperiod},
           given={Klaus},
           giveni={K\bibinitperiod}}}%
        {{hash=5ce46428423062d80a85b723425cef79}{%
           family={Heule},
           familyi={H\bibinitperiod},
           given={Rahel},
           giveni={R\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{e182858a4399de88a69f000e467c31bc}
      \strng{fullhash}{bc8db9bff13292fa82fe18a0789d21a7}
      \strng{bibnamehash}{e182858a4399de88a69f000e467c31bc}
      \strng{authorbibnamehash}{e182858a4399de88a69f000e467c31bc}
      \strng{authornamehash}{e182858a4399de88a69f000e467c31bc}
      \strng{authorfullhash}{bc8db9bff13292fa82fe18a0789d21a7}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose to utilize the rich information content about microstructural tissue properties entangled in asymmetric balanced steady-state free precession (bSSFP) profiles to estimate multiple diffusion metrics simultaneously by neural network (NN) parameter quantification. A 12-point bSSFP phase-cycling scheme with high-resolution whole-brain coverage is employed at 3 and 9.4 T for NN input. Low-resolution target diffusion data are derived based on diffusion-weighted spin-echo echo-planar-imaging (SE-EPI) scans, that is, mean, axial, and radial diffusivity (MD, AD, and RD), fractional anisotropy (FA), as well as the spherical coordinates (azimuth Φ and inclination ϴ) of the principal diffusion eigenvector. A feedforward NN is trained with incorporated probabilistic uncertainty estimation. The NN predictions yielded highly reliable results in white matter (WM) and gray matter structures for MD. The quantification of FA, AD, and RD was overall in good agreement with the reference but the dependence of these parameters on WM anisotropy was somewhat biased (e.g. in corpus callosum). The inclination ϴ was well predicted for anisotropic WM structures, while the azimuth Φ was overall poorly predicted. The findings were highly consistent across both field strengths. Application of the optimized NN to high-resolution input data provided whole-brain maps with rich structural details. In conclusion, the proposed NN-driven approach showed potential to provide distortion-free high-resolution whole-brain maps of multiple diffusion metrics at high to ultrahigh field strengths in clinically relevant scan times.}
      \field{issn}{1099-1492}
      \field{journaltitle}{NMR in Biomedicine}
      \field{number}{6}
      \field{title}{High-resolution neural network-driven mapping of multiple diffusion metrics leveraging asymmetries in the balanced steady-state free precession frequency profile}
      \field{urlday}{11}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{35}
      \field{year}{2022}
      \field{urldateera}{ce}
      \field{pages}{e4669}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1002/nbm.4669
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/IW6H3LBR/Birk et al. - 2022 - High-resolution neural network-driven mapping of m.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/8ILQ3RCE/nbm.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/nbm.4669
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/nbm.4669
      \endverb
      \keyw{diffusion metrics,high resolution,multiparametric quantitative MRI,neural networks,phase-cycled bSSFP,probabilistic uncertainty estimation}
    \endentry
    \entry{bozinovski_reminder_2020}{article}{}
      \name{author}{1}{}{%
        {{hash=6cb5dee0129667a4c46082179bd8895e}{%
           family={Bozinovski},
           familyi={B\bibinitperiod},
           given={Stevo},
           giveni={S\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{6cb5dee0129667a4c46082179bd8895e}
      \strng{fullhash}{6cb5dee0129667a4c46082179bd8895e}
      \strng{bibnamehash}{6cb5dee0129667a4c46082179bd8895e}
      \strng{authorbibnamehash}{6cb5dee0129667a4c46082179bd8895e}
      \strng{authornamehash}{6cb5dee0129667a4c46082179bd8895e}
      \strng{authorfullhash}{6cb5dee0129667a4c46082179bd8895e}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper describes a work on transfer learning in neural networks carried out in 1970s and early 1980s, which produced its first publication in 1976. In the contemporary research on transfer learning there is a belief that pioneering work on transfer learning took place in early 1990s, and this paper updates that knowledge, pointing out that the transfer learning research started more than a decade earlier. This paper reviews that 1970s research and addresses important issues relevant for the current transfer learning research. It gives a mathematical model and geometric interpretation of transfer learning, and  a measure of transfer learning indicating positive, negative, and no transfer learning. It presents experimental investigation in the mentioned types of transfer learning. And it gives an application of transfer learning in pattern recognition using datasets of images.}
      \field{issn}{1854-3871}
      \field{journaltitle}{Informatica}
      \field{month}{9}
      \field{note}{Number: 3}
      \field{number}{3}
      \field{title}{Reminder of the {First} {Paper} on {Transfer} {Learning} in {Neural} {Networks}, 1976}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{44}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.31449/inf.v44i3.2828
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/KSYBFYVH/Bozinovski - 2020 - Reminder of the First Paper on Transfer Learning i.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.informatica.si/index.php/informatica/article/view/2828
      \endverb
      \verb{url}
      \verb https://www.informatica.si/index.php/informatica/article/view/2828
      \endverb
    \endentry
    \entry{brett_nipynibabel_2024}{misc}{}
      \name{author}{99}{}{%
        {{hash=626cc151613864abeb653c0d8172d98c}{%
           family={Brett},
           familyi={B\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=f629153ba111aa5f9ad5155beb0dd3e1}{%
           family={Markiewicz},
           familyi={M\bibinitperiod},
           given={Christopher\bibnamedelima J.},
           giveni={C\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=3f769f6f38f10ce050aff0d54f58526e}{%
           family={Hanke},
           familyi={H\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=90f75a481318c6e2f4d938116479e00f}{%
           family={Côté},
           familyi={C\bibinitperiod},
           given={Marc-Alexandre},
           giveni={M\bibinithyphendelim A\bibinitperiod}}}%
        {{hash=2434cb02d35e1a0b93baca3e0ad07092}{%
           family={Cipollini},
           familyi={C\bibinitperiod},
           given={Ben},
           giveni={B\bibinitperiod}}}%
        {{hash=9cd39db136b9fa76eb1032f772d38542}{%
           family={McCarthy},
           familyi={M\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod}}}%
        {{hash=e1a83b14951b32856e7a3fb8c88dbcdf}{%
           family={Jarecka},
           familyi={J\bibinitperiod},
           given={Dorota},
           giveni={D\bibinitperiod}}}%
        {{hash=f86f4d5916e5c4859c48d8ce6af23d28}{%
           family={Cheng},
           familyi={C\bibinitperiod},
           given={Christopher\bibnamedelima P.},
           giveni={C\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=8d336f110675c46226ece1db501ce712}{%
           family={Larson},
           familyi={L\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=e2fb284cc447dda0b361d24f661475ce}{%
           family={Halchenko},
           familyi={H\bibinitperiod},
           given={Yaroslav\bibnamedelima O.},
           giveni={Y\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=9b01250b5fc31f6ea0059e5b40c4cd8a}{%
           family={Cottaar},
           familyi={C\bibinitperiod},
           given={Michiel},
           giveni={M\bibinitperiod}}}%
        {{hash=07087ce774a9e957ee449e9c645696c2}{%
           family={Ghosh},
           familyi={G\bibinitperiod},
           given={Satrajit},
           giveni={S\bibinitperiod}}}%
        {{hash=6fd964c8a4142f04fd117b23a4f550c9}{%
           family={Wassermann},
           familyi={W\bibinitperiod},
           given={Demian},
           giveni={D\bibinitperiod}}}%
        {{hash=373a0a16b2f41b58fdddeef08d8ba43d}{%
           family={Gerhard},
           familyi={G\bibinitperiod},
           given={Stephan},
           giveni={S\bibinitperiod}}}%
        {{hash=235032fbc12d47e45283ca9a714aeda7}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Gregory\bibnamedelima R.},
           giveni={G\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=72a3a112c357eb38377384ea8e767c11}{%
           family={Baratz},
           familyi={B\bibinitperiod},
           given={Zvi},
           giveni={Z\bibinitperiod}}}%
        {{hash=2866cf64a5086ffc10ac32bf4be39205}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Hao-Ting},
           giveni={H\bibinithyphendelim T\bibinitperiod}}}%
        {{hash=3188f116b932aa7a8dec48cacd89677d}{%
           family={Papadopoulos\bibnamedelima Orfanos},
           familyi={P\bibinitperiod\bibinitdelim O\bibinitperiod},
           given={Dimitri},
           giveni={D\bibinitperiod}}}%
        {{hash=15ea00e86864b07ebb5c463db9664b35}{%
           family={Kastman},
           familyi={K\bibinitperiod},
           given={Erik},
           giveni={E\bibinitperiod}}}%
        {{hash=a0c933c207f09eacb73530e7af60073a}{%
           family={Kaczmarzyk},
           familyi={K\bibinitperiod},
           given={Jakub},
           giveni={J\bibinitperiod}}}%
        {{hash=291572e2ef0833df0942d622cfce47bd}{%
           family={Guidotti},
           familyi={G\bibinitperiod},
           given={Roberto},
           giveni={R\bibinitperiod}}}%
        {{hash=52b12b71d5a5e7fe6c13b01760b7cfd5}{%
           family={Daniel},
           familyi={D\bibinitperiod},
           given={Jonathan},
           giveni={J\bibinitperiod}}}%
        {{hash=b3701df6929af6743659e7b736f00c83}{%
           family={Duek},
           familyi={D\bibinitperiod},
           given={Or},
           giveni={O\bibinitperiod}}}%
        {{hash=848bbb8a883bec42d46ee442da523381}{%
           family={Rokem},
           familyi={R\bibinitperiod},
           given={Ariel},
           giveni={A\bibinitperiod}}}%
        {{hash=1c9ab5e4e455d7eee45f5e75c8fb56e0}{%
           family={Scheltienne},
           familyi={S\bibinitperiod},
           given={Mathieu},
           giveni={M\bibinitperiod}}}%
        {{hash=b3afe40090d7a8b36b4a0840e244c8ff}{%
           family={Madison},
           familyi={M\bibinitperiod},
           given={Cindee},
           giveni={C\bibinitperiod}}}%
        {{hash=7f39cd2960dfb8caff344fbb292dbf06}{%
           family={Sólon},
           familyi={S\bibinitperiod},
           given={Anibal},
           giveni={A\bibinitperiod}}}%
        {{hash=4fbb65faebd9a5ae3c34217c733c477e}{%
           family={Moloney},
           familyi={M\bibinitperiod},
           given={Brendan},
           giveni={B\bibinitperiod}}}%
        {{hash=28a2e940d0b6ebad29edb5bae588799f}{%
           family={Morency},
           familyi={M\bibinitperiod},
           given={Félix\bibnamedelima C.},
           giveni={F\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=c9690af972845ee41959a41c2eb56dd1}{%
           family={Goncalves},
           familyi={G\bibinitperiod},
           given={Mathias},
           giveni={M\bibinitperiod}}}%
        {{hash=00b655f1744cd9476d45b14e1d521a79}{%
           family={Markello},
           familyi={M\bibinitperiod},
           given={Ross},
           giveni={R\bibinitperiod}}}%
        {{hash=815741c15122b5bbb836008dbdf9b48c}{%
           family={Riddell},
           familyi={R\bibinitperiod},
           given={Cameron},
           giveni={C\bibinitperiod}}}%
        {{hash=2a8e6fb30064dd9ff465064b05cb2628}{%
           family={Burns},
           familyi={B\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod}}}%
        {{hash=eca9aeefdc8563b0e153fbedf08bc1a1}{%
           family={Millman},
           familyi={M\bibinitperiod},
           given={Jarrod},
           giveni={J\bibinitperiod}}}%
        {{hash=12ebe424e1c87de156c57e8fa7683f46}{%
           family={Gramfort},
           familyi={G\bibinitperiod},
           given={Alexandre},
           giveni={A\bibinitperiod}}}%
        {{hash=a2e162e1acae5a3859441944c0094736}{%
           family={Leppäkangas},
           familyi={L\bibinitperiod},
           given={Jaakko},
           giveni={J\bibinitperiod}}}%
        {{hash=9601f9d87b9760c18c8d6689e9ed6cd1}{%
           family={Bosch},
           familyi={B\bibinitperiod},
           given={Jasper\bibnamedelima J.F.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod},
           prefix={van\bibnamedelima den},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=7e8cb89f5c75cb98a1d77fc0eb951338}{%
           family={Vincent},
           familyi={V\bibinitperiod},
           given={Robert\bibnamedelima D.},
           giveni={R\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=5a9ac99354d0fe7eccec165965c179d9}{%
           family={Braun},
           familyi={B\bibinitperiod},
           given={Henry},
           giveni={H\bibinitperiod}}}%
        {{hash=79859656a0e79582731b4e89a955691a}{%
           family={Subramaniam},
           familyi={S\bibinitperiod},
           given={Krish},
           giveni={K\bibinitperiod}}}%
        {{hash=483ca1fd366733ca71e5df29c31ce026}{%
           family={Van},
           familyi={V\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
        {{hash=37fd6602fafa336c9f4f082ecd471b6c}{%
           family={Gorgolewski},
           familyi={G\bibinitperiod},
           given={Krzysztof\bibnamedelima J.},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=a38c3e10123230486099d321f3c93cd9}{%
           family={Raamana},
           familyi={R\bibinitperiod},
           given={Pradeep\bibnamedelima Reddy},
           giveni={P\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=33cf6836f4a37d82595d08dd614fb4ad}{%
           family={Klug},
           familyi={K\bibinitperiod},
           given={Julian},
           giveni={J\bibinitperiod}}}%
        {{hash=63a260b48343e34f0fdffd03ca67df6d}{%
           family={Vos\bibnamedelimb de\bibnamedelima Wael},
           familyi={V\bibinitperiod\bibinitdelim d\bibinitperiod\bibinitdelim W\bibinitperiod},
           given={Reinder},
           giveni={R\bibinitperiod}}}%
        {{hash=3f00e08f9637b590dcf017a51a8ee23a}{%
           family={Nichols},
           familyi={N\bibinitperiod},
           given={B.\bibnamedelimi Nolan},
           giveni={B\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=7c296d4c50374670978aaac2a91960f9}{%
           family={Baker},
           familyi={B\bibinitperiod},
           given={Eric\bibnamedelima M.},
           giveni={E\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=6819629f3291287562590ad17a8e9ee3}{%
           family={Hayashi},
           familyi={H\bibinitperiod},
           given={Soichi},
           giveni={S\bibinitperiod}}}%
        {{hash=23a87decad68d6c3d9a6584835af2068}{%
           family={Pinsard},
           familyi={P\bibinitperiod},
           given={Basile},
           giveni={B\bibinitperiod}}}%
        {{hash=fdca4ea48ef60697d8575b9fe70cf79d}{%
           family={Haselgrove},
           familyi={H\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=cd4d26afae4431d3cccfd202d77aa578}{%
           family={Hymers},
           familyi={H\bibinitperiod},
           given={Mark},
           giveni={M\bibinitperiod}}}%
        {{hash=bad82335174e52244c1c45aa43507b06}{%
           family={Esteban},
           familyi={E\bibinitperiod},
           given={Oscar},
           giveni={O\bibinitperiod}}}%
        {{hash=033fd8c67cbf254daeb85913f483dbc2}{%
           family={Koudoro},
           familyi={K\bibinitperiod},
           given={Serge},
           giveni={S\bibinitperiod}}}%
        {{hash=5387d2c9d7c24dae0973e307652b413f}{%
           family={Pérez-García},
           familyi={P\bibinithyphendelim G\bibinitperiod},
           given={Fernando},
           giveni={F\bibinitperiod}}}%
        {{hash=131b4cefb01c56d9d1548d75c4ba5555}{%
           family={Dockès},
           familyi={D\bibinitperiod},
           given={Jérôme},
           giveni={J\bibinitperiod}}}%
        {{hash=7d64b7e08271acef0f62ccb3a2086fc1}{%
           family={Oosterhof},
           familyi={O\bibinitperiod},
           given={Nikolaas\bibnamedelima N.},
           giveni={N\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=405e1c52f4fabc97cac1f289e54a5832}{%
           family={Amirbekian},
           familyi={A\bibinitperiod},
           given={Bago},
           giveni={B\bibinitperiod}}}%
        {{hash=b8a2e0d14ce6ed430a3b97cb7a00597a}{%
           family={Christian},
           familyi={C\bibinitperiod},
           given={Horea},
           giveni={H\bibinitperiod}}}%
        {{hash=1386d696657e90c3df96b57e4b83ac92}{%
           family={Nimmo-Smith},
           familyi={N\bibinithyphendelim S\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod}}}%
        {{hash=7515c84f17df1c1a97691ce8512d2fb4}{%
           family={Nguyen},
           familyi={N\bibinitperiod},
           given={Ly},
           giveni={L\bibinitperiod}}}%
        {{hash=a8a595575691ac12067af19f6479b75a}{%
           family={Suter},
           familyi={S\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
        {{hash=026da5b16945ff1399bf0a5376883a76}{%
           family={Reddigari},
           familyi={R\bibinitperiod},
           given={Samir},
           giveni={S\bibinitperiod}}}%
        {{hash=d74323afe4aacb98ff4df690e6f43a75}{%
           family={St-Jean},
           familyi={S\bibinithyphendelim J\bibinitperiod},
           given={Samuel},
           giveni={S\bibinitperiod}}}%
        {{hash=1591ec104129dd98dc4f1d1f7944547d}{%
           family={Panfilov},
           familyi={P\bibinitperiod},
           given={Egor},
           giveni={E\bibinitperiod}}}%
        {{hash=3bc0e9c1e8a2e07e842b9da60db9e2e4}{%
           family={Garyfallidis},
           familyi={G\bibinitperiod},
           given={Eleftherios},
           giveni={E\bibinitperiod}}}%
        {{hash=8dfd6b3615de2946b6e0c1772b3b5827}{%
           family={Varoquaux},
           familyi={V\bibinitperiod},
           given={Gael},
           giveni={G\bibinitperiod}}}%
        {{hash=923ef8213327cb57a0df221933600017}{%
           family={Legarreta},
           familyi={L\bibinitperiod},
           given={Jon\bibnamedelima Haitz},
           giveni={J\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=eea2fa76f99fc49f04ea6675bd48d521}{%
           family={Hahn},
           familyi={H\bibinitperiod},
           given={Kevin\bibnamedelima S.},
           giveni={K\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=24a85092676cba212806bda20447fc00}{%
           family={Waller},
           familyi={W\bibinitperiod},
           given={Lea},
           giveni={L\bibinitperiod}}}%
        {{hash=86b86c4f8e326183a4a58f6320cfae43}{%
           family={Hinds},
           familyi={H\bibinitperiod},
           given={Oliver\bibnamedelima P.},
           giveni={O\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=b2fdd4d9d7b3747819bc42f089d98fc7}{%
           family={Fauber},
           familyi={F\bibinitperiod},
           given={Bennet},
           giveni={B\bibinitperiod}}}%
        {{hash=4890ad94c5f5be9cafc8339910a50e94}{%
           family={Dewey},
           familyi={D\bibinitperiod},
           given={Blake},
           giveni={B\bibinitperiod}}}%
        {{hash=d04d0c8e703a6753f561785283f32aca}{%
           family={Perez},
           familyi={P\bibinitperiod},
           given={Fabian},
           giveni={F\bibinitperiod}}}%
        {{hash=fafaa7d00542cd079af17916abf3e347}{%
           family={Roberts},
           familyi={R\bibinitperiod},
           given={Jacob},
           giveni={J\bibinitperiod}}}%
        {{hash=7e567d51746021a736084a5d361744cd}{%
           family={Poline},
           familyi={P\bibinitperiod},
           given={Jean-Baptiste},
           giveni={J\bibinithyphendelim B\bibinitperiod}}}%
        {{hash=8ed2fe66036cc5896c724f8d3ae224e7}{%
           family={Stutters},
           familyi={S\bibinitperiod},
           given={Jon},
           giveni={J\bibinitperiod}}}%
        {{hash=9a19f4e44630b13e3f84ec15b3fbae40}{%
           family={Jordan},
           familyi={J\bibinitperiod},
           given={Kesshi},
           giveni={K\bibinitperiod}}}%
        {{hash=f3ad93e94d21d6ccf6d45e8e2feb0cc4}{%
           family={Cieslak},
           familyi={C\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=7e5f1f2de0d00735a74d1783427d0e4a}{%
           family={Moreno},
           familyi={M\bibinitperiod},
           given={Miguel\bibnamedelima Estevan},
           giveni={M\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=8bfc20fef04af664627398f8a3c699f1}{%
           family={Hrnčiar},
           familyi={H\bibinitperiod},
           given={Tomáš},
           giveni={T\bibinitperiod}}}%
        {{hash=e0edd56e67a051a8db8a3c3e85bc4d53}{%
           family={Haenel},
           familyi={H\bibinitperiod},
           given={Valentin},
           giveni={V\bibinitperiod}}}%
        {{hash=48d7274dea9ffbd3123a8a01ce2cc75f}{%
           family={Schwartz},
           familyi={S\bibinitperiod},
           given={Yannick},
           giveni={Y\bibinitperiod}}}%
        {{hash=c2d5fc581e388044753adf60766a4d83}{%
           family={Darwin},
           familyi={D\bibinitperiod},
           given={Benjamin\bibnamedelima C},
           giveni={B\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=0f3fc06fb9fcbb01b9cc0985eaf0a71c}{%
           family={Thirion},
           familyi={T\bibinitperiod},
           given={Bertrand},
           giveni={B\bibinitperiod}}}%
        {{hash=1fd98bc79db84f5282035c08794c9013}{%
           family={Gauthier},
           familyi={G\bibinitperiod},
           given={Carl},
           giveni={C\bibinitperiod}}}%
        {{hash=230e942bcd44ffaf4e862f8137e63fa7}{%
           family={Solovey},
           familyi={S\bibinitperiod},
           given={Igor},
           giveni={I\bibinitperiod}}}%
        {{hash=bb6436d795631781bbeea6e398716f53}{%
           family={Gonzalez},
           familyi={G\bibinitperiod},
           given={Ivan},
           giveni={I\bibinitperiod}}}%
        {{hash=b68d05f3be7a6c4bf56e1fa116b0f606}{%
           family={Palasubramaniam},
           familyi={P\bibinitperiod},
           given={Jath},
           giveni={J\bibinitperiod}}}%
        {{hash=6a46a7954c134ee632e283c67181dcd6}{%
           family={Lecher},
           familyi={L\bibinitperiod},
           given={Justin},
           giveni={J\bibinitperiod}}}%
        {{hash=aee7436792494f62c5685ced32c3d183}{%
           family={Leinweber},
           familyi={L\bibinitperiod},
           given={Katrin},
           giveni={K\bibinitperiod}}}%
        {{hash=1b7c1d7cdfc90d4a2aeb40d5251f9b0e}{%
           family={Raktivan},
           familyi={R\bibinitperiod},
           given={Konstantinos},
           giveni={K\bibinitperiod}}}%
        {{hash=c62af025d09d9a3f47dbac3726c10a10}{%
           family={Calábková},
           familyi={C\bibinitperiod},
           given={Markéta},
           giveni={M\bibinitperiod}}}%
        {{hash=a55d7c9320ccb32e0eea577c8552f4e9}{%
           family={Fischer},
           familyi={F\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
        {{hash=316e8efde95cbbe662a53fa3bf5165e4}{%
           family={Gervais},
           familyi={G\bibinitperiod},
           given={Philippe},
           giveni={P\bibinitperiod}}}%
        {{hash=b2d9251dda959f553d451e74922bf317}{%
           family={Gadde},
           familyi={G\bibinitperiod},
           given={Syam},
           giveni={S\bibinitperiod}}}%
        {{hash=296157b8dc063e83dbdca144a86c50b3}{%
           family={Ballinger},
           familyi={B\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=599dfa24843aecbe951fb1816db01e19}{%
           family={Roos},
           familyi={R\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=4db3ff4181549023021535736edb77af}{%
           family={Reddam},
           familyi={R\bibinitperiod},
           given={Venkateswara\bibnamedelima Reddy},
           giveni={V\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=eccd9e180c535039ee164103eee75b46}{%
           family={{freec84}},
           familyi={f\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Zenodo}%
      }
      \strng{namehash}{b4687c1517f1a0edb4d121c7c1b1abc7}
      \strng{fullhash}{d499f2cb2420a7b2c65c9ee7bc182fe2}
      \strng{bibnamehash}{b4687c1517f1a0edb4d121c7c1b1abc7}
      \strng{authorbibnamehash}{b4687c1517f1a0edb4d121c7c1b1abc7}
      \strng{authornamehash}{b4687c1517f1a0edb4d121c7c1b1abc7}
      \strng{authorfullhash}{d499f2cb2420a7b2c65c9ee7bc182fe2}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{month}{2}
      \field{title}{nipy/nibabel: 5.2.1}
      \field{year}{2024}
      \verb{doi}
      \verb 10.5281/zenodo.10714563
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.5281/zenodo.10714563
      \endverb
      \verb{url}
      \verb https://doi.org/10.5281/zenodo.10714563
      \endverb
    \endentry
    \entry{relaxation}{incollection}{}
      \name{author}{3}{}{%
        {{hash=a3071b694d6b97dd462035095c3ce751}{%
           family={{Brian M. Dale}},
           familyi={B\bibinitperiod}}}%
        {{hash=12e0bae991545a3866b336a1ef3556b8}{%
           family={{Mark A. Brown}},
           familyi={M\bibinitperiod}}}%
        {{hash=910976112c83f0a034f95e6e04bd00b9}{%
           family={{PhD,, Richard C. Semelka}},
           familyi={P\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {John Wiley \& Sons, Ltd}%
      }
      \strng{namehash}{831960ac6cb7919db35705d39089be0e}
      \strng{fullhash}{831960ac6cb7919db35705d39089be0e}
      \strng{bibnamehash}{831960ac6cb7919db35705d39089be0e}
      \strng{authorbibnamehash}{831960ac6cb7919db35705d39089be0e}
      \strng{authornamehash}{831960ac6cb7919db35705d39089be0e}
      \strng{authorfullhash}{831960ac6cb7919db35705d39089be0e}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The process by which the protons release the energy that they absorbed from the RF pulse is known as relaxation. Relaxation is a fundamental aspect of MR, as essential as energy absorption, and provides the primary mechanism for image contrast. In resonance absorption, RF energy is absorbed by the protons only when it is broadcast at the correct frequency. Following excitation, relaxation occurs in which the protons release this added energy and return to their original configuration through naturally occurring processes. Two relaxation times can be measured, known as T1 and T2. While both times measure the spontaneous energy transfer by an excited proton, they differ in the final disposition of the energy. The rate of RF pulse application and the efficiency of energy transfer must have the proper balance. Spin-lattice relaxation measures the rate of energy transfer from an excited proton to its surroundings.}
      \field{booktitle}{{MRI} {Basic} {Principles} and {Applications}}
      \field{isbn}{978-1-119-01306-8}
      \field{note}{Section: 3 \_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119013068.ch3}
      \field{title}{Relaxation}
      \field{urlday}{18}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{17\bibrangedash 25}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1002/9781119013068.ch3
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/8JWTZX3C/2015 - Relaxation.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/KMAWZEQS/9781119013068.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119013068.ch3
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119013068.ch3
      \endverb
      \keyw{MR measurement,RF energy,spin–spin relaxation,T1 relaxation,T2 relaxation}
    \endentry
    \entry{brown_introduction_2014}{incollection}{}
      \name{author}{5}{}{%
        {{hash=f160b82b5c491ab12b83c9f179c1c88c}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Robert\bibnamedelima W.},
           giveni={R\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{hash=61004c1cadfc73a2222d9994848c72a4}{%
           family={Cheng},
           familyi={C\bibinitperiod},
           given={Yu-Chung\bibnamedelima N.},
           giveni={Y\bibinithyphendelim C\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=d2c16a1f5c7bbc864024b4765357c33e}{%
           family={Haacke},
           familyi={H\bibinitperiod},
           given={Mark},
           giveni={M\bibinitperiod}}}%
        {{hash=b1ec4a71c2d452fd36939d8c6780cdd4}{%
           family={Thompson},
           familyi={T\bibinitperiod},
           given={Michael\bibnamedelima R.},
           giveni={M\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=7e8586de48ca089266cd61938b8dcc38}{%
           family={Venkatesan},
           familyi={V\bibinitperiod},
           given={Ramesh},
           giveni={R\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {John Wiley \& Sons, Ltd}%
      }
      \strng{namehash}{f9342337369630d0d366b18dd534e22b}
      \strng{fullhash}{f4ee26842d41c8160d95cd31fb4dc4a4}
      \strng{bibnamehash}{f9342337369630d0d366b18dd534e22b}
      \strng{authorbibnamehash}{f9342337369630d0d366b18dd534e22b}
      \strng{authornamehash}{f9342337369630d0d366b18dd534e22b}
      \strng{authorfullhash}{f4ee26842d41c8160d95cd31fb4dc4a4}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This chapter introduces the basic electromagnetic and mathematical concepts needed to understand the design of the coils that generate the fields used in MRI. It discusses the desirable properties of the various coil systems (main magnet, rf, and gradient). The design of coils lies primarily in determining the optimal arrangements of current necessary to produce the magnetic fields used in MRI. The second class of coils employed in MRI are linear magnetic field gradient coils. These coils are used to encode spatially the positions of the spins in MRI by varying the value of the local magnetic field causing spins Larmor frequencies to vary as a function of their positions. These coils are rapidly switched during MRI sequences to allow the collection of large regions of κ-space in a short amount of time. It gives a brief introduction to radiofrequency power deposition and specific absorption rate.}
      \field{booktitle}{Magnetic {Resonance} {Imaging}}
      \field{isbn}{978-1-118-63395-3}
      \field{note}{Section: 27 \_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118633953.ch27}
      \field{title}{Introduction to {MRI} {Coils} and {Magnets}}
      \field{urlday}{8}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2014}
      \field{urldateera}{ce}
      \field{pages}{823\bibrangedash 857}
      \range{pages}{35}
      \verb{doi}
      \verb 10.1002/9781118633953.ch27
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/FMWDYCQX/2014 - Introduction to MRI Coils and Magnets.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/QNVX9EF4/9781118633953.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118633953.ch27
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118633953.ch27
      \endverb
      \keyw{absorption rate,coil system,magnet,magnetic field gradient,MRI,power deposition,radiofrequency}
    \endentry
    \entry{hutchison_robust_2013}{incollection}{}
      \name{author}{6}{}{%
        {{hash=39670ad503c9ccbed6e7a302b95d0f39}{%
           family={Cao},
           familyi={C\bibinitperiod},
           given={Tian},
           giveni={T\bibinitperiod}}}%
        {{hash=3b2f6bbdb4322c135bde344ec779f073}{%
           family={Jojic},
           familyi={J\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod}}}%
        {{hash=66ec6820b19f869e8f53c41851da77f8}{%
           family={Modla},
           familyi={M\bibinitperiod},
           given={Shannon},
           giveni={S\bibinitperiod}}}%
        {{hash=5a3e02f87871fed8cebf327b11e178d5}{%
           family={Powell},
           familyi={P\bibinitperiod},
           given={Debbie},
           giveni={D\bibinitperiod}}}%
        {{hash=1c52bafed9456301902ccdb208bc2579}{%
           family={Czymmek},
           familyi={C\bibinitperiod},
           given={Kirk},
           giveni={K\bibinitperiod}}}%
        {{hash=c6add5cc3b01d80c7332dc87ce7cc9e8}{%
           family={Niethammer},
           familyi={N\bibinitperiod},
           given={Marc},
           giveni={M\bibinitperiod}}}%
      }
      \name{editor}{18}{}{%
        {{hash=d003d9a994005f480f7fa06dde74326e}{%
           family={Hutchison},
           familyi={H\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=45496c6a7530cfbfb4f3218a2602b77e}{%
           family={Kanade},
           familyi={K\bibinitperiod},
           given={Takeo},
           giveni={T\bibinitperiod}}}%
        {{hash=9dd3a56c94774f5880ca7475fdc308ea}{%
           family={Kittler},
           familyi={K\bibinitperiod},
           given={Josef},
           giveni={J\bibinitperiod}}}%
        {{hash=fb11814963625d418100ec9ca3710333}{%
           family={Kleinberg},
           familyi={K\bibinitperiod},
           given={Jon\bibnamedelima M.},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=e07c4272d13053fc36d770d4735f2c14}{%
           family={Mattern},
           familyi={M\bibinitperiod},
           given={Friedemann},
           giveni={F\bibinitperiod}}}%
        {{hash=47dbc192a926109dd86ea18b25249a93}{%
           family={Mitchell},
           familyi={M\bibinitperiod},
           given={John\bibnamedelima C.},
           giveni={J\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=c6af39e79e88306281e6e0b0ccea956c}{%
           family={Naor},
           familyi={N\bibinitperiod},
           given={Moni},
           giveni={M\bibinitperiod}}}%
        {{hash=7d3ea70a5274b32c8a184dd4d844ee47}{%
           family={Nierstrasz},
           familyi={N\bibinitperiod},
           given={Oscar},
           giveni={O\bibinitperiod}}}%
        {{hash=6bcab2334dc65214139b0ad45fe8185e}{%
           family={Pandu\bibnamedelima Rangan},
           familyi={P\bibinitperiod\bibinitdelim R\bibinitperiod},
           given={C.},
           giveni={C\bibinitperiod}}}%
        {{hash=665b6687b4ed05721bf55d61032505ca}{%
           family={Steffen},
           familyi={S\bibinitperiod},
           given={Bernhard},
           giveni={B\bibinitperiod}}}%
        {{hash=8753fbfaaa4aa8a1195c657edc9daef4}{%
           family={Sudan},
           familyi={S\bibinitperiod},
           given={Madhu},
           giveni={M\bibinitperiod}}}%
        {{hash=cd9aa5de7673e375889cc32997ef97df}{%
           family={Terzopoulos},
           familyi={T\bibinitperiod},
           given={Demetri},
           giveni={D\bibinitperiod}}}%
        {{hash=0e2feef9b3f0364b6e5bf7c63136056e}{%
           family={Tygar},
           familyi={T\bibinitperiod},
           given={Doug},
           giveni={D\bibinitperiod}}}%
        {{hash=a4cf237a06b02ad7e7601b14b4d005be}{%
           family={Vardi},
           familyi={V\bibinitperiod},
           given={Moshe\bibnamedelima Y.},
           giveni={M\bibinitperiod\bibinitdelim Y\bibinitperiod}}}%
        {{hash=e47f9d085c16045a5911784850208ada}{%
           family={Weikum},
           familyi={W\bibinitperiod},
           given={Gerhard},
           giveni={G\bibinitperiod}}}%
        {{hash=e4eb33be9f70b08fdbae06f4003ad249}{%
           family={Salinesi},
           familyi={S\bibinitperiod},
           given={Camille},
           giveni={C\bibinitperiod}}}%
        {{hash=88e22618df6cb769735eacd5a19e7f4b}{%
           family={Norrie},
           familyi={N\bibinitperiod},
           given={Moira\bibnamedelima C.},
           giveni={M\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=c3d0b98b9fa6149fb896a8a8ab8e8e25}{%
           family={Pastor},
           familyi={P\bibinitperiod},
           given={Óscar},
           giveni={Ó\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer Berlin Heidelberg}%
      }
      \strng{namehash}{92e9788a1dc326e27acf2dc591e02e96}
      \strng{fullhash}{d8d035a2b2cb941122867806411fd368}
      \strng{bibnamehash}{92e9788a1dc326e27acf2dc591e02e96}
      \strng{authorbibnamehash}{92e9788a1dc326e27acf2dc591e02e96}
      \strng{authornamehash}{92e9788a1dc326e27acf2dc591e02e96}
      \strng{authorfullhash}{d8d035a2b2cb941122867806411fd368}
      \strng{editorbibnamehash}{1878e5aaeb2ba2e2aaa5cb8a1a7cf207}
      \strng{editornamehash}{1878e5aaeb2ba2e2aaa5cb8a1a7cf207}
      \strng{editorfullhash}{48457093068d165d970335ed23bacded}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a robust multimodal dictionary learning method for multimodal images. Joint dictionary learning for both modalities may be impaired by lack of correspondence between image modalities in training data, for example due to areas of low quality in one of the modalities. Dictionaries learned with such non-corresponding data will induce uncertainty about image representation. In this paper, we propose a probabilistic model that accounts for image areas that are poorly corresponding between the image modalities. We cast the problem of learning a dictionary in presence of problematic image patches as a likelihood maximization problem and solve it with a variant of the EM algorithm. Our algorithm iterates identiﬁcation of poorly corresponding patches and reﬁnements of the dictionary. We tested our method on synthetic and real data. We show improvements in image prediction quality and alignment accuracy when using the method for multimodal image registration.}
      \field{booktitle}{Advanced {Information} {Systems} {Engineering}}
      \field{isbn}{978-3-642-38708-1 978-3-642-38709-8}
      \field{note}{Series Title: Lecture Notes in Computer Science}
      \field{title}{Robust {Multimodal} {Dictionary} {Learning}}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{7908}
      \field{year}{2013}
      \field{urldateera}{ce}
      \field{pages}{259\bibrangedash 266}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1007/978-3-642-40811-3_33
      \endverb
      \verb{file}
      \verb Cao et al. - 2013 - Robust Multimodal Dictionary Learning.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/TQW5VCFT/Cao et al. - 2013 - Robust Multimodal Dictionary Learning.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/978-3-642-40811-3_33
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/978-3-642-40811-3_33
      \endverb
    \endentry
    \entry{cardoso_monai_2022}{misc}{}
      \name{author}{57}{}{%
        {{hash=da7555ed408fdfa8a4bf2b6aa96e7e75}{%
           family={Cardoso},
           familyi={C\bibinitperiod},
           given={M.\bibnamedelimi Jorge},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=d32ec3dde5f923678d38244353a95911}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Wenqi},
           giveni={W\bibinitperiod}}}%
        {{hash=2e7c4d1d38f7906188ea79dadf997b1d}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod}}}%
        {{hash=ae7c2b784f76e15ce2eb6234f4c8d155}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Nic},
           giveni={N\bibinitperiod}}}%
        {{hash=05e21e25083844a6792428e8c193fee1}{%
           family={Kerfoot},
           familyi={K\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=f4f38a9e771a6dbf5985f32cfe258976}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yiheng},
           giveni={Y\bibinitperiod}}}%
        {{hash=010f7d66876ba7c27726cc24cd492efb}{%
           family={Murrey},
           familyi={M\bibinitperiod},
           given={Benjamin},
           giveni={B\bibinitperiod}}}%
        {{hash=c4dd0f2ee007b795cefdfd28a46af79f}{%
           family={Myronenko},
           familyi={M\bibinitperiod},
           given={Andriy},
           giveni={A\bibinitperiod}}}%
        {{hash=f982740a7438415c1c096a90edd58d3e}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Can},
           giveni={C\bibinitperiod}}}%
        {{hash=43bfecf0db835905ffe98dadaa0b057f}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Dong},
           giveni={D\bibinitperiod}}}%
        {{hash=d0968ce3719368d26817f02301e44c29}{%
           family={Nath},
           familyi={N\bibinitperiod},
           given={Vishwesh},
           giveni={V\bibinitperiod}}}%
        {{hash=81459eaa42a93f02518623c67312acd5}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Yufan},
           giveni={Y\bibinitperiod}}}%
        {{hash=1ee2882bc84b45bc87f4adf71cfc32c0}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Ziyue},
           giveni={Z\bibinitperiod}}}%
        {{hash=4a8b0d75ef5dd9aff244bd459eb56921}{%
           family={Hatamizadeh},
           familyi={H\bibinitperiod},
           given={Ali},
           giveni={A\bibinitperiod}}}%
        {{hash=c4dd0f2ee007b795cefdfd28a46af79f}{%
           family={Myronenko},
           familyi={M\bibinitperiod},
           given={Andriy},
           giveni={A\bibinitperiod}}}%
        {{hash=0617a43f5a6cc67950dce84f7ee05b67}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Wentao},
           giveni={W\bibinitperiod}}}%
        {{hash=e8425d142317172c04a78968a7c61852}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Yun},
           giveni={Y\bibinitperiod}}}%
        {{hash=c01a45cd34aaef2e26bbbc6e006c5bd7}{%
           family={Zheng},
           familyi={Z\bibinitperiod},
           given={Mingxin},
           giveni={M\bibinitperiod}}}%
        {{hash=caeb0e5523b56ad22085585d7f65afa4}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Yucheng},
           giveni={Y\bibinitperiod}}}%
        {{hash=21426a8690eaf934dae96290d66e06fc}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Isaac},
           giveni={I\bibinitperiod}}}%
        {{hash=75d36de17c24cc7dfeae4d5f6c4f0505}{%
           family={Zephyr},
           familyi={Z\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=eeb7465bafc9ade3f6ae23db25f1a3da}{%
           family={Hashemian},
           familyi={H\bibinitperiod},
           given={Behrooz},
           giveni={B\bibinitperiod}}}%
        {{hash=b3cb32a33521393f07c2c1bfa519f33c}{%
           family={Alle},
           familyi={A\bibinitperiod},
           given={Sachidanand},
           giveni={S\bibinitperiod}}}%
        {{hash=51ec7cf3c3986fa7df321bffc7c95b09}{%
           family={Darestani},
           familyi={D\bibinitperiod},
           given={Mohammad\bibnamedelima Zalbagi},
           giveni={M\bibinitperiod\bibinitdelim Z\bibinitperiod}}}%
        {{hash=020067a2d9955cbfad44167994530dae}{%
           family={Budd},
           familyi={B\bibinitperiod},
           given={Charlie},
           giveni={C\bibinitperiod}}}%
        {{hash=3f5972050012d3d24ecc78385b735a73}{%
           family={Modat},
           familyi={M\bibinitperiod},
           given={Marc},
           giveni={M\bibinitperiod}}}%
        {{hash=befa5547c0c5b07d62ba6f20e5977440}{%
           family={Vercauteren},
           familyi={V\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod}}}%
        {{hash=61f1129982fbe96be3ddc3392cac2655}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Guotai},
           giveni={G\bibinitperiod}}}%
        {{hash=66f6c494ecf41750a84f46ce88d205dd}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yiwen},
           giveni={Y\bibinitperiod}}}%
        {{hash=2cf080b215ec9f16ab2edc3dbce13876}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Yipeng},
           giveni={Y\bibinitperiod}}}%
        {{hash=1e24e8a383766c564db8b1cb1bd731e2}{%
           family={Fu},
           familyi={F\bibinitperiod},
           given={Yunguan},
           giveni={Y\bibinitperiod}}}%
        {{hash=8a41474890a6a83e5a4801b1c33ff12e}{%
           family={Gorman},
           familyi={G\bibinitperiod},
           given={Benjamin},
           giveni={B\bibinitperiod}}}%
        {{hash=6048ec4777f717a50cafebea5148e281}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Hans},
           giveni={H\bibinitperiod}}}%
        {{hash=c6e7fd6b3f36f46ddab5074347c8caa0}{%
           family={Genereaux},
           familyi={G\bibinitperiod},
           given={Brad},
           giveni={B\bibinitperiod}}}%
        {{hash=d1042f6784810d70bf14346dbee91e93}{%
           family={Erdal},
           familyi={E\bibinitperiod},
           given={Barbaros\bibnamedelima S.},
           giveni={B\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=fd62bbb6cbbcffef90b1d331263a68c6}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Vikash},
           giveni={V\bibinitperiod}}}%
        {{hash=cda7ab58324a69413816838fdd4c39ad}{%
           family={Diaz-Pinto},
           familyi={D\bibinithyphendelim P\bibinitperiod},
           given={Andres},
           giveni={A\bibinitperiod}}}%
        {{hash=782f3a99624685ce18dce2c3933b8a1c}{%
           family={Dourson},
           familyi={D\bibinitperiod},
           given={Andre},
           giveni={A\bibinitperiod}}}%
        {{hash=ef1e4fd37692b1d549e91153b52119ef}{%
           family={Maier-Hein},
           familyi={M\bibinithyphendelim H\bibinitperiod},
           given={Lena},
           giveni={L\bibinitperiod}}}%
        {{hash=63350393ee74dce2bfeda809cbb2f459}{%
           family={Jaeger},
           familyi={J\bibinitperiod},
           given={Paul\bibnamedelima F.},
           giveni={P\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
        {{hash=75ee2a2d5a206640fc164c5606ffad19}{%
           family={Baumgartner},
           familyi={B\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=b342b8d22d373edc0ef9b257397d5896}{%
           family={Kalpathy-Cramer},
           familyi={K\bibinithyphendelim C\bibinitperiod},
           given={Jayashree},
           giveni={J\bibinitperiod}}}%
        {{hash=6f13542e79365113e4f2f26087b30bbb}{%
           family={Flores},
           familyi={F\bibinitperiod},
           given={Mona},
           giveni={M\bibinitperiod}}}%
        {{hash=93d1bacd02ff5b479a51ed532bec1dc8}{%
           family={Kirby},
           familyi={K\bibinitperiod},
           given={Justin},
           giveni={J\bibinitperiod}}}%
        {{hash=7013a5f589c3f6b78d41dd8faee49f77}{%
           family={Cooper},
           familyi={C\bibinitperiod},
           given={Lee\bibnamedelimb A.\bibnamedelimi D.},
           giveni={L\bibinitperiod\bibinitdelim A\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=04c08832941bceae0bfee57a4113dd33}{%
           family={Roth},
           familyi={R\bibinitperiod},
           given={Holger\bibnamedelima R.},
           giveni={H\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=40c221ac11c898cb10013b2468fc229b}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Daguang},
           giveni={D\bibinitperiod}}}%
        {{hash=07b05e4c178f05c2bc52eb7e4a733be9}{%
           family={Bericat},
           familyi={B\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=d3f8aa7d0bce843bc19dd2081744e29d}{%
           family={Floca},
           familyi={F\bibinitperiod},
           given={Ralf},
           giveni={R\bibinitperiod}}}%
        {{hash=9c1e53c3d15103f0b0e185c215512074}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={S.\bibnamedelimi Kevin},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=73841809b315a8cb5960c05545cea201}{%
           family={Shuaib},
           familyi={S\bibinitperiod},
           given={Haris},
           giveni={H\bibinitperiod}}}%
        {{hash=dafbc5fc0c5dd1432e9620ee94c94ec4}{%
           family={Farahani},
           familyi={F\bibinitperiod},
           given={Keyvan},
           giveni={K\bibinitperiod}}}%
        {{hash=f673cd141cf85e311274bfdcd9fd11f6}{%
           family={Maier-Hein},
           familyi={M\bibinithyphendelim H\bibinitperiod},
           given={Klaus\bibnamedelima H.},
           giveni={K\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=f09d7ed79efbb905bbd7df9776597963}{%
           family={Aylward},
           familyi={A\bibinitperiod},
           given={Stephen},
           giveni={S\bibinitperiod}}}%
        {{hash=7960fee10000dde8bb88f6d93d053053}{%
           family={Dogra},
           familyi={D\bibinitperiod},
           given={Prerna},
           giveni={P\bibinitperiod}}}%
        {{hash=32246aa24a3f02a73916f12a384e1707}{%
           family={Ourselin},
           familyi={O\bibinitperiod},
           given={Sebastien},
           giveni={S\bibinitperiod}}}%
        {{hash=4b633bc43ae852d2f51a00e4555500e1}{%
           family={Feng},
           familyi={F\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{772e945314805674bc2dba65ec45f7d3}
      \strng{fullhash}{43f5aaafba95d1e9461e6610a8b22579}
      \strng{bibnamehash}{772e945314805674bc2dba65ec45f7d3}
      \strng{authorbibnamehash}{772e945314805674bc2dba65ec45f7d3}
      \strng{authornamehash}{772e945314805674bc2dba65ec45f7d3}
      \strng{authorfullhash}{43f5aaafba95d1e9461e6610a8b22579}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Artificial Intelligence (AI) is having a tremendous impact across most areas of science. Applications of AI in healthcare have the potential to improve our ability to detect, diagnose, prognose, and intervene on human disease. For AI models to be used clinically, they need to be made safe, reproducible and robust, and the underlying software framework must be aware of the particularities (e.g. geometry, physiology, physics) of medical data being processed. This work introduces MONAI, a freely available, community-supported, and consortium-led PyTorch-based framework for deep learning in healthcare. MONAI extends PyTorch to support medical data, with a particular focus on imaging, and provide purpose-specific AI model architectures, transformations and utilities that streamline the development and deployment of medical AI models. MONAI follows best practices for software-development, providing an easy-to-use, robust, well-documented, and well-tested software framework. MONAI preserves the simple, additive, and compositional approach of its underlying PyTorch libraries. MONAI is being used by and receiving contributions from research, clinical and industrial teams from around the world, who are pursuing applications spanning nearly every aspect of healthcare.}
      \field{month}{11}
      \field{shorttitle}{{MONAI}}
      \field{title}{{MONAI}: {An} open-source framework for deep learning in healthcare}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2211.02701
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/IEJ6VT3D/Cardoso et al. - 2022 - MONAI An open-source framework for deep learning .pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/KZHLS5NT/2211.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2211.02701
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2211.02701
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{chen_med3d_2019}{misc}{}
      \name{author}{3}{}{%
        {{hash=8a4e1b2730dcad4d093174fe61dd01eb}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Sihong},
           giveni={S\bibinitperiod}}}%
        {{hash=3df39f88e0c7df3e7c8775e180006d4e}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kai},
           giveni={K\bibinitperiod}}}%
        {{hash=828d9baf956fa25bba9fb1a2dc3ab299}{%
           family={Zheng},
           familyi={Z\bibinitperiod},
           given={Yefeng},
           giveni={Y\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{9da5366eac4a5435659f04dfe5d587b0}
      \strng{fullhash}{9da5366eac4a5435659f04dfe5d587b0}
      \strng{bibnamehash}{9da5366eac4a5435659f04dfe5d587b0}
      \strng{authorbibnamehash}{9da5366eac4a5435659f04dfe5d587b0}
      \strng{authornamehash}{9da5366eac4a5435659f04dfe5d587b0}
      \strng{authorfullhash}{9da5366eac4a5435659f04dfe5d587b0}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The performance on deep learning is significantly affected by volume of training data. Models pre-trained from massive dataset such as ImageNet become a powerful weapon for speeding up training convergence and improving accuracy. Similarly, models based on large dataset are important for the development of deep learning in 3D medical images. However, it is extremely challenging to build a sufficiently large dataset due to difficulty of data acquisition and annotation in 3D medical imaging. We aggregate the dataset from several medical challenges to build 3DSeg-8 dataset with diverse modalities, target organs, and pathologies. To extract general medical three-dimension (3D) features, we design a heterogeneous 3D network called Med3D to co-train multi-domain 3DSeg-8 so as to make a series of pre-trained models. We transfer Med3D pre-trained models to lung segmentation in LIDC dataset, pulmonary nodule classification in LIDC dataset and liver segmentation on LiTS challenge. Experiments show that the Med3D can accelerate the training convergence speed of target 3D medical tasks 2 times compared with model pre-trained on Kinetics dataset, and 10 times compared with training from scratch as well as improve accuracy ranging from 3\% to 20\%. Transferring our Med3D model on state-the-of-art DenseASPP segmentation network, in case of single model, we achieve 94.6{\textbackslash}\% Dice coefficient which approaches the result of top-ranged algorithms on the LiTS challenge.}
      \field{month}{7}
      \field{note}{arXiv:1904.00625 [cs]}
      \field{shorttitle}{{Med3D}}
      \field{title}{{Med3D}: {Transfer} {Learning} for {3D} {Medical} {Image} {Analysis}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \true{nocite}
      \verb{doi}
      \verb 10.48550/arXiv.1904.00625
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/EMLGABUP/Chen et al. - 2019 - Med3D Transfer Learning for 3D Medical Image Anal.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/48JUMZ59/1904.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1904.00625
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1904.00625
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{chronopoulou_embarrassingly_2019}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=b0b7a7b96f4874316bb3a8dc595890e3}{%
           family={Chronopoulou},
           familyi={C\bibinitperiod},
           given={Alexandra},
           giveni={A\bibinitperiod}}}%
        {{hash=b1fa8e198db3a205dd0e9a7b05909238}{%
           family={Baziotis},
           familyi={B\bibinitperiod},
           given={Christos},
           giveni={C\bibinitperiod}}}%
        {{hash=2eb58cecf753a66a5aa5c394edd43442}{%
           family={Potamianos},
           familyi={P\bibinitperiod},
           given={Alexandros},
           giveni={A\bibinitperiod}}}%
      }
      \name{editor}{3}{}{%
        {{hash=f974925c5c6cca1d67fd604cc9fc9c79}{%
           family={Burstein},
           familyi={B\bibinitperiod},
           given={Jill},
           giveni={J\bibinitperiod}}}%
        {{hash=3aec97177cb69c892f2c8a2d9bc31a10}{%
           family={Doran},
           familyi={D\bibinitperiod},
           given={Christy},
           giveni={C\bibinitperiod}}}%
        {{hash=b47889ad94571547c92970150485798b}{%
           family={Solorio},
           familyi={S\bibinitperiod},
           given={Thamar},
           giveni={T\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Minneapolis, Minnesota}%
      }
      \list{publisher}{1}{%
        {Association for Computational Linguistics}%
      }
      \strng{namehash}{7271497ebbda9714386f51e78ca2c681}
      \strng{fullhash}{7271497ebbda9714386f51e78ca2c681}
      \strng{bibnamehash}{7271497ebbda9714386f51e78ca2c681}
      \strng{authorbibnamehash}{7271497ebbda9714386f51e78ca2c681}
      \strng{authornamehash}{7271497ebbda9714386f51e78ca2c681}
      \strng{authorfullhash}{7271497ebbda9714386f51e78ca2c681}
      \strng{editorbibnamehash}{3ba8abc3fd60f22784bd617fd230d1c6}
      \strng{editornamehash}{3ba8abc3fd60f22784bd617fd230d1c6}
      \strng{editorfullhash}{3ba8abc3fd60f22784bd617fd230d1c6}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A growing number of state-of-the-art transfer learning methods employ language models pretrained on large generic corpora. In this paper we present a conceptually simple and effective transfer learning approach that addresses the problem of catastrophic forgetting. Specifically, we combine the task-specific optimization function with an auxiliary language model objective, which is adjusted during the training process. This preserves language regularities captured by language models, while enabling sufficient adaptation for solving the target task. Our method does not require pretraining or finetuning separate components of the network and we train our models end-to-end in a single step. We present results on a variety of challenging affective and text classification tasks, surpassing well established transfer learning methods with greater level of complexity.}
      \field{booktitle}{Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} and {Short} {Papers})}
      \field{month}{6}
      \field{title}{An {Embarrassingly} {Simple} {Approach} for {Transfer} {Learning} from {Pretrained} {Language} {Models}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \true{nocite}
      \field{pages}{2089\bibrangedash 2095}
      \range{pages}{7}
      \verb{doi}
      \verb 10.18653/v1/N19-1213
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/4UEZKUMU/Chronopoulou et al. - 2019 - An Embarrassingly Simple Approach for Transfer Lea.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://aclanthology.org/N19-1213
      \endverb
      \verb{url}
      \verb https://aclanthology.org/N19-1213
      \endverb
    \endentry
    \entry{Clare1997FunctionalM}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=00c16608929d028ab06e90ad60b37608}{%
           family={Clare},
           familyi={C\bibinitperiod},
           given={Stuart},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{00c16608929d028ab06e90ad60b37608}
      \strng{fullhash}{00c16608929d028ab06e90ad60b37608}
      \strng{bibnamehash}{00c16608929d028ab06e90ad60b37608}
      \strng{authorbibnamehash}{00c16608929d028ab06e90ad60b37608}
      \strng{authornamehash}{00c16608929d028ab06e90ad60b37608}
      \strng{authorfullhash}{00c16608929d028ab06e90ad60b37608}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Functional MRI : Methods and Applications}
      \field{year}{1997}
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:8441926
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:8441926
      \endverb
    \endentry
    \entry{dale_fine-tuning_2024}{misc}{}
      \name{author}{1}{}{%
        {{hash=1dc563c75ea7e611af974cbaa7340fea}{%
           family={Dale},
           familyi={D\bibinitperiod},
           given={Dan},
           giveni={D\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Zenodo}%
      }
      \strng{namehash}{1dc563c75ea7e611af974cbaa7340fea}
      \strng{fullhash}{1dc563c75ea7e611af974cbaa7340fea}
      \strng{bibnamehash}{1dc563c75ea7e611af974cbaa7340fea}
      \strng{authorbibnamehash}{1dc563c75ea7e611af974cbaa7340fea}
      \strng{authornamehash}{1dc563c75ea7e611af974cbaa7340fea}
      \strng{authorfullhash}{1dc563c75ea7e611af974cbaa7340fea}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A PyTorch Lightning extension that enhances model experimentation with flexible fine-tuning schedules.}
      \field{month}{3}
      \field{title}{Fine-{Tuning} {Scheduler}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.5281/zenodo.10780386
      \endverb
      \verb{file}
      \verb Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/9D7X47Y3/10780386.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://zenodo.org/records/10780386
      \endverb
      \verb{url}
      \verb https://zenodo.org/records/10780386
      \endverb
      \keyw{artificial intelligence,deep learning,fine-tuning,finetuning,machine learning}
    \endentry
    \entry{dhollander_diffusion_2016}{incollection}{}
      \name{author}{1}{}{%
        {{hash=d9d0c37e8431eea31a2703b5ab5ec161}{%
           family={Dhollander},
           familyi={D\bibinitperiod},
           given={Thijs},
           giveni={T\bibinitperiod}}}%
      }
      \name{editor}{3}{}{%
        {{hash=2cb5bf6ba938feb62a02e46afa5c212d}{%
           family={Van\bibnamedelima Hecke},
           familyi={V\bibinitperiod\bibinitdelim H\bibinitperiod},
           given={Wim},
           giveni={W\bibinitperiod}}}%
        {{hash=ba9198970f88c4b262a4a83846190a98}{%
           family={Emsell},
           familyi={E\bibinitperiod},
           given={Louise},
           giveni={L\bibinitperiod}}}%
        {{hash=aad9368c18d7108ca49d81a5c8a5d36b}{%
           family={Sunaert},
           familyi={S\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {New York, NY}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{d9d0c37e8431eea31a2703b5ab5ec161}
      \strng{fullhash}{d9d0c37e8431eea31a2703b5ab5ec161}
      \strng{bibnamehash}{d9d0c37e8431eea31a2703b5ab5ec161}
      \strng{authorbibnamehash}{d9d0c37e8431eea31a2703b5ab5ec161}
      \strng{authornamehash}{d9d0c37e8431eea31a2703b5ab5ec161}
      \strng{authorfullhash}{d9d0c37e8431eea31a2703b5ab5ec161}
      \strng{editorbibnamehash}{01ef7be86435b062beaaa4b99fc5a8a4}
      \strng{editornamehash}{01ef7be86435b062beaaa4b99fc5a8a4}
      \strng{editorfullhash}{01ef7be86435b062beaaa4b99fc5a8a4}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The term “diffusion tensor imaging” (DTI) is used on many occasions to informally refer to anything related to diffusion-weighted imaging (DWI). From a formal point of view, however, DTI is the practice of fitting a tensor model to the DWI data. It is one of the simplest ways to model the DWI data that accounts, up to some extent, for the anisotropy in this kind of data. Exploiting this anisotropy is key to obtaining the characteristic directionally encoded color (DEC) maps and tractograms that are typically associated to the practice of DWI in general. Hence, it is not surprising many people use the term “DTI” in very different contexts. In this chapter, we aim to give the reader a feeling for what is really under the hood of the true art of DTI: obtaining these so-called diffusion tensors. What are they actually modeling? And, in this context, what is a tensor anyway? There’s a short and clear answer to this: the diffusion tensor describes the apparent diffusion coefficient (ADC), in function of direction. Hmm… “ADC” you say…?}
      \field{booktitle}{Diffusion {Tensor} {Imaging}: {A} {Practical} {Handbook}}
      \field{isbn}{978-1-4939-3118-7}
      \field{title}{From {Diffusion} to the {Diffusion} {Tensor}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{urldateera}{ce}
      \true{nocite}
      \field{pages}{37\bibrangedash 63}
      \range{pages}{27}
      \verb{doi}
      \verb 10.1007/978-1-4939-3118-7_4
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/RKQUQZES/Dhollander - 2016 - From Diffusion to the Diffusion Tensor.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/978-1-4939-3118-7_4
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/978-1-4939-3118-7_4
      \endverb
      \keyw{Anisotropy,Apparent diffusion coefficient,Eigenvalues,Eigenvectors,Tensor fitting}
    \endentry
    \entry{dumoulin_guide_2018}{misc}{}
      \name{author}{2}{}{%
        {{hash=1328d3ceef6add8461994fc364c664df}{%
           family={Dumoulin},
           familyi={D\bibinitperiod},
           given={Vincent},
           giveni={V\bibinitperiod}}}%
        {{hash=6b5929470a8840e4c6f9b8836bd55286}{%
           family={Visin},
           familyi={V\bibinitperiod},
           given={Francesco},
           giveni={F\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ac3e7f97a270527500aed940113f1070}
      \strng{fullhash}{ac3e7f97a270527500aed940113f1070}
      \strng{bibnamehash}{ac3e7f97a270527500aed940113f1070}
      \strng{authorbibnamehash}{ac3e7f97a270527500aed940113f1070}
      \strng{authornamehash}{ac3e7f97a270527500aed940113f1070}
      \strng{authorfullhash}{ac3e7f97a270527500aed940113f1070}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.}
      \field{month}{1}
      \field{note}{arXiv:1603.07285 [cs, stat]}
      \field{title}{A guide to convolution arithmetic for deep learning}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{file}
      \verb Dumoulin und Visin - 2018 - A guide to convolution arithmetic for deep learnin.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/6U6CPY5E/Dumoulin und Visin - 2018 - A guide to convolution arithmetic for deep learnin.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1603.07285
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1603.07285
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning}
    \endentry
    \entry{falcon_pytorch_2019}{article}{}
      \name{author}{1}{}{%
        {{hash=08e4000cddb78a983761ebf9f3805ddc}{%
           family={Falcon},
           familyi={F\bibinitperiod},
           given={William\bibnamedelima A.},
           giveni={W\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \strng{namehash}{08e4000cddb78a983761ebf9f3805ddc}
      \strng{fullhash}{08e4000cddb78a983761ebf9f3805ddc}
      \strng{bibnamehash}{08e4000cddb78a983761ebf9f3805ddc}
      \strng{authorbibnamehash}{08e4000cddb78a983761ebf9f3805ddc}
      \strng{authornamehash}{08e4000cddb78a983761ebf9f3805ddc}
      \strng{authorfullhash}{08e4000cddb78a983761ebf9f3805ddc}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{GitHub}
      \field{title}{Pytorch lightning}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{3}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb https://cir.nii.ac.jp/crid/1370013168774120069
      \endverb
      \verb{url}
      \verb https://cir.nii.ac.jp/crid/1370013168774120069
      \endverb
    \endentry
    \entry{FilePraezessionsvgWikimediaCommons-2024-04-23}{misc}{}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labeltitlesource}{title}
      \field{day}{23}
      \field{month}{4}
      \field{title}{File:Praezession.svg - Wikimedia Commons}
      \field{urlday}{7}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb :./references/wiki-File:Praezession.svg.html:html
      \endverb
      \verb{urlraw}
      \verb https://commons.wikimedia.org/wiki/File:Praezession.svg
      \endverb
      \verb{url}
      \verb https://commons.wikimedia.org/wiki/File:Praezession.svg
      \endverb
    \endentry
    \entry{friston_statistical_1994}{article}{}
      \name{author}{6}{}{%
        {{hash=8adee722e5b9472a3883aaaa1f9a066d}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={K.\bibnamedelimi J.},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=0c10467b3ffccdf9c972b1b440263e33}{%
           family={Holmes},
           familyi={H\bibinitperiod},
           given={A.\bibnamedelimi P.},
           giveni={A\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=7dbeb33ee3301ff9afe977c05ff845f6}{%
           family={Worsley},
           familyi={W\bibinitperiod},
           given={K.\bibnamedelimi J.},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=b1e7b40b41406918be9c1f0d2fcec43f}{%
           family={Poline},
           familyi={P\bibinitperiod},
           given={J.-P.},
           giveni={J\bibinithyphendelim P\bibinitperiod}}}%
        {{hash=1488153249a28a1d279f091dfb42cf0b}{%
           family={Frith},
           familyi={F\bibinitperiod},
           given={C.\bibnamedelimi D.},
           giveni={C\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=22449f9b5aca041efb3eb36614ed372a}{%
           family={Frackowiak},
           familyi={F\bibinitperiod},
           given={R.\bibnamedelimi S.\bibnamedelimi J.},
           giveni={R\bibinitperiod\bibinitdelim S\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{186104dfba34bfcd34db1d24bc6d1be3}
      \strng{fullhash}{c2686f42a4d7436e1fde52077d6b43f9}
      \strng{bibnamehash}{186104dfba34bfcd34db1d24bc6d1be3}
      \strng{authorbibnamehash}{186104dfba34bfcd34db1d24bc6d1be3}
      \strng{authornamehash}{186104dfba34bfcd34db1d24bc6d1be3}
      \strng{authorfullhash}{c2686f42a4d7436e1fde52077d6b43f9}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Statistical parametric maps are spatially extended statistical processes that are used to test hypotheses about regionally specific effects in neuroimaging data. The most established sorts of statistical parametric maps (e.g., Friston et al. [1991]: J Cereb Blood Flow Metab 11:690–699; Worsley et al. [1992]: J Cereb Blood Flow Metab 12:900–918) are based on linear models, for example ANCOVA, correlation coefficients and t tests. In the sense that these examples are all special cases of the general linear model it should be possible to implement them (and many others) within a unified framework. We present here a general approach that accomodates most forms of experimental layout and ensuing analysis (designed experiments with fixed effects for factors, covariates and interaction of factors). This approach brings together two well established bodies of theory (the general linear model and the theory of Gaussian fields) to provide a complete and simple framework for the analysis of imaging data. The importance of this framework is twofold: (i) Conceptual and mathematical simplicity, in that the same small number of operational equations is used irrespective of the complexity of the experiment or nature of the statistical model and (ii) the generality of the framework provides for great latitude in experimental design and analysis. © 1995 Wiley-Liss, Inc.}
      \field{issn}{1097-0193}
      \field{journaltitle}{Human Brain Mapping}
      \field{number}{4}
      \field{shorttitle}{Statistical parametric maps in functional imaging}
      \field{title}{Statistical parametric maps in functional imaging: {A} general linear approach}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{2}
      \field{year}{1994}
      \field{urldateera}{ce}
      \field{pages}{189\bibrangedash 210}
      \range{pages}{22}
      \verb{doi}
      \verb 10.1002/hbm.460020402
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/SPVR5RAK/Friston et al. - 1994 - Statistical parametric maps in functional imaging.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/LV36GSMF/hbm.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.460020402
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.460020402
      \endverb
      \keyw{analysis of variance,functional anatomy,functional imaging,Gaussian fields,general linear model,statistical parametric maps,statistics}
    \endentry
    \entry{ganter_steady_2006}{article}{}
      \name{author}{1}{}{%
        {{hash=ff920f5d86f79295bf523495ff0ff3e0}{%
           family={Ganter},
           familyi={G\bibinitperiod},
           given={Carl},
           giveni={C\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{ff920f5d86f79295bf523495ff0ff3e0}
      \strng{fullhash}{ff920f5d86f79295bf523495ff0ff3e0}
      \strng{bibnamehash}{ff920f5d86f79295bf523495ff0ff3e0}
      \strng{authorbibnamehash}{ff920f5d86f79295bf523495ff0ff3e0}
      \strng{authornamehash}{ff920f5d86f79295bf523495ff0ff3e0}
      \strng{authorfullhash}{ff920f5d86f79295bf523495ff0ff3e0}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Spoiled gradient echo sequences can only reach a homogeneous steady state if sufficiently strong crusher gradients are used in combination with RF phase cycling (RF spoiling). However, the signal depends quite sensitively on the chosen phase increment ϕ and—lacking analytical solutions—numerical simulations must be used to study the transient and steady-state magnetization. For the steady state an exact analytical solution is derived, which holds for arbitrary sequence and tissue parameters. Besides a considerably improved computation performance, the analytical approach enables a better understanding of the complicated dependence on ϕ. For short repetition times (TR) the regime of small ϕ turns out to be particularly interesting: It is shown that the typical ϕc, where RF spoiling starts to become effective, is essentially inversely proportional to T2. This tissue dependence implies that contrasts can be considerably larger with partial spoiling (ϕ ≈ ϕc) than with conventional RF spoiling (ϕ ≫ ϕc). As an example, the uptake of contrast agents in tissues is investigated. For typical parameters a considerably improved contrast enhancement can be obtained, both theoretically and experimentally. Magn Reson Med, 2006. © 2005 Wiley-Liss, Inc.}
      \field{issn}{1522-2594}
      \field{journaltitle}{Magnetic Resonance in Medicine}
      \field{number}{1}
      \field{shorttitle}{Steady state of gradient echo sequences with radiofrequency phase cycling}
      \field{title}{Steady state of gradient echo sequences with radiofrequency phase cycling: {Analytical} solution, contrast enhancement with partial spoiling}
      \field{urlday}{8}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{55}
      \field{year}{2006}
      \field{urldateera}{ce}
      \field{pages}{98\bibrangedash 107}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1002/mrm.20736
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/58GXFUV5/Ganter - 2006 - Steady state of gradient echo sequences with radio.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/RU93XKXG/mrm.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.20736
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.20736
      \endverb
      \keyw{phase cycling,rapid imaging,RF spoiling,spoiled gradient echo,steady state}
    \endentry
    \entry{garyfallidis_dipy_2014}{article}{}
      \name{author}{7}{}{%
        {{hash=3bc0e9c1e8a2e07e842b9da60db9e2e4}{%
           family={Garyfallidis},
           familyi={G\bibinitperiod},
           given={Eleftherios},
           giveni={E\bibinitperiod}}}%
        {{hash=626cc151613864abeb653c0d8172d98c}{%
           family={Brett},
           familyi={B\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=a8662b066dcbff449a2f7e6223495f98}{%
           family={Amirbekian},
           familyi={A\bibinitperiod},
           given={Bagrat},
           giveni={B\bibinitperiod}}}%
        {{hash=848bbb8a883bec42d46ee442da523381}{%
           family={Rokem},
           familyi={R\bibinitperiod},
           given={Ariel},
           giveni={A\bibinitperiod}}}%
        {{hash=425d5dfa44ff351a41168d777fd2dca8}{%
           family={Van\bibnamedelimb Der\bibnamedelima Walt},
           familyi={V\bibinitperiod\bibinitdelim D\bibinitperiod\bibinitdelim W\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
        {{hash=40a0f5eaa96f93cee51c143158223658}{%
           family={Descoteaux},
           familyi={D\bibinitperiod},
           given={Maxime},
           giveni={M\bibinitperiod}}}%
        {{hash=1386d696657e90c3df96b57e4b83ac92}{%
           family={Nimmo-Smith},
           familyi={N\bibinithyphendelim S\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {English}%
      }
      \strng{namehash}{dfe25afe741eb7cad246e42514067a61}
      \strng{fullhash}{d55337a80cb0192bbc99359676e5a2b5}
      \strng{bibnamehash}{dfe25afe741eb7cad246e42514067a61}
      \strng{authorbibnamehash}{dfe25afe741eb7cad246e42514067a61}
      \strng{authornamehash}{dfe25afe741eb7cad246e42514067a61}
      \strng{authorfullhash}{d55337a80cb0192bbc99359676e5a2b5}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Diffusion Imaging in Python (Dipy) is a free and open source software projectfor the analysis of data from diffusion magnetic resonance imaging (dMRI)experiments. dMRI is an application of MRI that can be used to measurestructural features of brain white matter. Many methods have been developed touse dMRI data to model the local configuration of white matter nerve fiberbundles and infer the trajectory of bundles connecting different parts of thebrain.Dipy gathers implementations of many different methods in dMRI, including:diffusion signal pre-processing; reconstruction of diffusion distributions inindividual voxels; fiber tractography and fiber track post-processing, analysisand visualization. Dipy aims to provide transparent implementations forall the different steps of dMRI analysis with a uniform programming interface.We have implemented classical signal reconstruction techniques, such as thediffusion tensor model and deterministic fiber tractography. In addition,cutting edge novel reconstruction techniques are implemented, such asconstrained spherical deconvolution and diffusion spectrum imaging withdeconvolution, as well as methods for probabilistic tracking and originalmethods for tractography clustering. Many additional utility functions areprovided to calculate various statistics, informative visualizations, as wellas file-handling routines to assist in the development and use of noveltechniques.In contrast to many other scientific software projects, Dipy is not beingdeveloped by a single research group. Rather, it is an open project thatencourages contributions from any scientist/developer through GitHub and opendiscussions on the project mailing list. Consequently, Dipy today has aninternational team of contributors, spanning seven different academic institutionsin five countries and three continents, which is still growing.}
      \field{issn}{1662-5196}
      \field{journaltitle}{Frontiers in Neuroinformatics}
      \field{month}{2}
      \field{note}{Publisher: Frontiers}
      \field{title}{Dipy, a library for the analysis of diffusion {MRI} data}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{8}
      \field{year}{2014}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.3389/fninf.2014.00008
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/IP74J49M/Garyfallidis et al. - 2014 - Dipy, a library for the analysis of diffusion MRI .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.frontiersin.org/articles/10.3389/fninf.2014.00008
      \endverb
      \verb{url}
      \verb https://www.frontiersin.org/articles/10.3389/fninf.2014.00008
      \endverb
      \keyw{clustering,Deterministic Tractography,diffusion MRI,diffusion tensor,fiber tracking,Free Open Source Software,medical imaging,Medical Visualization,Probabilistic Tractography,python,Spherical Deconvolution}
    \endentry
    \entry{gencay_pricing_2001}{article}{}
      \name{author}{2}{}{%
        {{hash=5ccc2a2004a738566cad9e9a3a15f039}{%
           family={Gencay},
           familyi={G\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod}}}%
        {{hash=4179744d04becbb5470c3ee5de81f435}{%
           family={Qi},
           familyi={Q\bibinitperiod},
           given={Min},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{011bda54a344737613ba9528580f4683}
      \strng{fullhash}{011bda54a344737613ba9528580f4683}
      \strng{bibnamehash}{011bda54a344737613ba9528580f4683}
      \strng{authorbibnamehash}{011bda54a344737613ba9528580f4683}
      \strng{authornamehash}{011bda54a344737613ba9528580f4683}
      \strng{authorfullhash}{011bda54a344737613ba9528580f4683}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We study the effectiveness of cross validation, Bayesian regularization, early stopping, and bagging to mitigate overfitting and improving generalization for pricing and hedging derivative securities with daily S\&P 500 index daily call options from January 1988 to December 1993. Our results indicate that Bayesian regularization can generate significantly smaller pricing and delta-hedging errors than the baseline neural-network (NN) model and the Black-Scholes model for some years. While early stopping does not affect the pricing errors, it significantly reduces the hedging error (HE) in four of the six years we investigated. Although computationally most demanding, bagging seems to provide the most accurate pricing and delta hedging. Furthermore, the standard deviation of the MSPE of bagging is far less than that of the baseline model in all six years, and the standard deviation of the average HE of bagging is far less than that of the baseline model in five out of six years. We conclude that they be used at least in cases when no appropriate hints are available.}
      \field{issn}{1941-0093}
      \field{journaltitle}{IEEE Transactions on Neural Networks}
      \field{month}{7}
      \field{note}{Conference Name: IEEE Transactions on Neural Networks}
      \field{number}{4}
      \field{shorttitle}{Pricing and hedging derivative securities with neural networks}
      \field{title}{Pricing and hedging derivative securities with neural networks: {Bayesian} regularization, early stopping, and bagging}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{12}
      \field{year}{2001}
      \field{urldateera}{ce}
      \field{pages}{726\bibrangedash 734}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1109/72.935086
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/home/someusername/workspace/UNet-bSSFP/lit/storage/DPUCZB4V/935086.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/abstract/document/935086
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/abstract/document/935086
      \endverb
      \keyw{Bagging,Bayesian methods,Convergence,Councils,Medical diagnosis,Neural networks,Parametric statistics,Pattern recognition,Pricing,Robustness}
    \endentry
    \entry{gholamalinezhad_pooling_nodate}{article}{}
      \name{author}{2}{}{%
        {{hash=0b3c01994b61f8f656a866a476ea2b1e}{%
           family={Gholamalinezhad},
           familyi={G\bibinitperiod},
           given={Hossein},
           giveni={H\bibinitperiod}}}%
        {{hash=e194d67ba0eeeca57ddde433961fb2e7}{%
           family={Khosravi},
           familyi={K\bibinitperiod},
           given={Hossein},
           giveni={H\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{cc7eb1b537a54c10122f4ca80baf1954}
      \strng{fullhash}{cc7eb1b537a54c10122f4ca80baf1954}
      \strng{bibnamehash}{cc7eb1b537a54c10122f4ca80baf1954}
      \strng{authorbibnamehash}{cc7eb1b537a54c10122f4ca80baf1954}
      \strng{authornamehash}{cc7eb1b537a54c10122f4ca80baf1954}
      \strng{authorfullhash}{cc7eb1b537a54c10122f4ca80baf1954}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Nowadays, Deep Neural Networks are among the main tools used in various sciences. Convolutional Neural Network is a special type of DNN consisting of several convolution layers, each followed by an activation function and a pooling layer. The pooling layer is an important layer that executes the down-sampling on the feature maps coming from the previous layer and produces new feature maps with a condensed resolution. This layer drastically reduces the spatial dimension of input. It serves two main purposes. The first is to reduce the number of parameters or weights, thus lessening the computational cost. The second is to control the overfitting of the network. An ideal pooling method is expected to extract only useful information and discard irrelevant details. There are a lot of methods for the implementation of pooling operation in Deep Neural Networks. In this paper, we reviewed some of the famous and useful pooling methods.}
      \field{title}{Pooling {Methods} in {Deep} {Neural} {Networks}, a {Review}}
      \verb{file}
      \verb Gholamalinezhad und Khosravi - Pooling Methods in Deep Neural Networks, a Review.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/AYMIJMWC/Gholamalinezhad und Khosravi - Pooling Methods in Deep Neural Networks, a Review.pdf:application/pdf
      \endverb
    \endentry
    \entry{glorot_understanding_2010}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=0b3943c3bfdbb5867b3760f7c7d488c2}{%
           family={Glorot},
           familyi={G\bibinitperiod},
           given={Xavier},
           giveni={X\bibinitperiod}}}%
        {{hash=40a8e4774982146adc2688546f54efb2}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Yoshua},
           giveni={Y\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{2}{%
        {JMLR Workshop}%
        {Conference Proceedings}%
      }
      \strng{namehash}{02af15243279c938a0a5ca766835bcd4}
      \strng{fullhash}{02af15243279c938a0a5ca766835bcd4}
      \strng{bibnamehash}{02af15243279c938a0a5ca766835bcd4}
      \strng{authorbibnamehash}{02af15243279c938a0a5ca766835bcd4}
      \strng{authornamehash}{02af15243279c938a0a5ca766835bcd4}
      \strng{authorfullhash}{02af15243279c938a0a5ca766835bcd4}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.}
      \field{booktitle}{Proceedings of the {Thirteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}}
      \field{month}{3}
      \field{note}{ISSN: 1938-7228}
      \field{title}{Understanding the difficulty of training deep feedforward neural networks}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2010}
      \field{urldateera}{ce}
      \field{pages}{249\bibrangedash 256}
      \range{pages}{8}
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/Q8MLKVNV/Glorot und Bengio - 2010 - Understanding the difficulty of training deep feed.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://proceedings.mlr.press/v9/glorot10a.html
      \endverb
      \verb{url}
      \verb https://proceedings.mlr.press/v9/glorot10a.html
      \endverb
    \endentry
    \entry{goodfellow_deep_2016}{book}{}
      \name{author}{3}{}{%
        {{hash=5d2585c11210cf1d4512e6e0a03ec315}{%
           family={Goodfellow},
           familyi={G\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod}}}%
        {{hash=40a8e4774982146adc2688546f54efb2}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Yoshua},
           giveni={Y\bibinitperiod}}}%
        {{hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {MIT Press}%
      }
      \strng{namehash}{3ae53fe582e8a815b118d26947eaa326}
      \strng{fullhash}{3ae53fe582e8a815b118d26947eaa326}
      \strng{bibnamehash}{3ae53fe582e8a815b118d26947eaa326}
      \strng{authorbibnamehash}{3ae53fe582e8a815b118d26947eaa326}
      \strng{authornamehash}{3ae53fe582e8a815b118d26947eaa326}
      \strng{authorfullhash}{3ae53fe582e8a815b118d26947eaa326}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.“Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.”—Elon Musk, cochair of OpenAI; cofounder and CEO of Tesla and SpaceXDeep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.}
      \field{isbn}{978-0-262-33737-3}
      \field{month}{11}
      \field{title}{Deep {Learning}}
      \field{year}{2016}
      \verb{file}
      \verb Goodfellow et al. - 2016 - Deep Learning.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/QT3DRWC4/Goodfellow et al. - 2016 - Deep Learning.pdf:application/pdf
      \endverb
      \keyw{Computers / Artificial Intelligence / General,Computers / Computer Science,Computers / Data Science / Machine Learning}
    \endentry
    \entry{goodfellow_generative_2020}{article}{}
      \name{author}{8}{}{%
        {{hash=5d2585c11210cf1d4512e6e0a03ec315}{%
           family={Goodfellow},
           familyi={G\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod}}}%
        {{hash=a341d25f80a8118cdbb90b272adc8b4f}{%
           family={Pouget-Abadie},
           familyi={P\bibinithyphendelim A\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
        {{hash=9e80f4779b032f68a6106e1424345450}{%
           family={Mirza},
           familyi={M\bibinitperiod},
           given={Mehdi},
           giveni={M\bibinitperiod}}}%
        {{hash=743dd6cdaa6639320289d219d351d7b7}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Bing},
           giveni={B\bibinitperiod}}}%
        {{hash=e8151f1b8f85a048cacb34f374ec922b}{%
           family={Warde-Farley},
           familyi={W\bibinithyphendelim F\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=9ca00ffd7cc35f7cfb8f698aa9239c76}{%
           family={Ozair},
           familyi={O\bibinitperiod},
           given={Sherjil},
           giveni={S\bibinitperiod}}}%
        {{hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod}}}%
        {{hash=40a8e4774982146adc2688546f54efb2}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Yoshua},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{d17e6557c5836d2d978179999ea1037f}
      \strng{fullhash}{fa2b4fb373e75fcf07b4b987e4507545}
      \strng{bibnamehash}{d17e6557c5836d2d978179999ea1037f}
      \strng{authorbibnamehash}{d17e6557c5836d2d978179999ea1037f}
      \strng{authornamehash}{d17e6557c5836d2d978179999ea1037f}
      \strng{authorfullhash}{fa2b4fb373e75fcf07b4b987e4507545}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.}
      \field{issn}{0001-0782}
      \field{journaltitle}{Communications of the ACM}
      \field{month}{10}
      \field{number}{11}
      \field{title}{Generative adversarial networks}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{63}
      \field{year}{2020}
      \field{urldateera}{ce}
      \field{pages}{139\bibrangedash 144}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1145/3422622
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/B39R66QC/Goodfellow et al. - 2020 - Generative adversarial networks.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://dl.acm.org/doi/10.1145/3422622
      \endverb
      \verb{url}
      \verb https://dl.acm.org/doi/10.1145/3422622
      \endverb
    \endentry
    \entry{gorgolewski_brain_2016}{article}{}
      \name{author}{27}{}{%
        {{hash=37fd6602fafa336c9f4f082ecd471b6c}{%
           family={Gorgolewski},
           familyi={G\bibinitperiod},
           given={Krzysztof\bibnamedelima J.},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=3325e05978ab33098a85fc07dd207104}{%
           family={Auer},
           familyi={A\bibinitperiod},
           given={Tibor},
           giveni={T\bibinitperiod}}}%
        {{hash=c7172dd45e3be68cbaaa4b3985f2e733}{%
           family={Calhoun},
           familyi={C\bibinitperiod},
           given={Vince\bibnamedelima D.},
           giveni={V\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=44fd334a21edae5fe18eda9d18695bde}{%
           family={Craddock},
           familyi={C\bibinitperiod},
           given={R.\bibnamedelimi Cameron},
           giveni={R\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=a6496ab1152f6176833d0c89cc43ff2b}{%
           family={Das},
           familyi={D\bibinitperiod},
           given={Samir},
           giveni={S\bibinitperiod}}}%
        {{hash=b141e77c571a92e34089ba18de0324f8}{%
           family={Duff},
           familyi={D\bibinitperiod},
           given={Eugene\bibnamedelima P.},
           giveni={E\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=bc7677808561fd1db41e55673446b2df}{%
           family={Flandin},
           familyi={F\bibinitperiod},
           given={Guillaume},
           giveni={G\bibinitperiod}}}%
        {{hash=76dba40c9142166c5540f708b967f13d}{%
           family={Ghosh},
           familyi={G\bibinitperiod},
           given={Satrajit\bibnamedelima S.},
           giveni={S\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=40b974bfe49f775d2bae3fa1e9366960}{%
           family={Glatard},
           familyi={G\bibinitperiod},
           given={Tristan},
           giveni={T\bibinitperiod}}}%
        {{hash=e2fb284cc447dda0b361d24f661475ce}{%
           family={Halchenko},
           familyi={H\bibinitperiod},
           given={Yaroslav\bibnamedelima O.},
           giveni={Y\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=d95e73a1a075e922479f50bf3fa21bc4}{%
           family={Handwerker},
           familyi={H\bibinitperiod},
           given={Daniel\bibnamedelima A.},
           giveni={D\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=3f769f6f38f10ce050aff0d54f58526e}{%
           family={Hanke},
           familyi={H\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=c3113b791dddd7f003a4f74ba1c1eff0}{%
           family={Keator},
           familyi={K\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=de91480b7e7e120166a7cd3909afbbfc}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Xiangrui},
           giveni={X\bibinitperiod}}}%
        {{hash=c255427329cb19a2fee07506cbe4188f}{%
           family={Michael},
           familyi={M\bibinitperiod},
           given={Zachary},
           giveni={Z\bibinitperiod}}}%
        {{hash=2ea68108772ac283b0dfa813e1183589}{%
           family={Maumet},
           familyi={M\bibinitperiod},
           given={Camille},
           giveni={C\bibinitperiod}}}%
        {{hash=3f00e08f9637b590dcf017a51a8ee23a}{%
           family={Nichols},
           familyi={N\bibinitperiod},
           given={B.\bibnamedelimi Nolan},
           giveni={B\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=941382c976b0fb8a5ca28a910a748a0b}{%
           family={Nichols},
           familyi={N\bibinitperiod},
           given={Thomas\bibnamedelima E.},
           giveni={T\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=b68061e9a0a36c1a2b7f03300bb3ba01}{%
           family={Pellman},
           familyi={P\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
        {{hash=7e567d51746021a736084a5d361744cd}{%
           family={Poline},
           familyi={P\bibinitperiod},
           given={Jean-Baptiste},
           giveni={J\bibinithyphendelim B\bibinitperiod}}}%
        {{hash=848bbb8a883bec42d46ee442da523381}{%
           family={Rokem},
           familyi={R\bibinitperiod},
           given={Ariel},
           giveni={A\bibinitperiod}}}%
        {{hash=8993343deb2a35fcc27f12496369532b}{%
           family={Schaefer},
           familyi={S\bibinitperiod},
           given={Gunnar},
           giveni={G\bibinitperiod}}}%
        {{hash=20bcea7098f2727067bd6b7f46818d3c}{%
           family={Sochat},
           familyi={S\bibinitperiod},
           given={Vanessa},
           giveni={V\bibinitperiod}}}%
        {{hash=efbce5368422c93667c67ef240b056e9}{%
           family={Triplett},
           familyi={T\bibinitperiod},
           given={William},
           giveni={W\bibinitperiod}}}%
        {{hash=101a42f9d9fccd6d842d2d58fa7d29f6}{%
           family={Turner},
           familyi={T\bibinitperiod},
           given={Jessica\bibnamedelima A.},
           giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=cfa3239dded54488f9a82a5718d5b927}{%
           family={Varoquaux},
           familyi={V\bibinitperiod},
           given={Gaël},
           giveni={G\bibinitperiod}}}%
        {{hash=21ffb9bf6762df0fb232215885be17e1}{%
           family={Poldrack},
           familyi={P\bibinitperiod},
           given={Russell\bibnamedelima A.},
           giveni={R\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{a4f1894bca1d05414f4ba2d32db7cfb7}
      \strng{fullhash}{19f3b4aa0080d893747d616f4084620d}
      \strng{bibnamehash}{a4f1894bca1d05414f4ba2d32db7cfb7}
      \strng{authorbibnamehash}{a4f1894bca1d05414f4ba2d32db7cfb7}
      \strng{authornamehash}{a4f1894bca1d05414f4ba2d32db7cfb7}
      \strng{authorfullhash}{19f3b4aa0080d893747d616f4084620d}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The development of magnetic resonance imaging (MRI) techniques has defined modern neuroimaging. Since its inception, tens of thousands of studies using techniques such as functional MRI and diffusion weighted imaging have allowed for the non-invasive study of the brain. Despite the fact that MRI is routinely used to obtain data for neuroscience research, there has been no widely adopted standard for organizing and describing the data collected in an imaging experiment. This renders sharing and reusing data (within or between labs) difficult if not impossible and unnecessarily complicates the application of automatic pipelines and quality assurance protocols. To solve this problem, we have developed the Brain Imaging Data Structure (BIDS), a standard for organizing and describing MRI datasets. The BIDS standard uses file formats compatible with existing software, unifies the majority of practices already common in the field, and captures the metadata necessary for most common data processing operations.}
      \field{issn}{2052-4463}
      \field{journaltitle}{Scientific Data}
      \field{month}{6}
      \field{note}{Publisher: Nature Publishing Group}
      \field{number}{1}
      \field{title}{The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments}
      \field{urlday}{12}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{3}
      \field{year}{2016}
      \field{urldateera}{ce}
      \field{pages}{160044}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1038/sdata.2016.44
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/4G3HD4EZ/Gorgolewski et al. - 2016 - The brain imaging data structure, a format for org.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.nature.com/articles/sdata201644
      \endverb
      \verb{url}
      \verb https://www.nature.com/articles/sdata201644
      \endverb
      \keyw{Data publication and archiving,Research data}
    \endentry
    \entry{grigoryev_when_2021}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=29a79315c025f2c516603511dbcf15a4}{%
           family={Grigoryev},
           familyi={G\bibinitperiod},
           given={Timofey},
           giveni={T\bibinitperiod}}}%
        {{hash=241aaf39d02a12eaf63714760ef624fa}{%
           family={Voynov},
           familyi={V\bibinitperiod},
           given={Andrey},
           giveni={A\bibinitperiod}}}%
        {{hash=799a6bc499428a859c0cfe734a21bdbb}{%
           family={Babenko},
           familyi={B\bibinitperiod},
           given={Artem},
           giveni={A\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{557f77d770d7327a393b638e99206643}
      \strng{fullhash}{557f77d770d7327a393b638e99206643}
      \strng{bibnamehash}{557f77d770d7327a393b638e99206643}
      \strng{authorbibnamehash}{557f77d770d7327a393b638e99206643}
      \strng{authornamehash}{557f77d770d7327a393b638e99206643}
      \strng{authorfullhash}{557f77d770d7327a393b638e99206643}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The literature has proposed several methods to finetune pretrained GANs on new datasets, which typically results in higher performance compared to training from scratch, especially in the limited-data regime. However, despite the apparent empirical benefits of GAN pretraining, its inner mechanisms were not analyzed in-depth, and understanding of its role is not entirely clear. Moreover, the essential practical details, e.g., selecting a proper pretrained GAN checkpoint, currently do not have rigorous grounding and are typically determined by trial and error. This work aims to dissect the process of GAN finetuning. First, we show that initializing the GAN training process by a pretrained checkpoint primarily affects the model's coverage rather than the fidelity of individual samples. Second, we explicitly describe how pretrained generators and discriminators contribute to the finetuning process and explain the previous evidence on the importance of pretraining both of them. Finally, as an immediate practical benefit of our analysis, we describe a simple recipe to choose an appropriate GAN checkpoint that is the most suitable for finetuning to a particular target task. Importantly, for most of the target tasks, Imagenet-pretrained GAN, despite having poor visual quality, appears to be an excellent starting point for finetuning, resembling the typical pretraining scenario of discriminative computer vision models.}
      \field{month}{10}
      \field{title}{When, {Why}, and {Which} {Pretrained} {GANs} {Are} {Useful}?}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2021}
      \field{urldateera}{ce}
      \true{nocite}
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/DEH66NEP/Grigoryev et al. - 2021 - When, Why, and Which Pretrained GANs Are Useful.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://openreview.net/forum?id=4Ycr8oeCoIh
      \endverb
      \verb{url}
      \verb https://openreview.net/forum?id=4Ycr8oeCoIh
      \endverb
    \endentry
    \entry{halliday}{book}{}
      \name{author}{3}{}{%
        {{hash=9d9a6552821ea504ab1a5c767dddff92}{%
           family={Halliday},
           familyi={H\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=8967f5a0664f741b0ef2530a47e698fa}{%
           family={Resnick},
           familyi={R\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
        {{hash=aa8304879d8f7d99c7c4570759b948e2}{%
           family={Walker},
           familyi={W\bibinitperiod},
           given={Jearl},
           giveni={J\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {John Wiley \& Sons}%
      }
      \strng{namehash}{3978689396696961b0bd612b55ccf075}
      \strng{fullhash}{3978689396696961b0bd612b55ccf075}
      \strng{bibnamehash}{3978689396696961b0bd612b55ccf075}
      \strng{authorbibnamehash}{3978689396696961b0bd612b55ccf075}
      \strng{authornamehash}{3978689396696961b0bd612b55ccf075}
      \strng{authorfullhash}{3978689396696961b0bd612b55ccf075}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The 10th edition of Halliday, Resnick and Walkers Fundamentals of Physics provides the perfect solution for teaching a 2 or 3 semester calculus-based physics course, providing instructors with a tool by which they can teach students how to effectively read scientific material, identify fundamental concepts, reason through scientific questions, and solve quantitative problems. The 10th edition builds upon previous editions by offering new features designed to better engage students and support critical thinking. These include NEW Video Illustrations that bring the subject matter to life, NEW Vector Drawing Questions that test students conceptual understanding, and additional multimedia resources (videos and animations) that provide an alternative pathway through the material for those who struggle with reading scientific exposition. WileyPLUS sold separately from text.}
      \field{isbn}{978-1-118-23071-8}
      \field{month}{8}
      \field{note}{Google-Books-ID: HybkAwAAQBAJ}
      \field{title}{Fundamentals of {Physics}}
      \field{year}{2013}
      \verb{file}
      \verb Halliday et al. - 2013 - Fundamentals of Physics.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/9H5Y5TBF/Halliday et al. - 2013 - Fundamentals of Physics.pdf:application/pdf
      \endverb
      \keyw{Science / Physics / General}
    \endentry
    \entry{hargreaves_rapid_2012}{article}{}
      \name{author}{1}{}{%
        {{hash=d74a9d1af3fa23aefe89cfd81f4eb8bb}{%
           family={Hargreaves},
           familyi={H\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{d74a9d1af3fa23aefe89cfd81f4eb8bb}
      \strng{fullhash}{d74a9d1af3fa23aefe89cfd81f4eb8bb}
      \strng{bibnamehash}{d74a9d1af3fa23aefe89cfd81f4eb8bb}
      \strng{authorbibnamehash}{d74a9d1af3fa23aefe89cfd81f4eb8bb}
      \strng{authornamehash}{d74a9d1af3fa23aefe89cfd81f4eb8bb}
      \strng{authorfullhash}{d74a9d1af3fa23aefe89cfd81f4eb8bb}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Gradient echo sequences are widely used in magnetic resonance imaging (MRI) for numerous applications ranging from angiography to perfusion to functional MRI. Compared with spin-echo techniques, the very short repetition times of gradient-echo methods enable very rapid 2D and 3D imaging, but also lead to complicated “steady states.” Signal and contrast behavior can be described graphically and mathematically, and depends strongly on the type of spoiling: fully balanced (no spoiling), gradient spoiling, or RF-spoiling. These spoiling options trade off between high signal and pure T1 contrast while the flip angle also affects image contrast in all cases, both of which can be demonstrated theoretically and in image examples. As with spin-echo sequences, magnetization preparation can be added to gradient-echo sequences to alter image contrast. Gradient echo sequences are widely used for numerous applications such as 3D perfusion imaging, functional MRI, cardiac imaging and MR angiography.}
      \field{issn}{1053-1807}
      \field{journaltitle}{Journal of magnetic resonance imaging : JMRI}
      \field{month}{12}
      \field{number}{6}
      \field{title}{Rapid {Gradient}-{Echo} {Imaging}}
      \field{urlday}{8}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{36}
      \field{year}{2012}
      \field{urldateera}{ce}
      \field{pages}{1300\bibrangedash 1313}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1002/jmri.23742
      \endverb
      \verb{file}
      \verb PubMed Central Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/ZHCE7NKS/Hargreaves - 2012 - Rapid Gradient-Echo Imaging.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3502662/
      \endverb
      \verb{url}
      \verb https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3502662/
      \endverb
    \endentry
    \entry{harris_array_2020}{article}{}
      \name{author}{26}{}{%
        {{hash=db2b4761cc46be347b418e68660c9554}{%
           family={Harris},
           familyi={H\bibinitperiod},
           given={Charles\bibnamedelima R.},
           giveni={C\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=b053969d2c6a9ec8689980fb6463cd56}{%
           family={Millman},
           familyi={M\bibinitperiod},
           given={K.\bibnamedelimi Jarrod},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=9a5a65a789013a8d1e8035ec28df9b6e}{%
           family={Walt},
           familyi={W\bibinitperiod},
           given={Stéfan\bibnamedelima J.},
           giveni={S\bibinitperiod\bibinitdelim J\bibinitperiod},
           prefix={van\bibnamedelima der},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=646fbfe08374cc41c2f9bd971d8c4725}{%
           family={Gommers},
           familyi={G\bibinitperiod},
           given={Ralf},
           giveni={R\bibinitperiod}}}%
        {{hash=18703a2bb6a62484483c193a212da2f8}{%
           family={Virtanen},
           familyi={V\bibinitperiod},
           given={Pauli},
           giveni={P\bibinitperiod}}}%
        {{hash=9fd9ed8466bbb96364ae008f2a665e6e}{%
           family={Cournapeau},
           familyi={C\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=4321feefe3d5715c6fe12639d2a1f7f1}{%
           family={Wieser},
           familyi={W\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=e8d1b0c2bff88b6bf54e2e934e2853f6}{%
           family={Taylor},
           familyi={T\bibinitperiod},
           given={Julian},
           giveni={J\bibinitperiod}}}%
        {{hash=265437a4424f0b845118651d7d04ab93}{%
           family={Berg},
           familyi={B\bibinitperiod},
           given={Sebastian},
           giveni={S\bibinitperiod}}}%
        {{hash=e4d23819637a961e0e598e1c82a8f10d}{%
           family={Smith},
           familyi={S\bibinitperiod},
           given={Nathaniel\bibnamedelima J.},
           giveni={N\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=9ad1d38817acd2f00cb7f324ec7d37ea}{%
           family={Kern},
           familyi={K\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
        {{hash=8ae844f84614690134ff5d8252fdc430}{%
           family={Picus},
           familyi={P\bibinitperiod},
           given={Matti},
           giveni={M\bibinitperiod}}}%
        {{hash=4a22828b76006f42d747b699d2ef5167}{%
           family={Hoyer},
           familyi={H\bibinitperiod},
           given={Stephan},
           giveni={S\bibinitperiod}}}%
        {{hash=10aba85d08ce22d724b21878b93f590a}{%
           family={Kerkwijk},
           familyi={K\bibinitperiod},
           given={Marten\bibnamedelima H.},
           giveni={M\bibinitperiod\bibinitdelim H\bibinitperiod},
           prefix={van},
           prefixi={v\bibinitperiod}}}%
        {{hash=626cc151613864abeb653c0d8172d98c}{%
           family={Brett},
           familyi={B\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=a989405517bbf67ae7b16be1d03c0081}{%
           family={Haldane},
           familyi={H\bibinitperiod},
           given={Allan},
           giveni={A\bibinitperiod}}}%
        {{hash=9517b38a3050d34c03ac479ee122f64a}{%
           family={Río},
           familyi={R\bibinitperiod},
           given={Jaime\bibnamedelima Fernández},
           giveni={J\bibinitperiod\bibinitdelim F\bibinitperiod},
           prefix={del},
           prefixi={d\bibinitperiod}}}%
        {{hash=76256cb9e4c31e0a4744b1b49a6199f4}{%
           family={Wiebe},
           familyi={W\bibinitperiod},
           given={Mark},
           giveni={M\bibinitperiod}}}%
        {{hash=3d6efaaa3d9682e20787eb06ff70a3d7}{%
           family={Peterson},
           familyi={P\bibinitperiod},
           given={Pearu},
           giveni={P\bibinitperiod}}}%
        {{hash=aac4486f60accb8b7db22ef300423e11}{%
           family={Gérard-Marchant},
           familyi={G\bibinithyphendelim M\bibinitperiod},
           given={Pierre},
           giveni={P\bibinitperiod}}}%
        {{hash=22fcbc93c38819e962968aad3e3cba7f}{%
           family={Sheppard},
           familyi={S\bibinitperiod},
           given={Kevin},
           giveni={K\bibinitperiod}}}%
        {{hash=fbb0c40f5d70be8ce47ce9daafdf5749}{%
           family={Reddy},
           familyi={R\bibinitperiod},
           given={Tyler},
           giveni={T\bibinitperiod}}}%
        {{hash=4c7e4c94b846fa41e2fc0a88e0dc656d}{%
           family={Weckesser},
           familyi={W\bibinitperiod},
           given={Warren},
           giveni={W\bibinitperiod}}}%
        {{hash=c588b2e35e75bba896fc5677afb52fa9}{%
           family={Abbasi},
           familyi={A\bibinitperiod},
           given={Hameer},
           giveni={H\bibinitperiod}}}%
        {{hash=52e2684c111b194e1f15fa06b0ce4544}{%
           family={Gohlke},
           familyi={G\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod}}}%
        {{hash=d500f4849030f34359cdb3e1513acf83}{%
           family={Oliphant},
           familyi={O\bibinitperiod},
           given={Travis\bibnamedelima E.},
           giveni={T\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{754b3dec5e203c19b9a5798bbb902222}
      \strng{fullhash}{bba1ae456b2655ba67cf6cee2d142dfc}
      \strng{bibnamehash}{754b3dec5e203c19b9a5798bbb902222}
      \strng{authorbibnamehash}{754b3dec5e203c19b9a5798bbb902222}
      \strng{authornamehash}{754b3dec5e203c19b9a5798bbb902222}
      \strng{authorfullhash}{bba1ae456b2655ba67cf6cee2d142dfc}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves1 and in the first imaging of a black hole2. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.}
      \field{issn}{1476-4687}
      \field{journaltitle}{Nature}
      \field{month}{9}
      \field{note}{Publisher: Nature Publishing Group}
      \field{number}{7825}
      \field{title}{Array programming with {NumPy}}
      \field{urlday}{12}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{585}
      \field{year}{2020}
      \field{urldateera}{ce}
      \field{pages}{357\bibrangedash 362}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1038/s41586-020-2649-2
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/BLWSYZ7X/Harris et al. - 2020 - Array programming with NumPy.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.nature.com/articles/s41586-020-2649-2
      \endverb
      \verb{url}
      \verb https://www.nature.com/articles/s41586-020-2649-2
      \endverb
      \keyw{Computational neuroscience,Computational science,Computer science,Software,Solar physics}
    \endentry
    \entry{he_deep_2016}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod}}}%
        {{hash=5e72bc22dbcf0984c6d113d280e36990}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Xiangyu},
           giveni={X\bibinitperiod}}}%
        {{hash=bb295293acacd54387339079ebbe4ead}{%
           family={Ren},
           familyi={R\bibinitperiod},
           given={Shaoqing},
           giveni={S\bibinitperiod}}}%
        {{hash=f85751488058842b5777c7b4074077b5}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Jian},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{fullhash}{42c4b52dc3a62cebabbc11c73e1afb53}
      \strng{bibnamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authorbibnamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authornamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authorfullhash}{42c4b52dc3a62cebabbc11c73e1afb53}
      \field{extraname}{1}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Deep {Residual} {Learning} for {Image} {Recognition}}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{urldateera}{ce}
      \field{pages}{770\bibrangedash 778}
      \range{pages}{9}
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/TXNCFF9Y/He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html
      \endverb
      \verb{url}
      \verb https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html
      \endverb
    \endentry
    \entry{he_delving_2015}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod}}}%
        {{hash=5e72bc22dbcf0984c6d113d280e36990}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Xiangyu},
           giveni={X\bibinitperiod}}}%
        {{hash=bb295293acacd54387339079ebbe4ead}{%
           family={Ren},
           familyi={R\bibinitperiod},
           given={Shaoqing},
           giveni={S\bibinitperiod}}}%
        {{hash=f85751488058842b5777c7b4074077b5}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Jian},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{fullhash}{42c4b52dc3a62cebabbc11c73e1afb53}
      \strng{bibnamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authorbibnamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authornamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authorfullhash}{42c4b52dc3a62cebabbc11c73e1afb53}
      \field{extraname}{2}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{shorttitle}{Delving {Deep} into {Rectifiers}}
      \field{title}{Delving {Deep} into {Rectifiers}: {Surpassing} {Human}-{Level} {Performance} on {ImageNet} {Classification}}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{1026\bibrangedash 1034}
      \range{pages}{9}
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/PCRYIUEF/He et al. - 2015 - Delving Deep into Rectifiers Surpassing Human-Lev.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://openaccess.thecvf.com/content_iccv_2015/html/He_Delving_Deep_into_ICCV_2015_paper.html
      \endverb
      \verb{url}
      \verb https://openaccess.thecvf.com/content_iccv_2015/html/He_Delving_Deep_into_ICCV_2015_paper.html
      \endverb
    \endentry
    \entry{helenius_diffusion-weighted_2002}{article}{}
      \name{author}{9}{}{%
        {{hash=82cdc62e8424484572b7141705221c2a}{%
           family={Helenius},
           familyi={H\bibinitperiod},
           given={Johanna},
           giveni={J\bibinitperiod}}}%
        {{hash=11c9d2c8c197a0f303597e042aa9b1db}{%
           family={Soinne},
           familyi={S\bibinitperiod},
           given={Lauri},
           giveni={L\bibinitperiod}}}%
        {{hash=e8d4b561cd8dcdea8f8fe2f7d6bd2bc0}{%
           family={Perkiö},
           familyi={P\bibinitperiod},
           given={Jussi},
           giveni={J\bibinitperiod}}}%
        {{hash=e01e7838262186f74cde8d8c0011d544}{%
           family={Salonen},
           familyi={S\bibinitperiod},
           given={Oili},
           giveni={O\bibinitperiod}}}%
        {{hash=86112b9bf2bc59a703cdd088e495599b}{%
           family={Kangasmäki},
           familyi={K\bibinitperiod},
           given={Aki},
           giveni={A\bibinitperiod}}}%
        {{hash=d5ed7cfcd86e635c95b1254f8dc4ec54}{%
           family={Kaste},
           familyi={K\bibinitperiod},
           given={Markku},
           giveni={M\bibinitperiod}}}%
        {{hash=9d5470d2b527b3765d3ba8ebb43e345c}{%
           family={Carano},
           familyi={C\bibinitperiod},
           given={Richard\bibnamedelimb A.\bibnamedelimi D.},
           giveni={R\bibinitperiod\bibinitdelim A\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=f0ff8a700d6bc3961c926c588bfe7617}{%
           family={Aronen},
           familyi={A\bibinitperiod},
           given={Hannu\bibnamedelima J.},
           giveni={H\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=10482b7c025f5613de40e4cd03a1d05a}{%
           family={Tatlisumak},
           familyi={T\bibinitperiod},
           given={Turgut},
           giveni={T\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{50a31ef027e45fcb3dbf65267f22c16a}
      \strng{fullhash}{0f0b28c8955d8d53d8b764b38db0b30a}
      \strng{bibnamehash}{50a31ef027e45fcb3dbf65267f22c16a}
      \strng{authorbibnamehash}{50a31ef027e45fcb3dbf65267f22c16a}
      \strng{authornamehash}{50a31ef027e45fcb3dbf65267f22c16a}
      \strng{authorfullhash}{0f0b28c8955d8d53d8b764b38db0b30a}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{BACKGROUND AND PURPOSE: Few studies have concerned the absolute apparent diffusion coefficient (ADC) values in the normal human brain and the effect of aging on diffusion. Therefore, our purpose was to determine whether the average ADC (ADCav) values in the various regions of the brain differ with age, sex, or hemisphere and to establish reference values of the absolute ADCav for further studies. METHODS: Subjects (40 men and 40 women) were chosen from a healthy population; age groups were 20–34, 35–49, and 50–64 years and 65 years or older (n = 20 each). All subjects were examined with MR imaging, including conventional and diffusion-weighted imaging in three orthogonal directions with two b values (0 and 1000 s/mm2) at 1.5 T. Bilateral ADCav values were determined in 36 regions of interest encompassing the entire brain. RESULTS: ADCav values were highest in the cortical gray matter ([0.89 ± 0.04] × 10−3 mm2/s; range, 0.78–1.09 × 10−3), lower in the deep gray matter ([0.75 ± 0.03] × 10−3 mm2/s; range, 0.64–0.83 × 10−3), and lowest in the white matter ([0.70 ± 0.03] × 10−3 mm2/s; range, 0.62–0.79 × 10−3). The ADCav values did not significantly change with aging, except for an increase in the lateral ventricles. No difference was observed between women and men or between the hemispheres. CONCLUSION: The data reported herein are representative, and the ADCav values can be used for reference in future studies and in clinical settings.}
      \field{issn}{0195-6108, 1936-959X}
      \field{journaltitle}{American Journal of Neuroradiology}
      \field{month}{2}
      \field{note}{Publisher: American Journal of Neuroradiology Section: BRAIN}
      \field{number}{2}
      \field{title}{Diffusion-{Weighted} {MR} {Imaging} in {Normal} {Human} {Brains} in {Various} {Age} {Groups}}
      \field{urlday}{8}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{23}
      \field{year}{2002}
      \field{urldateera}{ce}
      \field{pages}{194\bibrangedash 199}
      \range{pages}{6}
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/TBTSID64/Helenius et al. - 2002 - Diffusion-Weighted MR Imaging in Normal Human Brai.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.ajnr.org/content/23/2/194
      \endverb
      \verb{url}
      \verb https://www.ajnr.org/content/23/2/194
      \endverb
    \endentry
    \entry{heule_triple_2014}{article}{}
      \name{author}{3}{}{%
        {{hash=5ce46428423062d80a85b723425cef79}{%
           family={Heule},
           familyi={H\bibinitperiod},
           given={Rahel},
           giveni={R\bibinitperiod}}}%
        {{hash=ff920f5d86f79295bf523495ff0ff3e0}{%
           family={Ganter},
           familyi={G\bibinitperiod},
           given={Carl},
           giveni={C\bibinitperiod}}}%
        {{hash=bb41146c4a8c0507581de495e5654324}{%
           family={Bieri},
           familyi={B\bibinitperiod},
           given={Oliver},
           giveni={O\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{b73d96a6577bba81fd69ad3407806aaa}
      \strng{fullhash}{b73d96a6577bba81fd69ad3407806aaa}
      \strng{bibnamehash}{b73d96a6577bba81fd69ad3407806aaa}
      \strng{authorbibnamehash}{b73d96a6577bba81fd69ad3407806aaa}
      \strng{authornamehash}{b73d96a6577bba81fd69ad3407806aaa}
      \strng{authorfullhash}{b73d96a6577bba81fd69ad3407806aaa}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Purpose Rapid imaging techniques have attracted increased interest for relaxometry, but none are perfect: they are prone to static (B0) and transmit (B1) field heterogeneities, and commonly biased by T2/T1. The purpose of this study is the development of a rapid T1 and T2 relaxometry method that is completely (T2) or partly (T1) bias-free. Methods A new method is introduced to simultaneously quantify T1 and T2 within one single scan based on a triple echo steady-state (TESS) approach in combination with an iterative golden section search. TESS relaxometry is optimized and evaluated from simulations, in vitro studies, and in vivo experiments. Results It is found that relaxometry with TESS is not biased by T2/T1, insensitive to B0 heterogeneities, and, surprisingly, that TESS-T2 is not affected by B1 field errors. Consequently, excellent correspondence between TESS and reference spin echo data is observed for T2 in vitro at 1.5 T and in vivo at 3 T. Conclusion TESS offers rapid T1 and T2 quantification within one single scan, and in particular B1-insensitive T2 estimation. As a result, the new proposed method is of high interest for fast and reliable high-resolution T2 mapping, especially of the musculoskeletal system at high to ultra-high fields. Magn Reson Med 71:230–237, 2014. © 2013 Wiley Periodicals, Inc.}
      \field{issn}{1522-2594}
      \field{journaltitle}{Magnetic Resonance in Medicine}
      \field{number}{1}
      \field{title}{Triple echo steady-state ({TESS}) relaxometry}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{71}
      \field{year}{2014}
      \field{urldateera}{ce}
      \true{nocite}
      \field{pages}{230\bibrangedash 237}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1002/mrm.24659
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/GL7YSYG6/Heule et al. - 2014 - Triple echo steady-state (TESS) relaxometry.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/TG996RNH/mrm.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.24659
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.24659
      \endverb
      \keyw{fast imaging,quantification,relaxometry,T1,T2,triple echo steady-state}
    \endentry
    \entry{howard_universal_2018}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=5ed422e177c5444b96679479aeed0c51}{%
           family={Howard},
           familyi={H\bibinitperiod},
           given={Jeremy},
           giveni={J\bibinitperiod}}}%
        {{hash=b468248a20d75c52ee742f4592c2569f}{%
           family={Ruder},
           familyi={R\bibinitperiod},
           given={Sebastian},
           giveni={S\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=ea70b44be1920f6e8c379706bc7d047a}{%
           family={Gurevych},
           familyi={G\bibinitperiod},
           given={Iryna},
           giveni={I\bibinitperiod}}}%
        {{hash=e3085b34ce73d4eb1516551aa3eb4beb}{%
           family={Miyao},
           familyi={M\bibinitperiod},
           given={Yusuke},
           giveni={Y\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Melbourne, Australia}%
      }
      \list{publisher}{1}{%
        {Association for Computational Linguistics}%
      }
      \strng{namehash}{7caeb63ea6a1e3558e6f9d46f7f11450}
      \strng{fullhash}{7caeb63ea6a1e3558e6f9d46f7f11450}
      \strng{bibnamehash}{7caeb63ea6a1e3558e6f9d46f7f11450}
      \strng{authorbibnamehash}{7caeb63ea6a1e3558e6f9d46f7f11450}
      \strng{authornamehash}{7caeb63ea6a1e3558e6f9d46f7f11450}
      \strng{authorfullhash}{7caeb63ea6a1e3558e6f9d46f7f11450}
      \strng{editorbibnamehash}{49872d3e2bf9fbad3a0eb3aab98db401}
      \strng{editornamehash}{49872d3e2bf9fbad3a0eb3aab98db401}
      \strng{editorfullhash}{49872d3e2bf9fbad3a0eb3aab98db401}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24\% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100 times more data. We open-source our pretrained models and code.}
      \field{booktitle}{Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})}
      \field{month}{7}
      \field{title}{Universal {Language} {Model} {Fine}-tuning for {Text} {Classification}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \true{nocite}
      \field{pages}{328\bibrangedash 339}
      \range{pages}{12}
      \verb{doi}
      \verb 10.18653/v1/P18-1031
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/4WU8IJDP/Howard and Ruder - 2018 - Universal Language Model Fine-tuning for Text Clas.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://aclanthology.org/P18-1031
      \endverb
      \verb{url}
      \verb https://aclanthology.org/P18-1031
      \endverb
    \endentry
    \entry{huang_simultaneous_2017}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=04ea73cdf1bdad5b2ecfd83c77f6e88e}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Yawen},
           giveni={Y\bibinitperiod}}}%
        {{hash=a19a5e715fda869516c9d9d4ffbfd7f7}{%
           family={Shao},
           familyi={S\bibinitperiod},
           given={Ling},
           giveni={L\bibinitperiod}}}%
        {{hash=2413defb142650e8edf0bcd5608ab789}{%
           family={Frangi},
           familyi={F\bibinitperiod},
           given={Alejandro\bibnamedelima F.},
           giveni={A\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
      }
      \strng{namehash}{69df3ce7a55f146350ed4aa81d5176c0}
      \strng{fullhash}{69df3ce7a55f146350ed4aa81d5176c0}
      \strng{bibnamehash}{69df3ce7a55f146350ed4aa81d5176c0}
      \strng{authorbibnamehash}{69df3ce7a55f146350ed4aa81d5176c0}
      \strng{authornamehash}{69df3ce7a55f146350ed4aa81d5176c0}
      \strng{authorfullhash}{69df3ce7a55f146350ed4aa81d5176c0}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Magnetic Resonance Imaging (MRI) offers high-resolution in vivo imaging and rich functional and anatomical multimodality tissue contrast. In practice, however, there are challenges associated with considerations of scanning costs, patient comfort, and scanning time that constrain how much data can be acquired in clinical or research studies. In this paper, we explore the possibility of generating high-resolution and multimodal images from low-resolution single-modality imagery. We propose the weakly-supervised joint convolutional sparse coding to simultaneously solve the problems of super-resolution (SR) and cross-modality image synthesis. The learning process requires only a few registered multimodal image pairs as the training set. Additionally, the quality of the joint dictionary learning can be improved using a larger set of unpaired images. To combine unpaired data from different image resolutions/modalities, a hetero-domain image alignment term is proposed. Local image neighborhoods are naturally preserved by operating on the whole image domain (as opposed to image patches) and using joint convolutional sparse coding. The paired images are enhanced in the joint learning process with unpaired data and an additional maximum mean discrepancy term, which minimizes the dissimilarity between their feature distributions. Experiments show that the proposed method outperforms state-of-the-art techniques on both SR reconstruction and simultaneous SR and cross-modality synthesis.}
      \field{booktitle}{2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})}
      \field{month}{7}
      \field{note}{ISSN: 1063-6919}
      \field{title}{Simultaneous {Super}-{Resolution} and {Cross}-{Modality} {Synthesis} of {3D} {Medical} {Images} {Using} {Weakly}-{Supervised} {Joint} {Convolutional} {Sparse} {Coding}}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2017}
      \field{urldateera}{ce}
      \field{pages}{5787\bibrangedash 5796}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/CVPR.2017.613
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/home/someusername/workspace/UNet-bSSFP/lit/storage/F3F2G3Z6/8100096.html:text/html;Volltext:/home/someusername/workspace/UNet-bSSFP/lit/storage/GUSHAH8S/Huang et al. - 2017 - Simultaneous Super-Resolution and Cross-Modality S.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8100096
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8100096
      \endverb
      \keyw{Biomedical imaging,Convolutional codes,Image coding,Image reconstruction,Image resolution,Three-dimensional displays,Training}
    \endentry
    \entry{huisman_diffusion-weighted_2010}{article}{}
      \name{author}{1}{}{%
        {{hash=cbaefc3c8c10e2e034fd6a7b092d242a}{%
           family={Huisman},
           familyi={H\bibinitperiod},
           given={T.A.G.M.},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{cbaefc3c8c10e2e034fd6a7b092d242a}
      \strng{fullhash}{cbaefc3c8c10e2e034fd6a7b092d242a}
      \strng{bibnamehash}{cbaefc3c8c10e2e034fd6a7b092d242a}
      \strng{authorbibnamehash}{cbaefc3c8c10e2e034fd6a7b092d242a}
      \strng{authornamehash}{cbaefc3c8c10e2e034fd6a7b092d242a}
      \strng{authorfullhash}{cbaefc3c8c10e2e034fd6a7b092d242a}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Diffusion-weighted and diffusion tensor imaging (DWI/DTI) has revolutionized clinical neuroimaging. Pathology may be detected earlier and with greater specificity than with conventional magnetic resonance imaging sequences. In addition, DWI/DTI allows exploring the microarchitecture of the brain. A detailed knowledge of the basics of DWI/DTI is mandatory to better understand pathology encountered and to avoid misinterpretation of typical DWI/DTI artifacts. This article reviews the basic physics of DWI/DTI exemplified by several classical clinical cases.}
      \field{issn}{1740-5025}
      \field{journaltitle}{Cancer Imaging}
      \field{month}{10}
      \field{number}{1A}
      \field{title}{Diffusion-weighted and diffusion tensor imaging of the brain, made easy}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{10}
      \field{year}{2010}
      \field{urldateera}{ce}
      \true{nocite}
      \field{pages}{S163\bibrangedash S171}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1102/1470-7330.2010.9023
      \endverb
      \verb{file}
      \verb PubMed Central Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/DW4YP9RE/Huisman - 2010 - Diffusion-weighted and diffusion tensor imaging of.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2967146/
      \endverb
      \verb{url}
      \verb https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2967146/
      \endverb
    \endentry
    \entry{hunter_matplotlib_2007}{article}{}
      \name{author}{1}{}{%
        {{hash=a2f53dcc6bb05a06b8ad94176f80fe26}{%
           family={Hunter},
           familyi={H\bibinitperiod},
           given={John\bibnamedelima D.},
           giveni={J\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
      }
      \strng{namehash}{a2f53dcc6bb05a06b8ad94176f80fe26}
      \strng{fullhash}{a2f53dcc6bb05a06b8ad94176f80fe26}
      \strng{bibnamehash}{a2f53dcc6bb05a06b8ad94176f80fe26}
      \strng{authorbibnamehash}{a2f53dcc6bb05a06b8ad94176f80fe26}
      \strng{authornamehash}{a2f53dcc6bb05a06b8ad94176f80fe26}
      \strng{authorfullhash}{a2f53dcc6bb05a06b8ad94176f80fe26}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Matplotlib is a 2D graphics package used for Python for application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems}
      \field{issn}{1558-366X}
      \field{journaltitle}{Computing in Science \& Engineering}
      \field{month}{5}
      \field{note}{Conference Name: Computing in Science \& Engineering}
      \field{number}{3}
      \field{shorttitle}{Matplotlib}
      \field{title}{Matplotlib: {A} {2D} {Graphics} {Environment}}
      \field{urlday}{12}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{9}
      \field{year}{2007}
      \field{urldateera}{ce}
      \field{pages}{90\bibrangedash 95}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/MCSE.2007.55
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/home/someusername/workspace/UNet-bSSFP/lit/storage/5DS93IUD/4160265.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/4160265
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/4160265
      \endverb
      \keyw{application development,Computer languages,Equations,Graphical user interfaces,Graphics,Image generation,Interpolation,Operating systems,Packaging,Programming profession,Python,scientific programming,scripting languages,User interfaces}
    \endentry
    \entry{ioffe_batch_2015}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=5543e82359e26b035efc009cb3efff9d}{%
           family={Ioffe},
           familyi={I\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod}}}%
        {{hash=ed568d9c3bb059e6bf22899fbf170f86}{%
           family={Szegedy},
           familyi={S\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Lille, France}%
      }
      \list{publisher}{1}{%
        {JMLR.org}%
      }
      \strng{namehash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{fullhash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{bibnamehash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{authorbibnamehash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{authornamehash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{authorfullhash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.}
      \field{booktitle}{Proceedings of the 32nd {International} {Conference} on {International} {Conference} on {Machine} {Learning} - {Volume} 37}
      \field{month}{7}
      \field{series}{{ICML}'15}
      \field{shorttitle}{Batch normalization}
      \field{title}{Batch normalization: accelerating deep network training by reducing internal covariate shift}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{448\bibrangedash 456}
      \range{pages}{9}
    \endentry
    \entry{isola_image-image_2017}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=cae9f806bc99a5f19fadea538fc2db04}{%
           family={Isola},
           familyi={I\bibinitperiod},
           given={Phillip},
           giveni={P\bibinitperiod}}}%
        {{hash=9fbb4b31963f07f34a13b375b4997338}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Jun-Yan},
           giveni={J\bibinithyphendelim Y\bibinitperiod}}}%
        {{hash=fbb5fac74ecd20c0f90a3884d6a93cdf}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Tinghui},
           giveni={T\bibinitperiod}}}%
        {{hash=5a663b27298722834a8cf09bb93d8c94}{%
           family={Efros},
           familyi={E\bibinitperiod},
           given={Alexei\bibnamedelima A.},
           giveni={A\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \strng{namehash}{dd9b478c7b76d20d978868251cf3ad35}
      \strng{fullhash}{18664a8c078ce7dff4c499de4e40bf2f}
      \strng{bibnamehash}{dd9b478c7b76d20d978868251cf3ad35}
      \strng{authorbibnamehash}{dd9b478c7b76d20d978868251cf3ad35}
      \strng{authornamehash}{dd9b478c7b76d20d978868251cf3ad35}
      \strng{authorfullhash}{18664a8c078ce7dff4c499de4e40bf2f}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Image-{To}-{Image} {Translation} {With} {Conditional} {Adversarial} {Networks}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2017}
      \field{urldateera}{ce}
      \field{pages}{1125\bibrangedash 1134}
      \range{pages}{10}
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/7NVTJX39/Isola et al. - 2017 - Image-To-Image Translation With Conditional Advers.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://openaccess.thecvf.com/content_cvpr_2017/html/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.html
      \endverb
      \verb{url}
      \verb https://openaccess.thecvf.com/content_cvpr_2017/html/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.html
      \endverb
    \endentry
    \entry{izmailov_averaging_2019}{misc}{}
      \name{author}{5}{}{%
        {{hash=510d675b8d71e867463f4025e0f66971}{%
           family={Izmailov},
           familyi={I\bibinitperiod},
           given={Pavel},
           giveni={P\bibinitperiod}}}%
        {{hash=5ee4a652a0fe093122681236d4d4cd29}{%
           family={Podoprikhin},
           familyi={P\bibinitperiod},
           given={Dmitrii},
           giveni={D\bibinitperiod}}}%
        {{hash=4b99e011f8a557619a28adf82fc51ddd}{%
           family={Garipov},
           familyi={G\bibinitperiod},
           given={Timur},
           giveni={T\bibinitperiod}}}%
        {{hash=f1c8fe7ad4d22499bdaaa3917e11783d}{%
           family={Vetrov},
           familyi={V\bibinitperiod},
           given={Dmitry},
           giveni={D\bibinitperiod}}}%
        {{hash=f58290185dfd014024f7abaf3fc0d0f2}{%
           family={Wilson},
           familyi={W\bibinitperiod},
           given={Andrew\bibnamedelima Gordon},
           giveni={A\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{1e32dac02a9d45257816a00000c4f5e6}
      \strng{fullhash}{729469f27be3d36e6186ebad85eb7d32}
      \strng{bibnamehash}{1e32dac02a9d45257816a00000c4f5e6}
      \strng{authorbibnamehash}{1e32dac02a9d45257816a00000c4f5e6}
      \strng{authornamehash}{1e32dac02a9d45257816a00000c4f5e6}
      \strng{authorfullhash}{729469f27be3d36e6186ebad85eb7d32}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep neural networks are typically trained by optimizing a loss function with an SGD variant, in conjunction with a decaying learning rate, until convergence. We show that simple averaging of multiple points along the trajectory of SGD, with a cyclical or constant learning rate, leads to better generalization than conventional training. We also show that this Stochastic Weight Averaging (SWA) procedure finds much flatter solutions than SGD, and approximates the recent Fast Geometric Ensembling (FGE) approach with a single model. Using SWA we achieve notable improvement in test accuracy over conventional SGD training on a range of state-of-the-art residual networks, PyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, and ImageNet. In short, SWA is extremely easy to implement, improves generalization, and has almost no computational overhead.}
      \field{annotation}{Comment: Appears at the Conference on Uncertainty in Artificial Intelligence (UAI), 2018}
      \field{month}{2}
      \field{title}{Averaging {Weights} {Leads} to {Wider} {Optima} and {Better} {Generalization}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \true{nocite}
      \verb{doi}
      \verb 10.48550/arXiv.1803.05407
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/TLX4R4JU/Izmailov et al. - 2019 - Averaging Weights Leads to Wider Optima and Better.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/UNLTZ6M9/1803.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1803.05407
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1803.05407
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Artificial Intelligence,Statistics - Machine Learning,Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{jeevanandham_comparison_2017}{article}{}
      \name{author}{4}{}{%
        {{hash=6e5abd14de80919c9c657323ea75dbf7}{%
           family={Jeevanandham},
           familyi={J\bibinitperiod},
           given={Balaji},
           giveni={B\bibinitperiod}}}%
        {{hash=8af4c41ede3f08d6f4c08ed83221c904}{%
           family={Kalyanpur},
           familyi={K\bibinitperiod},
           given={Tejas},
           giveni={T\bibinitperiod}}}%
        {{hash=42bc7a574ae1f7adf2636b11f4736bb7}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Prashant},
           giveni={P\bibinitperiod}}}%
        {{hash=a424d49971fa68f39e45d8c805e76191}{%
           family={Cherian},
           familyi={C\bibinitperiod},
           given={Mathew},
           giveni={M\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {eng}%
      }
      \strng{namehash}{94cffe6b2b5f3af63373c9b5fb89913e}
      \strng{fullhash}{625e66546b7a6792ceb2742fc170cd06}
      \strng{bibnamehash}{94cffe6b2b5f3af63373c9b5fb89913e}
      \strng{authorbibnamehash}{94cffe6b2b5f3af63373c9b5fb89913e}
      \strng{authornamehash}{94cffe6b2b5f3af63373c9b5fb89913e}
      \strng{authorfullhash}{625e66546b7a6792ceb2742fc170cd06}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{OBJECTIVE: This study was to assess the usefulness of newer three-dimensional (3D)-T1 sampling perfection with application optimized contrast using different flip-angle evolutions (SPACE) and 3D-T2 fluid-attenuated inversion recovery (FLAIR) sequences in evaluation of meningeal abnormalities. METHODS: 78 patients who presented with high suspicion of meningeal abnormalities were evaluated using post-contrast 3D-T2-FLAIR, 3D-T1 magnetization-prepared rapid gradient-echo (MPRAGE) and 3D-T1-SPACE sequences. The images were evaluated independently by two radiologists for cortical gyral, sulcal space, basal cisterns and dural enhancement. The diagnoses were confirmed by further investigations including histopathology. RESULTS: Post-contrast 3D-T1-SPACE and 3D-T2-FLAIR images yielded significantly more information than MPRAGE images (p {<} 0.05 for both SPACE and FLAIR images) in detection of meningeal abnormalities. SPACE images best demonstrated abnormalities in dural and sulcal spaces, whereas FLAIR was useful for basal cisterns enhancement. Both SPACE and FLAIR performed equally well in detection of gyral enhancement. In all 10 patients, where both SPACE and T2-FLAIR images failed to demonstrate any abnormality, further analysis was also negative. CONCLUSION: The 3D-T1-SPACE sequence best demonstrated abnormalities in dural and sulcal spaces, whereas FLAIR was useful for abnormalities in basal cisterns. Both SPACE and FLAIR performed holds good for detection of gyral enhancement. Post-contrast SPACE and FLAIR sequences are superior to the MPRAGE sequence for evaluation of meningeal abnormalities and when used in combination have the maximum sensitivity for leptomeningeal abnormalities. The negative-predictive value is nearly 100\%, where no leptomeningeal abnormality was detected on these sequences. Advances in knowledge: Post-contrast 3D-T1-SPACE and 3D-T2-FLAIR images are more useful than 3D-T1-MPRAGE images in evaluation of meningeal abnormalities.}
      \field{issn}{1748-880X}
      \field{journaltitle}{The British Journal of Radiology}
      \field{month}{6}
      \field{number}{1074}
      \field{title}{Comparison of post-contrast {3D}-{T1}-{MPRAGE}, {3D}-{T1}-{SPACE} and {3D}-{T2}-{FLAIR} {MR} images in evaluation of meningeal abnormalities at 3-{T} {MRI}}
      \field{volume}{90}
      \field{year}{2017}
      \true{nocite}
      \field{pages}{20160834}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1259/bjr.20160834
      \endverb
      \verb{file}
      \verb Volltext:/home/someusername/workspace/UNet-bSSFP/lit/storage/YYNNKS4N/Jeevanandham et al. - 2017 - Comparison of post-contrast 3D-T1-MPRAGE, 3D-T1-SP.pdf:application/pdf
      \endverb
      \keyw{Adolescent,Adult,Child,Contrast Media,Female,Humans,Image Interpretation,Computer-Assisted,Imaging,Three-Dimensional,India,Magnetic Resonance Imaging,Male,Meninges,Middle Aged,Prospective Studies}
    \endentry
    \entry{jung_spin_2013}{article}{}
      \name{author}{2}{}{%
        {{hash=28050a8cc85001a01b58d05ac5586c44}{%
           family={Jung},
           familyi={J\bibinitperiod},
           given={Bernd\bibnamedelima André},
           giveni={B\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=fa947fcb01d8f6e7312e2b8684bec2fd}{%
           family={Weigel},
           familyi={W\bibinitperiod},
           given={Matthias},
           giveni={M\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{4b6e9b890b40258298cab23c755c3adf}
      \strng{fullhash}{4b6e9b890b40258298cab23c755c3adf}
      \strng{bibnamehash}{4b6e9b890b40258298cab23c755c3adf}
      \strng{authorbibnamehash}{4b6e9b890b40258298cab23c755c3adf}
      \strng{authornamehash}{4b6e9b890b40258298cab23c755c3adf}
      \strng{authorfullhash}{4b6e9b890b40258298cab23c755c3adf}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The spin echo sequence is a fundamental pulse sequence in MRI. Many of today's applications in routine clinical use are based on this elementary sequence. In this review article, the principles of the spin echo formation are demonstrated on which the generation of the fundamental image contrasts T1, T2, and proton density is based. The basic imaging parameters repetition time (TR) and echo time (TE) and their influence on the image contrast are explained. Important properties such as the behavior in multi-slice imaging or in the presence of flow are depicted and the basic differences with gradient echo imaging are illustrated. The characteristics of the spin echo sequence for different magnetic field strengths with respect to clinical applications are discussed. J. Magn. Reson. Imaging 2013;37:805–817. © 2013 Wiley Periodicals, Inc.}
      \field{issn}{1522-2586}
      \field{journaltitle}{Journal of Magnetic Resonance Imaging}
      \field{number}{4}
      \field{title}{Spin echo magnetic resonance imaging}
      \field{urlday}{8}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{37}
      \field{year}{2013}
      \field{urldateera}{ce}
      \field{pages}{805\bibrangedash 817}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1002/jmri.24068
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/VSP3XSMZ/Jung und Weigel - 2013 - Spin echo magnetic resonance imaging.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/R3FPXJ7Y/jmri.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.24068
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.24068
      \endverb
      \keyw{PD,proton density,relaxation,SE,spin echo,T1,T2}
    \endentry
    \entry{kingma_adam_2017}{misc}{}
      \name{author}{2}{}{%
        {{hash=b6fbd171848aad4edf3925543f1f1522}{%
           family={Kingma},
           familyi={K\bibinitperiod},
           given={Diederik\bibnamedelima P.},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=8aa66e8231cc2fdbe67aa4f18ca970c6}{%
           family={Ba},
           familyi={B\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{fullhash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{bibnamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authorbibnamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authornamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authorfullhash}{a09df9f123146b8e2c7f1134c9496932}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We introduce Adam, an algorithm for ﬁrst-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efﬁcient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the inﬁnity norm.}
      \field{annotation}{Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015}
      \field{month}{1}
      \field{note}{arXiv:1412.6980 [cs]}
      \field{shorttitle}{Adam}
      \field{title}{Adam: {A} {Method} for {Stochastic} {Optimization}}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{file}
      \verb Kingma und Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/DDIRZJUI/Kingma und Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1412.6980
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1412.6980
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{kingma_auto-encoding_2022}{misc}{}
      \name{author}{2}{}{%
        {{hash=b6fbd171848aad4edf3925543f1f1522}{%
           family={Kingma},
           familyi={K\bibinitperiod},
           given={Diederik\bibnamedelima P.},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=53d2880ad8047b61cdae2c6b2803e763}{%
           family={Welling},
           familyi={W\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{fullhash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{bibnamehash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{authorbibnamehash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{authornamehash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{authorfullhash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{How can we perform efﬁcient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efﬁcient by ﬁtting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reﬂected in experimental results.}
      \field{annotation}{Comment: Fixes a typo in the abstract, no other changes}
      \field{month}{12}
      \field{note}{arXiv:1312.6114 [cs, stat]}
      \field{title}{Auto-{Encoding} {Variational} {Bayes}}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb Kingma und Welling - 2022 - Auto-Encoding Variational Bayes.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/X2DF3PAG/Kingma und Welling - 2022 - Auto-Encoding Variational Bayes.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1312.6114
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1312.6114
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{krizhevsky_imagenet_2012}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=c5e3a676e2ac1164b3afcd539c131fc9}{%
           family={Krizhevsky},
           familyi={K\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
        {{hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
        {{hash=813bd95fe553e6079cd53a567b238287}{%
           family={Hinton},
           familyi={H\bibinitperiod},
           given={Geoffrey\bibnamedelima E},
           giveni={G\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{1a23c09aa65b3c2ade45ed18d8127375}
      \strng{fullhash}{1a23c09aa65b3c2ade45ed18d8127375}
      \strng{bibnamehash}{1a23c09aa65b3c2ade45ed18d8127375}
      \strng{authorbibnamehash}{1a23c09aa65b3c2ade45ed18d8127375}
      \strng{authornamehash}{1a23c09aa65b3c2ade45ed18d8127375}
      \strng{authorfullhash}{1a23c09aa65b3c2ade45ed18d8127375}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.}
      \field{booktitle}{Advances in {Neural} {Information} {Processing} {Systems}}
      \field{title}{{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{25}
      \field{year}{2012}
      \field{urldateera}{ce}
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/BAGPM86J/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html
      \endverb
    \endentry
    \entry{MRIAGuidedTourMagnetAcademy-2024-05-07}{misc}{}
      \name{author}{1}{}{%
        {{hash=f8cd07e6b2072f0498f9ea8aafff4e99}{%
           family={Laboratory},
           familyi={L\bibinitperiod},
           given={National\bibnamedelimb High\bibnamedelimb Magnetic\bibnamedelima Field},
           giveni={N\bibinitperiod\bibinitdelim H\bibinitperiod\bibinitdelim M\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
      }
      \strng{namehash}{f8cd07e6b2072f0498f9ea8aafff4e99}
      \strng{fullhash}{f8cd07e6b2072f0498f9ea8aafff4e99}
      \strng{bibnamehash}{f8cd07e6b2072f0498f9ea8aafff4e99}
      \strng{authorbibnamehash}{f8cd07e6b2072f0498f9ea8aafff4e99}
      \strng{authornamehash}{f8cd07e6b2072f0498f9ea8aafff4e99}
      \strng{authorfullhash}{f8cd07e6b2072f0498f9ea8aafff4e99}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{day}{7}
      \field{month}{5}
      \field{title}{MRI: A Guided Tour - Magnet Academy}
      \field{urlday}{7}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb :./references/magnet-academy-read-science-stories-science-simplified-mri-a-guided-tour-.html:html
      \endverb
      \verb{urlraw}
      \verb https://nationalmaglab.org/magnet-academy/read-science-stories/science-simplified/mri-a-guided-tour/
      \endverb
      \verb{url}
      \verb https://nationalmaglab.org/magnet-academy/read-science-stories/science-simplified/mri-a-guided-tour/
      \endverb
    \endentry
    \entry{lecun_deep_2015}{article}{}
      \name{author}{3}{}{%
        {{hash=6a1aa6b7eab12b931ca7c7e3f927231d}{%
           family={LeCun},
           familyi={L\bibinitperiod},
           given={Yann},
           giveni={Y\bibinitperiod}}}%
        {{hash=40a8e4774982146adc2688546f54efb2}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Yoshua},
           giveni={Y\bibinitperiod}}}%
        {{hash=9a8750ccdb2a4cf14d2655face1ce016}{%
           family={Hinton},
           familyi={H\bibinitperiod},
           given={Geoffrey},
           giveni={G\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{c6c75bd00ce5a488e91a749d8383b3df}
      \strng{fullhash}{c6c75bd00ce5a488e91a749d8383b3df}
      \strng{bibnamehash}{c6c75bd00ce5a488e91a749d8383b3df}
      \strng{authorbibnamehash}{c6c75bd00ce5a488e91a749d8383b3df}
      \strng{authornamehash}{c6c75bd00ce5a488e91a749d8383b3df}
      \strng{authorfullhash}{c6c75bd00ce5a488e91a749d8383b3df}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.}
      \field{issn}{1476-4687}
      \field{journaltitle}{Nature}
      \field{month}{5}
      \field{note}{Publisher: Nature Publishing Group}
      \field{number}{7553}
      \field{title}{Deep learning}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{521}
      \field{year}{2015}
      \field{urldateera}{ce}
      \true{nocite}
      \field{pages}{436\bibrangedash 444}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1038/nature14539
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/DRLEAYRB/LeCun et al. - 2015 - Deep learning.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.nature.com/articles/nature14539
      \endverb
      \verb{url}
      \verb https://www.nature.com/articles/nature14539
      \endverb
      \keyw{Computer science,Mathematics and computing}
    \endentry
    \entry{lecun_handwritten_1989}{inproceedings}{}
      \name{author}{7}{}{%
        {{hash=6a1aa6b7eab12b931ca7c7e3f927231d}{%
           family={LeCun},
           familyi={L\bibinitperiod},
           given={Yann},
           giveni={Y\bibinitperiod}}}%
        {{hash=824ee0660bd2a40e283a9b8266f0868b}{%
           family={Boser},
           familyi={B\bibinitperiod},
           given={Bernhard},
           giveni={B\bibinitperiod}}}%
        {{hash=2e06fda0238979cad0d24113daf80ed5}{%
           family={Denker},
           familyi={D\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
        {{hash=0444ce878492140cb17d6d4f19c2b24d}{%
           family={Henderson},
           familyi={H\bibinitperiod},
           given={Donnie},
           giveni={D\bibinitperiod}}}%
        {{hash=09c5a94a3b4d44c65e19cea92a351737}{%
           family={Howard},
           familyi={H\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod}}}%
        {{hash=494b3ee863ae780ea5237c5b09b80c0e}{%
           family={Hubbard},
           familyi={H\bibinitperiod},
           given={Wayne},
           giveni={W\bibinitperiod}}}%
        {{hash=4b8d7e185f2fbc444f33953aa1c0a385}{%
           family={Jackel},
           familyi={J\bibinitperiod},
           given={Lawrence},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Morgan-Kaufmann}%
      }
      \strng{namehash}{9e4c6012409dc8dd9b2aa198a2059804}
      \strng{fullhash}{850352120a3ba111c2cfdcbcc36f7f30}
      \strng{bibnamehash}{9e4c6012409dc8dd9b2aa198a2059804}
      \strng{authorbibnamehash}{9e4c6012409dc8dd9b2aa198a2059804}
      \strng{authornamehash}{9e4c6012409dc8dd9b2aa198a2059804}
      \strng{authorfullhash}{850352120a3ba111c2cfdcbcc36f7f30}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present an application of back-propagation networks to hand(cid:173) written digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1 \% error rate and about a 9\% reject rate on zipcode digits provided by the U.S. Postal Service.}
      \field{booktitle}{Advances in {Neural} {Information} {Processing} {Systems}}
      \field{title}{Handwritten {Digit} {Recognition} with a {Back}-{Propagation} {Network}}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{2}
      \field{year}{1989}
      \field{urldateera}{ce}
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/WTDUYVFR/LeCun et al. - 1989 - Handwritten Digit Recognition with a Back-Propagat.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://papers.nips.cc/paper/1989/hash/53c3bce66e43be4f209556518c2fcb54-Abstract.html
      \endverb
      \verb{url}
      \verb https://papers.nips.cc/paper/1989/hash/53c3bce66e43be4f209556518c2fcb54-Abstract.html
      \endverb
    \endentry
    \entry{lauterbur}{book}{}
      \name{author}{2}{}{%
        {{hash=36ba018a9d1501ce6bde8b95029c1f10}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Zhi-Pei},
           giveni={Z\bibinithyphendelim P\bibinitperiod}}}%
        {{hash=618712d8e4b632cf463ea4ef4b4fa464}{%
           family={Lauterbur},
           familyi={L\bibinitperiod},
           given={Paul\bibnamedelima C.},
           giveni={P\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {SPIE Optical Engineering Press Bellingham}%
      }
      \strng{namehash}{764c9650b1c6082c811d26a3493975cd}
      \strng{fullhash}{764c9650b1c6082c811d26a3493975cd}
      \strng{bibnamehash}{764c9650b1c6082c811d26a3493975cd}
      \strng{authorbibnamehash}{764c9650b1c6082c811d26a3493975cd}
      \strng{authornamehash}{764c9650b1c6082c811d26a3493975cd}
      \strng{authorfullhash}{764c9650b1c6082c811d26a3493975cd}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Principles of Magnetic Resonance Imaging}
      \field{urlday}{17}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2000}
      \field{urldateera}{ce}
      \verb{file}
      \verb Liang and Lauterbur - 2000 - Principles of magnetic resonance imaging.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/UNGLL97V/Liang and Lauterbur - 2000 - Principles of magnetic resonance imaging.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://cds.cern.ch/record/1480847/files/0780347234_TOC.pdf
      \endverb
      \verb{url}
      \verb https://cds.cern.ch/record/1480847/files/0780347234_TOC.pdf
      \endverb
    \endentry
    \entry{loshchilov_decoupled_2019}{misc}{}
      \name{author}{2}{}{%
        {{hash=1241b8181104f1917578d4c7f9b323b6}{%
           family={Loshchilov},
           familyi={L\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
        {{hash=528d4af87fd2ecf5fb8a22db913ce088}{%
           family={Hutter},
           familyi={H\bibinitperiod},
           given={Frank},
           giveni={F\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{fullhash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{bibnamehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{authorbibnamehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{authornamehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{authorfullhash}{b308ccb07134a06ec3735828ac4f15e2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW}
      \field{annotation}{Comment: Published as a conference paper at ICLR 2019}
      \field{month}{1}
      \field{note}{arXiv:1711.05101 [cs, math]}
      \field{title}{Decoupled {Weight} {Decay} {Regularization}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1711.05101
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/8M9AWAN6/Loshchilov and Hutter - 2019 - Decoupled Weight Decay Regularization.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/H5Y7MTWT/1711.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1711.05101
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1711.05101
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Optimization and Control}
    \endentry
    \entry{marques_mp2rage_2010}{article}{}
      \name{author}{6}{}{%
        {{hash=9792e23f0602864e26dd63581815679f}{%
           family={Marques},
           familyi={M\bibinitperiod},
           given={José\bibnamedelima P.},
           giveni={J\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=d5746c2c7df86179c728f888633164d1}{%
           family={Kober},
           familyi={K\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=fe8122730238f5235578bbb000887e87}{%
           family={Krueger},
           familyi={K\bibinitperiod},
           given={Gunnar},
           giveni={G\bibinitperiod}}}%
        {{hash=f92270b9303ebe92cb03b5ab3a942859}{%
           family={Zwaag},
           familyi={Z\bibinitperiod},
           given={Wietske},
           giveni={W\bibinitperiod},
           prefix={van\bibnamedelima der},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=5158e62eab17e6ec2be251a59e284d95}{%
           family={Van\bibnamedelimb de\bibnamedelima Moortele},
           familyi={V\bibinitperiod\bibinitdelim d\bibinitperiod\bibinitdelim M\bibinitperiod},
           given={Pierre-François},
           giveni={P\bibinithyphendelim F\bibinitperiod}}}%
        {{hash=92c181277b6d23eae9e1d94b2018c7d3}{%
           family={Gruetter},
           familyi={G\bibinitperiod},
           given={Rolf},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{3bb920a2816b6d54d4aebff5f60b2a86}
      \strng{fullhash}{4438f1957e85d15b95fb158ae488498f}
      \strng{bibnamehash}{3bb920a2816b6d54d4aebff5f60b2a86}
      \strng{authorbibnamehash}{3bb920a2816b6d54d4aebff5f60b2a86}
      \strng{authornamehash}{3bb920a2816b6d54d4aebff5f60b2a86}
      \strng{authorfullhash}{4438f1957e85d15b95fb158ae488498f}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The large spatial inhomogeneity in transmit B1 field (B1+) observable in human MR images at high static magnetic fields (B0) severely impairs image quality. To overcome this effect in brain T1-weighted images, the MPRAGE sequence was modified to generate two different images at different inversion times, MP2RAGE. By combining the two images in a novel fashion, it was possible to create T1-weigthed images where the result image was free of proton density contrast, T2⁎ contrast, reception bias field, and, to first order, transmit field inhomogeneity. MP2RAGE sequence parameters were optimized using Bloch equations to maximize contrast-to-noise ratio per unit of time between brain tissues and minimize the effect of B1+ variations through space. Images of high anatomical quality and excellent brain tissue differentiation suitable for applications such as segmentation and voxel-based morphometry were obtained at 3 and 7 T. From such T1-weighted images, acquired within 12 min, high-resolution 3D T1 maps were routinely calculated at 7 T with sub-millimeter voxel resolution (0.65–0.85 mm isotropic). T1 maps were validated in phantom experiments. In humans, the T1 values obtained at 7 T were 1.15±0.06 s for white matter (WM) and 1.92±0.16 s for grey matter (GM), in good agreement with literature values obtained at lower spatial resolution. At 3 T, where whole-brain acquisitions with 1 mm isotropic voxels were acquired in 8 min, the T1 values obtained (0.81±0.03 s for WM and 1.35±0.05 for GM) were once again found to be in very good agreement with values in the literature.}
      \field{issn}{1053-8119}
      \field{journaltitle}{NeuroImage}
      \field{month}{1}
      \field{number}{2}
      \field{title}{{MP2RAGE}, a self bias-field corrected sequence for improved segmentation and {T1}-mapping at high field}
      \field{urlday}{12}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{49}
      \field{year}{2010}
      \field{urldateera}{ce}
      \field{pages}{1271\bibrangedash 1281}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1016/j.neuroimage.2009.10.002
      \endverb
      \verb{file}
      \verb ScienceDirect Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/WVZIF6XA/S1053811909010738.html:text/html;Volltext:/home/someusername/workspace/UNet-bSSFP/lit/storage/2QS37GK6/Marques et al. - 2010 - MP2RAGE, a self bias-field corrected sequence for .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S1053811909010738
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S1053811909010738
      \endverb
    \endentry
    \entry{mcculloch_logical_1943}{article}{}
      \name{author}{2}{}{%
        {{hash=1ccb147b2b2165266e6ce5900193e687}{%
           family={McCulloch},
           familyi={M\bibinitperiod},
           given={Warren\bibnamedelima S.},
           giveni={W\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=c5a56e799cdf785e814246c091d36e73}{%
           family={Pitts},
           familyi={P\bibinitperiod},
           given={Walter},
           giveni={W\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{816477c5724040789c6fe02e3968dc62}
      \strng{fullhash}{816477c5724040789c6fe02e3968dc62}
      \strng{bibnamehash}{816477c5724040789c6fe02e3968dc62}
      \strng{authorbibnamehash}{816477c5724040789c6fe02e3968dc62}
      \strng{authornamehash}{816477c5724040789c6fe02e3968dc62}
      \strng{authorfullhash}{816477c5724040789c6fe02e3968dc62}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.}
      \field{issn}{1522-9602}
      \field{journaltitle}{The bulletin of mathematical biophysics}
      \field{month}{12}
      \field{number}{4}
      \field{title}{A logical calculus of the ideas immanent in nervous activity}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{5}
      \field{year}{1943}
      \field{urldateera}{ce}
      \field{pages}{115\bibrangedash 133}
      \range{pages}{19}
      \verb{doi}
      \verb 10.1007/BF02478259
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/M53XKUC4/McCulloch und Pitts - 1943 - A logical calculus of the ideas immanent in nervou.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/BF02478259
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/BF02478259
      \endverb
      \keyw{Excitatory Synapse,Inhibitory Synapse,Nervous Activity,Spatial Summation,Temporal Summation}
    \endentry
    \entry{nair_rectified_2010}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=0719e279192084705efab5d7e0505f52}{%
           family={Nair},
           familyi={N\bibinitperiod},
           given={Vinod},
           giveni={V\bibinitperiod}}}%
        {{hash=813bd95fe553e6079cd53a567b238287}{%
           family={Hinton},
           familyi={H\bibinitperiod},
           given={Geoffrey\bibnamedelima E.},
           giveni={G\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Madison, WI, USA}%
      }
      \list{publisher}{1}{%
        {Omnipress}%
      }
      \strng{namehash}{08d64b697ddc0d522928febb8e7c119b}
      \strng{fullhash}{08d64b697ddc0d522928febb8e7c119b}
      \strng{bibnamehash}{08d64b697ddc0d522928febb8e7c119b}
      \strng{authorbibnamehash}{08d64b697ddc0d522928febb8e7c119b}
      \strng{authornamehash}{08d64b697ddc0d522928febb8e7c119b}
      \strng{authorfullhash}{08d64b697ddc0d522928febb8e7c119b}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these "Stepped Sigmoid Units" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.}
      \field{booktitle}{Proceedings of the 27th {International} {Conference} on {International} {Conference} on {Machine} {Learning}}
      \field{isbn}{978-1-60558-907-7}
      \field{month}{6}
      \field{series}{{ICML}'10}
      \field{title}{Rectified linear units improve restricted boltzmann machines}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2010}
      \field{urldateera}{ce}
      \field{pages}{807\bibrangedash 814}
      \range{pages}{8}
    \endentry
    \entry{nguyen_motion-insensitive_2017}{article}{}
      \name{author}{2}{}{%
        {{hash=20e1c9979b163b51e8bfb749cddde9e8}{%
           family={Nguyen},
           familyi={N\bibinitperiod},
           given={Damien},
           giveni={D\bibinitperiod}}}%
        {{hash=bb41146c4a8c0507581de495e5654324}{%
           family={Bieri},
           familyi={B\bibinitperiod},
           given={Oliver},
           giveni={O\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{d9116fcdf83d1be583f6a757b340cfcc}
      \strng{fullhash}{d9116fcdf83d1be583f6a757b340cfcc}
      \strng{bibnamehash}{d9116fcdf83d1be583f6a757b340cfcc}
      \strng{authorbibnamehash}{d9116fcdf83d1be583f6a757b340cfcc}
      \strng{authornamehash}{d9116fcdf83d1be583f6a757b340cfcc}
      \strng{authorfullhash}{d9116fcdf83d1be583f6a757b340cfcc}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Purpose Triple echo steady state (TESS) uses the lowest steady state configuration modes for rapid relaxometry. Due to its unbalanced gradient scheme, however, TESS is inherently motion-sensitive. The purpose of this work is to merge TESS with a balanced acquisition scheme for motion-insensitive rapid configuration relaxometry, termed MIRACLE. Methods The lowest order steady state free precession (SSFP) configurations are retrieved by Fourier transformation of the frequency response of N frequency-shifted balanced SSFP (bSSFP) scans and subsequently processed for relaxometry, as proposed with TESS. Accuracy of MIRACLE is evaluated from simulations, phantom studies as well as in vivo brain and cartilage imaging at 3T. Results Simulations and phantom results revealed no conceptual flaw, and artifact-free configuration imaging was achieved in vivo. Overall, relaxometry results were accurate in phantoms and in good agreement for cartilage and for in the brain, but apparent low values were observed for brain white matter; reflecting asymmetries in the bSSFP profile. Conclusion Rapid and mapping with MIRACLE offers analogous properties as TESS while successfully mitigating its motion-sensitivity. As a result of the Fourier transformation, relaxometry becomes sensitive to the voxel frequency distribution, which may contain useful physiologic information, such as structural brain integrity. © 2016 International Society for Magnetic Resonance in Medicine. Magn Reson Med 78:518–526, 2017. © 2016 International Society for Magnetic Resonance in Medicine}
      \field{issn}{1522-2594}
      \field{journaltitle}{Magnetic Resonance in Medicine}
      \field{number}{2}
      \field{title}{Motion-insensitive rapid configuration relaxometry}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{78}
      \field{year}{2017}
      \field{urldateera}{ce}
      \field{pages}{518\bibrangedash 526}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1002/mrm.26384
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/VR83HDLP/Nguyen and Bieri - 2017 - Motion-insensitive rapid configuration relaxometry.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/YX3LH69G/mrm.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.26384
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.26384
      \endverb
      \keyw{relaxometry,balanced Steady State Free Precession (bSSFP),T1 mapping,T2 mapping}
    \endentry
    \entry{nishimura}{book}{}
      \name{author}{1}{}{%
        {{hash=beccd678f721f88d1b3537074646104e}{%
           family={Nishimura},
           familyi={N\bibinitperiod},
           given={Dwight},
           giveni={D\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {English}%
      }
      \list{publisher}{1}{%
        {Stanford Univ}%
      }
      \strng{namehash}{beccd678f721f88d1b3537074646104e}
      \strng{fullhash}{beccd678f721f88d1b3537074646104e}
      \strng{bibnamehash}{beccd678f721f88d1b3537074646104e}
      \strng{authorbibnamehash}{beccd678f721f88d1b3537074646104e}
      \strng{authornamehash}{beccd678f721f88d1b3537074646104e}
      \strng{authorfullhash}{beccd678f721f88d1b3537074646104e}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This book presents the basic principles of magnetic resonance imaging (MRI), focusing on image formation, image content, and performance considerations. Emphasis is on the signal processing elements of MRI, particularly the Fourier transform relationships. Although developed as a teaching text for an electrical engineering course at Stanford University, the material should be accessible to those from other technical fields. The primary chapters (Chapters 1-7) cover the foundational material while the latter chapters (Chapters 8-11) provide brief overviews of extensions and selected topics.}
      \field{month}{2}
      \field{title}{Principles of {Magnetic} {Resonance} {Imaging}}
      \field{year}{2010}
      \verb{file}
      \verb Nishimura - 2010 - Principles of Magnetic Resonance Imaging.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/TF4RUKCE/Nishimura - 2010 - Principles of Magnetic Resonance Imaging.pdf:application/pdf
      \endverb
    \endentry
    \entry{pang_image-image_2021}{misc}{}
      \name{author}{4}{}{%
        {{hash=95e2f9b881c964bb17b011ef38c1c558}{%
           family={Pang},
           familyi={P\bibinitperiod},
           given={Yingxue},
           giveni={Y\bibinitperiod}}}%
        {{hash=25da004d1147d80ff018794286650701}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Jianxin},
           giveni={J\bibinitperiod}}}%
        {{hash=5588f729660dbe4dbf5af3850f858ae3}{%
           family={Qin},
           familyi={Q\bibinitperiod},
           given={Tao},
           giveni={T\bibinitperiod}}}%
        {{hash=18dc21ba371100b5e6f3bd88a675373e}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Zhibo},
           giveni={Z\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b8c551c4c477a56b8c83ee4abefbbcc0}
      \strng{fullhash}{6d79191ed54c7397855aba80f60dad34}
      \strng{bibnamehash}{b8c551c4c477a56b8c83ee4abefbbcc0}
      \strng{authorbibnamehash}{b8c551c4c477a56b8c83ee4abefbbcc0}
      \strng{authornamehash}{b8c551c4c477a56b8c83ee4abefbbcc0}
      \strng{authorfullhash}{6d79191ed54c7397855aba80f60dad34}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Image-to-image translation (I2I) aims to transfer images from a source domain to a target domain while preserving the content representations. I2I has drawn increasing attention and made tremendous progress in recent years because of its wide range of applications in many computer vision and image processing problems, such as image synthesis, segmentation, style transfer, restoration, and pose estimation. In this paper, we provide an overview of the I2I works developed in recent years. We will analyze the key techniques of the existing I2I works and clarify the main progress the community has made. Additionally, we will elaborate on the effect of I2I on the research and industry community and point out remaining challenges in related ﬁelds.}
      \field{annotation}{Comment: 24 pages, 21 figures}
      \field{month}{7}
      \field{note}{arXiv:2101.08629 [cs]}
      \field{shorttitle}{Image-to-{Image} {Translation}}
      \field{title}{Image-to-{Image} {Translation}: {Methods} and {Applications}}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{file}
      \verb Pang et al. - 2021 - Image-to-Image Translation Methods and Applicatio.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/JHJYN3R8/Pang et al. - 2021 - Image-to-Image Translation Methods and Applicatio.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2101.08629
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2101.08629
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{paszke_pytorch_2019}{inproceedings}{}
      \name{author}{21}{}{%
        {{hash=56bf0b340039cf8594436a624ff548a9}{%
           family={Paszke},
           familyi={P\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod}}}%
        {{hash=4ba5062e5919c814aceec188d54c01f2}{%
           family={Gross},
           familyi={G\bibinitperiod},
           given={Sam},
           giveni={S\bibinitperiod}}}%
        {{hash=e5dfae4582081d649e3a0d5342050016}{%
           family={Massa},
           familyi={M\bibinitperiod},
           given={Francisco},
           giveni={F\bibinitperiod}}}%
        {{hash=b5815e1692fa2d0c1f44eecf509bd7c4}{%
           family={Lerer},
           familyi={L\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod}}}%
        {{hash=b75383e6b48c8360c7a60031424c85cf}{%
           family={Bradbury},
           familyi={B\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
        {{hash=f897ed422c34d95af2e22778dfc2607e}{%
           family={Chanan},
           familyi={C\bibinitperiod},
           given={Gregory},
           giveni={G\bibinitperiod}}}%
        {{hash=046269e070246feb6f394141db80ed87}{%
           family={Killeen},
           familyi={K\bibinitperiod},
           given={Trevor},
           giveni={T\bibinitperiod}}}%
        {{hash=c40352c194e60a3ef458ee7e8685afb5}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Zeming},
           giveni={Z\bibinitperiod}}}%
        {{hash=6e45f49ec618e619efad90c8e8a61f0c}{%
           family={Gimelshein},
           familyi={G\bibinitperiod},
           given={Natalia},
           giveni={N\bibinitperiod}}}%
        {{hash=f65a80959d520337ae99a0798515036c}{%
           family={Antiga},
           familyi={A\bibinitperiod},
           given={Luca},
           giveni={L\bibinitperiod}}}%
        {{hash=954cf7680b6ce14813973eccdca3c4bc}{%
           family={Desmaison},
           familyi={D\bibinitperiod},
           given={Alban},
           giveni={A\bibinitperiod}}}%
        {{hash=c1b8f8db68d6667b9f2f9a9a3567721b}{%
           family={Kopf},
           familyi={K\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod}}}%
        {{hash=b9e701339e56fd0b171145b08288a1b7}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Edward},
           giveni={E\bibinitperiod}}}%
        {{hash=3f9535be511fd2fa346093e63b8e61a0}{%
           family={DeVito},
           familyi={D\bibinitperiod},
           given={Zachary},
           giveni={Z\bibinitperiod}}}%
        {{hash=d814afaa50b9e22ab92cc9f8f9a9e43a}{%
           family={Raison},
           familyi={R\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod}}}%
        {{hash=3feeeebee8583ecc208f7fb3e0a55068}{%
           family={Tejani},
           familyi={T\bibinitperiod},
           given={Alykhan},
           giveni={A\bibinitperiod}}}%
        {{hash=e18536d5cb7543731fbf2ca1a4908732}{%
           family={Chilamkurthy},
           familyi={C\bibinitperiod},
           given={Sasank},
           giveni={S\bibinitperiod}}}%
        {{hash=0a0b028c6b85c46f368317d0c5bfe3a0}{%
           family={Steiner},
           familyi={S\bibinitperiod},
           given={Benoit},
           giveni={B\bibinitperiod}}}%
        {{hash=998a001f16bb57c079c1d5afb1cb02c8}{%
           family={Fang},
           familyi={F\bibinitperiod},
           given={Lu},
           giveni={L\bibinitperiod}}}%
        {{hash=3f19c633bbfb847db6a0e71d3659eacd}{%
           family={Bai},
           familyi={B\bibinitperiod},
           given={Junjie},
           giveni={J\bibinitperiod}}}%
        {{hash=8ef51a0906e47d2b4472c4e714ed598f}{%
           family={Chintala},
           familyi={C\bibinitperiod},
           given={Soumith},
           giveni={S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{724e74fc18651eb78eb82fbcd1d9dfb1}
      \strng{fullhash}{ba1e2da270d08cb8de2856498a028fed}
      \strng{bibnamehash}{724e74fc18651eb78eb82fbcd1d9dfb1}
      \strng{authorbibnamehash}{724e74fc18651eb78eb82fbcd1d9dfb1}
      \strng{authornamehash}{724e74fc18651eb78eb82fbcd1d9dfb1}
      \strng{authorfullhash}{ba1e2da270d08cb8de2856498a028fed}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.}
      \field{booktitle}{Advances in {Neural} {Information} {Processing} {Systems}}
      \field{shorttitle}{{PyTorch}}
      \field{title}{{PyTorch}: {An} {Imperative} {Style}, {High}-{Performance} {Deep} {Learning} {Library}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{32}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/7QNTHMYS/Paszke et al. - 2019 - PyTorch An Imperative Style, High-Performance Dee.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html
      \endverb
    \endentry
    \entry{perez-garcia_torchio_2021}{article}{}
      \name{author}{3}{}{%
        {{hash=5387d2c9d7c24dae0973e307652b413f}{%
           family={Pérez-García},
           familyi={P\bibinithyphendelim G\bibinitperiod},
           given={Fernando},
           giveni={F\bibinitperiod}}}%
        {{hash=7bea641010b3c62c71c908ce48cb7ec4}{%
           family={Sparks},
           familyi={S\bibinitperiod},
           given={Rachel},
           giveni={R\bibinitperiod}}}%
        {{hash=81ba59598fdce027a3a694c8dd331fe7}{%
           family={Ourselin},
           familyi={O\bibinitperiod},
           given={Sébastien},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{d7e5e689e2c2635c84d8599e8bdb2c4a}
      \strng{fullhash}{d7e5e689e2c2635c84d8599e8bdb2c4a}
      \strng{bibnamehash}{d7e5e689e2c2635c84d8599e8bdb2c4a}
      \strng{authorbibnamehash}{d7e5e689e2c2635c84d8599e8bdb2c4a}
      \strng{authornamehash}{d7e5e689e2c2635c84d8599e8bdb2c4a}
      \strng{authorfullhash}{d7e5e689e2c2635c84d8599e8bdb2c4a}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Background and objective Processing of medical images such as MRI or CT presents different challenges compared to RGB images typically used in computer vision. These include a lack of labels for large datasets, high computational costs, and the need of metadata to describe the physical properties of voxels. Data augmentation is used to artificially increase the size of the training datasets. Training with image subvolumes or patches decreases the need for computational power. Spatial metadata needs to be carefully taken into account in order to ensure a correct alignment and orientation of volumes. Methods We present TorchIO, an open-source Python library to enable efficient loading, preprocessing, augmentation and patch-based sampling of medical images for deep learning. TorchIO follows the style of PyTorch and integrates standard medical image processing libraries to efficiently process images during training of neural networks. TorchIO transforms can be easily composed, reproduced, traced and extended. Most transforms can be inverted, making the library suitable for test-time augmentation and estimation of aleatoric uncertainty in the context of segmentation. We provide multiple generic preprocessing and augmentation operations as well as simulation of MRI-specific artifacts. Results Source code, comprehensive tutorials and extensive documentation for TorchIO can be found at http://torchio.rtfd.io/. The package can be installed from the Python Package Index (PyPI) running pip install torchio. It includes a command-line interface which allows users to apply transforms to image files without using Python. Additionally, we provide a graphical user interface within a TorchIO extension in 3D Slicer to visualize the effects of transforms. Conclusion TorchIO was developed to help researchers standardize medical image processing pipelines and allow them to focus on the deep learning experiments. It encourages good open-science practices, as it supports experiment reproducibility and is version-controlled so that the software can be cited precisely. Due to its modularity, the library is compatible with other frameworks for deep learning with medical images.}
      \field{issn}{0169-2607}
      \field{journaltitle}{Computer Methods and Programs in Biomedicine}
      \field{month}{9}
      \field{shorttitle}{{TorchIO}}
      \field{title}{{TorchIO}: {A} {Python} library for efficient loading, preprocessing, augmentation and patch-based sampling of medical images in deep learning}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{208}
      \field{year}{2021}
      \field{urldateera}{ce}
      \field{pages}{106236}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1016/j.cmpb.2021.106236
      \endverb
      \verb{file}
      \verb Full Text:/home/someusername/workspace/UNet-bSSFP/lit/storage/4JR9AM48/Pérez-García et al. - 2021 - TorchIO A Python library for efficient loading, p.pdf:application/pdf;ScienceDirect Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/ECUINQPD/S0169260721003102.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S0169260721003102
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S0169260721003102
      \endverb
      \keyw{Data augmentation,Deep learning,Medical image computing,Preprocessing}
    \endentry
    \entry{peters_tune_2019}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=711e37ce316a72d79bd008a205513ef0}{%
           family={Peters},
           familyi={P\bibinitperiod},
           given={Matthew\bibnamedelima E.},
           giveni={M\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=b468248a20d75c52ee742f4592c2569f}{%
           family={Ruder},
           familyi={R\bibinitperiod},
           given={Sebastian},
           giveni={S\bibinitperiod}}}%
        {{hash=76caee508bed7d0995f7c21cc5e6208c}{%
           family={Smith},
           familyi={S\bibinitperiod},
           given={Noah\bibnamedelima A.},
           giveni={N\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \name{editor}{9}{}{%
        {{hash=501fda621b3a249bc03e442c4f256d6f}{%
           family={Augenstein},
           familyi={A\bibinitperiod},
           given={Isabelle},
           giveni={I\bibinitperiod}}}%
        {{hash=af3eddb0ceb13defad747ca622dd8b4b}{%
           family={Gella},
           familyi={G\bibinitperiod},
           given={Spandana},
           giveni={S\bibinitperiod}}}%
        {{hash=b468248a20d75c52ee742f4592c2569f}{%
           family={Ruder},
           familyi={R\bibinitperiod},
           given={Sebastian},
           giveni={S\bibinitperiod}}}%
        {{hash=4ad8d51802941285dfefe5363d6e7fe1}{%
           family={Kann},
           familyi={K\bibinitperiod},
           given={Katharina},
           giveni={K\bibinitperiod}}}%
        {{hash=2f442ce436143e77bfaed65dad1ae011}{%
           family={Can},
           familyi={C\bibinitperiod},
           given={Burcu},
           giveni={B\bibinitperiod}}}%
        {{hash=7a7fdb4cb72d04e1eaa8a6a2ca0358dc}{%
           family={Welbl},
           familyi={W\bibinitperiod},
           given={Johannes},
           giveni={J\bibinitperiod}}}%
        {{hash=7cf7ac6a9456559cc67ee138c7f21cec}{%
           family={Conneau},
           familyi={C\bibinitperiod},
           given={Alexis},
           giveni={A\bibinitperiod}}}%
        {{hash=62341ebcc57e03720c55a39d93f0b17d}{%
           family={Ren},
           familyi={R\bibinitperiod},
           given={Xiang},
           giveni={X\bibinitperiod}}}%
        {{hash=bd651b0a99d219fbbcf0b23d89a85e2e}{%
           family={Rei},
           familyi={R\bibinitperiod},
           given={Marek},
           giveni={M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Florence, Italy}%
      }
      \list{publisher}{1}{%
        {Association for Computational Linguistics}%
      }
      \strng{namehash}{d6c1d0e4e3c4f9c7b94e677c95a73d56}
      \strng{fullhash}{d6c1d0e4e3c4f9c7b94e677c95a73d56}
      \strng{bibnamehash}{d6c1d0e4e3c4f9c7b94e677c95a73d56}
      \strng{authorbibnamehash}{d6c1d0e4e3c4f9c7b94e677c95a73d56}
      \strng{authornamehash}{d6c1d0e4e3c4f9c7b94e677c95a73d56}
      \strng{authorfullhash}{d6c1d0e4e3c4f9c7b94e677c95a73d56}
      \strng{editorbibnamehash}{c71278f0c4b8aa616ee85e8e00e18e33}
      \strng{editornamehash}{c71278f0c4b8aa616ee85e8e00e18e33}
      \strng{editorfullhash}{3a1e56dcf86ffa5f876363d2c53c27e3}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{While most previous work has focused on different pretraining objectives and architectures for transfer learning, we ask how to best adapt the pretrained model to a given target task. We focus on the two most common forms of adaptation, feature extraction (where the pretrained weights are frozen), and directly fine-tuning the pretrained model. Our empirical results across diverse NLP tasks with two state-of-the-art models show that the relative performance of fine-tuning vs. feature extraction depends on the similarity of the pretraining and target tasks. We explore possible explanations for this finding and provide a set of adaptation guidelines for the NLP practitioner.}
      \field{booktitle}{Proceedings of the 4th {Workshop} on {Representation} {Learning} for {NLP} ({RepL4NLP}-2019)}
      \field{month}{8}
      \field{shorttitle}{To {Tune} or {Not} to {Tune}?}
      \field{title}{To {Tune} or {Not} to {Tune}? {Adapting} {Pretrained} {Representations} to {Diverse} {Tasks}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \field{pages}{7\bibrangedash 14}
      \range{pages}{8}
      \verb{doi}
      \verb 10.18653/v1/W19-4302
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/BWQ94T48/Peters et al. - 2019 - To Tune or Not to Tune Adapting Pretrained Repres.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://aclanthology.org/W19-4302
      \endverb
      \verb{url}
      \verb https://aclanthology.org/W19-4302
      \endverb
    \endentry
    \entry{pfeiffer_modular_2024}{misc}{}
      \name{author}{4}{}{%
        {{hash=080ae0feeabd4b971cde16160cd96ac6}{%
           family={Pfeiffer},
           familyi={P\bibinitperiod},
           given={Jonas},
           giveni={J\bibinitperiod}}}%
        {{hash=b468248a20d75c52ee742f4592c2569f}{%
           family={Ruder},
           familyi={R\bibinitperiod},
           given={Sebastian},
           giveni={S\bibinitperiod}}}%
        {{hash=9fa17331489449c86886282786aa6111}{%
           family={Vulić},
           familyi={V\bibinitperiod},
           given={Ivan},
           giveni={I\bibinitperiod}}}%
        {{hash=2a8464d8017cb3c9d745fd2c330a49ef}{%
           family={Ponti},
           familyi={P\bibinitperiod},
           given={Edoardo\bibnamedelima Maria},
           giveni={E\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{cd54f536c019847c8eeffefb01b5d858}
      \strng{fullhash}{d864d5bda54f2ca7ebae6eab9b8adafe}
      \strng{bibnamehash}{cd54f536c019847c8eeffefb01b5d858}
      \strng{authorbibnamehash}{cd54f536c019847c8eeffefb01b5d858}
      \strng{authornamehash}{cd54f536c019847c8eeffefb01b5d858}
      \strng{authorfullhash}{d864d5bda54f2ca7ebae6eab9b8adafe}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Transfer learning has recently become the dominant paradigm of machine learning. Pre-trained models fine-tuned for downstream tasks achieve better performance with fewer labelled examples. Nonetheless, it remains unclear how to develop models that specialise towards multiple tasks without incurring negative interference and that generalise systematically to non-identically distributed tasks. Modular deep learning has emerged as a promising solution to these challenges. In this framework, units of computation are often implemented as autonomous parameter-efficient modules. Information is conditionally routed to a subset of modules and subsequently aggregated. These properties enable positive transfer and systematic generalisation by separating computation from routing and updating modules locally. We offer a survey of modular architectures, providing a unified view over several threads of research that evolved independently in the scientific literature. Moreover, we explore various additional purposes of modularity, including scaling language models, causal inference, programme induction, and planning in reinforcement learning. Finally, we report various concrete applications where modularity has been successfully deployed such as cross-lingual and cross-modal knowledge transfer. Related talks and projects to this survey, are available at https://www.modulardeeplearning.com/.}
      \field{month}{1}
      \field{title}{Modular {Deep} {Learning}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{urldateera}{ce}
      \true{nocite}
      \verb{doi}
      \verb 10.48550/arXiv.2302.11529
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/Y9T7A5NR/Pfeiffer et al. - 2024 - Modular Deep Learning.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/GV67UMSV/2302.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2302.11529
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2302.11529
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{plewes_physics_2012}{article}{}
      \name{author}{2}{}{%
        {{hash=dab6388f21cc96cd93434d6cb9af486b}{%
           family={Plewes},
           familyi={P\bibinitperiod},
           given={Donald\bibnamedelima B.},
           giveni={D\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{hash=3941f109a41b228f6a8cb61e0a731fbd}{%
           family={Kucharczyk},
           familyi={K\bibinitperiod},
           given={Walter},
           giveni={W\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{79b006dbf98ff16477996418693fa7d3}
      \strng{fullhash}{79b006dbf98ff16477996418693fa7d3}
      \strng{bibnamehash}{79b006dbf98ff16477996418693fa7d3}
      \strng{authorbibnamehash}{79b006dbf98ff16477996418693fa7d3}
      \strng{authornamehash}{79b006dbf98ff16477996418693fa7d3}
      \strng{authorfullhash}{79b006dbf98ff16477996418693fa7d3}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This article is based on an introductory lecture given for the past many years during the “MR Physics and Techniques for Clinicians” course at the Annual Meeting of the ISMRM. This introduction is not intended to be a comprehensive overview of the field, as the subject of magnetic resonance imaging (MRI) physics is large and complex. Rather, it is intended to lay a conceptual foundation by which magnetic resonance image formation can be understood from an intuitive perspective. The presentation is nonmathematical, relying on simple models that take the reader progressively from the basic spin physics of nuclei, through descriptions of how the magnetic resonance signal is generated and detected in an MRI scanner, the foundations of nuclear magnetic resonance (NMR) relaxation, and a discussion of the Fourier transform and its relation to MR image formation. The article continues with a discussion of how magnetic field gradients are used to facilitate spatial encoding and concludes with a development of basic pulse sequences and the factors defining image contrast. J. Magn. Reson. Imaging 2012;35:1038-1054. © 2012 Wiley Periodicals, Inc.}
      \field{issn}{1522-2586}
      \field{journaltitle}{Journal of Magnetic Resonance Imaging}
      \field{number}{5}
      \field{shorttitle}{Physics of {MRI}}
      \field{title}{Physics of {MRI}: {A} primer}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{35}
      \field{year}{2012}
      \field{urldateera}{ce}
      \field{pages}{1038\bibrangedash 1054}
      \range{pages}{17}
      \verb{doi}
      \verb 10.1002/jmri.23642
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/U4BM5R8G/Plewes and Kucharczyk - 2012 - Physics of MRI A primer.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/DN6IQGX7/jmri.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.23642
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.23642
      \endverb
      \keyw{k-space,MRI image formation,MRI physics,NMR relaxation}
    \endentry
    \entry{prechelt_early_1998}{incollection}{}
      \name{author}{1}{}{%
        {{hash=c33e375f7c45363931f7e4ffe01192cc}{%
           family={Prechelt},
           familyi={P\bibinitperiod},
           given={Lutz},
           giveni={L\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=ea9de995dd928a60e9f2ec878f176627}{%
           family={Orr},
           familyi={O\bibinitperiod},
           given={Genevieve\bibnamedelima B.},
           giveni={G\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{hash=9f1b6144a45b1967e989e74552e37ada}{%
           family={Müller},
           familyi={M\bibinitperiod},
           given={Klaus-Robert},
           giveni={K\bibinithyphendelim R\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{c33e375f7c45363931f7e4ffe01192cc}
      \strng{fullhash}{c33e375f7c45363931f7e4ffe01192cc}
      \strng{bibnamehash}{c33e375f7c45363931f7e4ffe01192cc}
      \strng{authorbibnamehash}{c33e375f7c45363931f7e4ffe01192cc}
      \strng{authornamehash}{c33e375f7c45363931f7e4ffe01192cc}
      \strng{authorfullhash}{c33e375f7c45363931f7e4ffe01192cc}
      \strng{editorbibnamehash}{bc30a6a4a7cd5205b397256133ad7b2a}
      \strng{editornamehash}{bc30a6a4a7cd5205b397256133ad7b2a}
      \strng{editorfullhash}{bc30a6a4a7cd5205b397256133ad7b2a}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Validation can be used to detect when overfitting starts during supervised training of a neural network; training is then stopped before convergence to avoid the overfitting (“early stopping”). The exact criterion used for validation-based early stopping, however, is usually chosen in an ad-hoc fashion or training is stopped interactively. This trick describes how to select a stopping criterion in a systematic fashion; it is a trick for either speeding learning procedures or improving generalization, whichever is more important in the particular situation. An empirical investigation on multi-layer perceptrons shows that there exists a tradeoff between training time and generalization: From the given mix of 1296 training runs using difierent 12 problems and 24 difierent network architectures I conclude slower stopping criteria allow for small improvements in generalization (here: about 4\% on average), but cost much more training time (here: about factor 4 longer on average).}
      \field{booktitle}{Neural {Networks}: {Tricks} of the {Trade}}
      \field{isbn}{978-3-540-49430-0}
      \field{title}{Early {Stopping} - {But} {When}?}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{1998}
      \field{urldateera}{ce}
      \true{nocite}
      \field{pages}{55\bibrangedash 69}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1007/3-540-49430-8_3
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/NF7I984X/Prechelt - 1998 - Early Stopping - But When.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/3-540-49430-8_3
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/3-540-49430-8_3
      \endverb
      \keyw{Early Stopping,Generalization Error,Neural Information Processing System,Training Time,Validation Error}
    \endentry
    \entry{radford_improving_nodate}{article}{}
      \name{author}{4}{}{%
        {{hash=a812c46caad94fc8701be37871f303ba}{%
           family={Radford},
           familyi={R\bibinitperiod},
           given={Alec},
           giveni={A\bibinitperiod}}}%
        {{hash=997c3143c2e5d593e816d2ff704fbf98}{%
           family={Narasimhan},
           familyi={N\bibinitperiod},
           given={Karthik},
           giveni={K\bibinitperiod}}}%
        {{hash=e6f76e1a4d058df028530916774ad3a7}{%
           family={Salimans},
           familyi={S\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod}}}%
        {{hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{ca3baa5a22057195db1c71be39b4c922}
      \strng{fullhash}{fbc85d06f02fc1534a6ba28d0d6e5c89}
      \strng{bibnamehash}{ca3baa5a22057195db1c71be39b4c922}
      \strng{authorbibnamehash}{ca3baa5a22057195db1c71be39b4c922}
      \strng{authornamehash}{ca3baa5a22057195db1c71be39b4c922}
      \strng{authorfullhash}{fbc85d06f02fc1534a6ba28d0d6e5c89}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task. In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).}
      \field{title}{Improving {Language} {Understanding} by {Generative} {Pre}-{Training}}
      \verb{file}
      \verb Radford et al. - Improving Language Understanding by Generative Pre.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/9I5FJD5T/Radford et al. - Improving Language Understanding by Generative Pre.pdf:application/pdf
      \endverb
    \endentry
    \entry{rao_transform_2018}{book}{}
      \name{author}{2}{}{%
        {{hash=78db54f48458b24a3a3b8cdc14aa348d}{%
           family={Rao},
           familyi={R\bibinitperiod},
           given={Kamisetty\bibnamedelima Ramam},
           giveni={K\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=d1a161fcb2ca10f80b081349e295833e}{%
           family={Yip},
           familyi={Y\bibinitperiod},
           given={Patrick\bibnamedelima C.},
           giveni={P\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {CRC Press}%
      }
      \strng{namehash}{d9c80abc30dafde9a5fb32d70a92e9b1}
      \strng{fullhash}{d9c80abc30dafde9a5fb32d70a92e9b1}
      \strng{bibnamehash}{d9c80abc30dafde9a5fb32d70a92e9b1}
      \strng{authorbibnamehash}{d9c80abc30dafde9a5fb32d70a92e9b1}
      \strng{authornamehash}{d9c80abc30dafde9a5fb32d70a92e9b1}
      \strng{authorfullhash}{d9c80abc30dafde9a5fb32d70a92e9b1}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Data compression is one of the main contributing factors in the explosive growth in information technology. Without it, a number of consumer and commercial products, such as DVD, videophone, digital camera, MP3, video-streaming and wireless PCS, would have been virtually impossible. Transforming the data to a frequency or other domain enables even more efficient compression. By illustrating this intimate link, The Transform and Data Compression Handbook serves as a much-needed handbook for a wide range of researchers and engineers.The authors describe various discrete transforms and their applications in different disciplines. They cover techniques, such as adaptive quantization and entropy coding, that result in significant reduction in bit rates when applied to the transform coefficients. With clear and concise presentations of the ideas and concepts, as well as detailed descriptions of the algorithms, the authors provide important insight into the applications and their limitations. Data compression is an essential step towards the efficient storage and transmission of information. The Transform and Data Compression Handbook provides a wealth of information regarding different discrete transforms and demonstrates their power and practicality in data compression.}
      \field{isbn}{978-1-4200-3738-8}
      \field{month}{10}
      \field{note}{Google-Books-ID: EgvOBQAAQBAJ}
      \field{title}{The {Transform} and {Data} {Compression} {Handbook}}
      \field{year}{2018}
      \verb{file}
      \verb Rao and Yip - 2018 - The Transform and Data Compression Handbook.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/9BJEL5YW/Rao and Yip - 2018 - The Transform and Data Compression Handbook.pdf:application/pdf
      \endverb
      \keyw{Computers / Computer Science,Computers / Computer Engineering,Computers / General,Technology \& Engineering / Electrical,Technology \& Engineering / Environmental / General,Technology \& Engineering / Telecommunications,psnr}
    \endentry
    \entry{raskutti_early_2013}{misc}{}
      \name{author}{3}{}{%
        {{hash=ca850c174a51d59e1eb217b5f4f06f73}{%
           family={Raskutti},
           familyi={R\bibinitperiod},
           given={Garvesh},
           giveni={G\bibinitperiod}}}%
        {{hash=7eb03239453694f59946ad6008e9f0ab}{%
           family={Wainwright},
           familyi={W\bibinitperiod},
           given={Martin\bibnamedelima J.},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=43d22dc81cc0e5bb1d24d5eeb65ecbae}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Bin},
           giveni={B\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{763e93770718ba3c8abcf4cf1d22d6f0}
      \strng{fullhash}{763e93770718ba3c8abcf4cf1d22d6f0}
      \strng{bibnamehash}{763e93770718ba3c8abcf4cf1d22d6f0}
      \strng{authorbibnamehash}{763e93770718ba3c8abcf4cf1d22d6f0}
      \strng{authornamehash}{763e93770718ba3c8abcf4cf1d22d6f0}
      \strng{authorfullhash}{763e93770718ba3c8abcf4cf1d22d6f0}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The strategy of early stopping is a regularization technique based on choosing a stopping time for an iterative algorithm. Focusing on non-parametric regression in a reproducing kernel Hilbert space, we analyze the early stopping strategy for a form of gradient-descent applied to the least-squares loss function. We propose a data-dependent stopping rule that does not involve hold-out or cross-validation data, and we prove upper bounds on the squared error of the resulting function estimate, measured in either the L2(P) and L2(Pn) norm. These upper bounds lead to minimax-optimal rates for various kernel classes, including Sobolev smoothness classes and other forms of reproducing kernel Hilbert spaces. We show through simulation that our stopping rule compares favorably to two other stopping rules, one based on hold-out data and the other based on Stein’s unbiased risk estimate. We also establish a tight connection between our early stopping strategy and the solution path of a kernel ridge regression estimator.}
      \field{annotation}{Comment: 29 pages, 4 figures}
      \field{month}{6}
      \field{note}{arXiv:1306.3574 [stat]}
      \field{shorttitle}{Early stopping and non-parametric regression}
      \field{title}{Early stopping and non-parametric regression: {An} optimal data-dependent stopping rule}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2013}
      \field{urldateera}{ce}
      \verb{file}
      \verb Raskutti et al. - 2013 - Early stopping and non-parametric regression An o.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/RATUHVKE/Raskutti et al. - 2013 - Early stopping and non-parametric regression An o.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1306.3574
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1306.3574
      \endverb
      \keyw{Statistics - Machine Learning}
    \endentry
    \entry{reback_pandas-devpandas_2020}{article}{}
      \name{author}{30}{}{%
        {{hash=88cea9aa14a14b77b77c448ed339cf89}{%
           family={Reback},
           familyi={R\bibinitperiod},
           given={Jeff},
           giveni={J\bibinitperiod}}}%
        {{hash=27ca77940a5e8c07c5d89d0f3fb11d75}{%
           family={McKinney},
           familyi={M\bibinitperiod},
           given={Wes},
           giveni={W\bibinitperiod}}}%
        {{hash=0fa2de4afde6f6ce625f9fd8c033cf02}{%
           family={{Jbrockmendel}},
           familyi={J\bibinitperiod}}}%
        {{hash=d0d379365636f8aff7fababea695d5bf}{%
           family={Van\bibnamedelimb Den\bibnamedelima Bossche},
           familyi={V\bibinitperiod\bibinitdelim D\bibinitperiod\bibinitdelim B\bibinitperiod},
           given={Joris},
           giveni={J\bibinitperiod}}}%
        {{hash=bbb9cae798de875fe375cd78fdbc05e8}{%
           family={Augspurger},
           familyi={A\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod}}}%
        {{hash=abc7b63653501dcb1794fe47649d32fb}{%
           family={Cloud},
           familyi={C\bibinitperiod},
           given={Phillip},
           giveni={P\bibinitperiod}}}%
        {{hash=344bc406fde6523a12ad6355eaae76a4}{%
           family={{Gfyoung}},
           familyi={G\bibinitperiod}}}%
        {{hash=dd396216bc8e4f0e57427ec2f40a063c}{%
           family={{Sinhrks}},
           familyi={S\bibinitperiod}}}%
        {{hash=21b3ea5a26c08468a71447b0480ba5e0}{%
           family={Klein},
           familyi={K\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod}}}%
        {{hash=05a873b337f2c6603299a4eab9c72bce}{%
           family={Hawkins},
           familyi={H\bibinitperiod},
           given={Simon},
           giveni={S\bibinitperiod}}}%
        {{hash=48bdfdba683afce467f4559c881080f7}{%
           family={Roeschke},
           familyi={R\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=b2cd15c7b8d39b42c79b601904fe9110}{%
           family={Tratner},
           familyi={T\bibinitperiod},
           given={Jeff},
           giveni={J\bibinitperiod}}}%
        {{hash=e5b2df24fc3f9501192f6fa8c86a8373}{%
           family={She},
           familyi={S\bibinitperiod},
           given={Chang},
           giveni={C\bibinitperiod}}}%
        {{hash=665dc01efe9b675a766324925065b8b6}{%
           family={Ayd},
           familyi={A\bibinitperiod},
           given={William},
           giveni={W\bibinitperiod}}}%
        {{hash=e38b1c3e125c1eab4d5930f277e5846e}{%
           family={Petersen},
           familyi={P\bibinitperiod},
           given={Terji},
           giveni={T\bibinitperiod}}}%
        {{hash=01c0d7203a1be3d57abac0a453d34a53}{%
           family={{MomIsBestFriend}},
           familyi={M\bibinitperiod}}}%
        {{hash=df1d62a915f9a5c2173c22f3ea49126a}{%
           family={Garcia},
           familyi={G\bibinitperiod},
           given={Marc},
           giveni={M\bibinitperiod}}}%
        {{hash=4de45d2a9753098448d3ac1300d20295}{%
           family={Schendel},
           familyi={S\bibinitperiod},
           given={Jeremy},
           giveni={J\bibinitperiod}}}%
        {{hash=8cb6fdf3ed3fa0c34b89d9963b71b831}{%
           family={Hayden},
           familyi={H\bibinitperiod},
           given={Andy},
           giveni={A\bibinitperiod}}}%
        {{hash=4493983240f034b1591aacbf7a02a5e1}{%
           family={Jancauskas},
           familyi={J\bibinitperiod},
           given={Vytautas},
           giveni={V\bibinitperiod}}}%
        {{hash=cf8522fe7e08c0bd7420988c289c2e06}{%
           family={Battiston},
           familyi={B\bibinitperiod},
           given={Pietro},
           giveni={P\bibinitperiod}}}%
        {{hash=bb340b8100ad532f076751d9dc3d9269}{%
           family={Saxton},
           familyi={S\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=d1d252dd6b4a79206fc21966d6b35923}{%
           family={Seabold},
           familyi={S\bibinitperiod},
           given={Skipper},
           giveni={S\bibinitperiod}}}%
        {{hash=a7d2ea52976da8941d0184821530a2ae}{%
           family={{Alimcmaster1}},
           familyi={A\bibinitperiod}}}%
        {{hash=9e5183b5d21e2185ed51809ce92043f5}{%
           family={{Chris-B1}},
           familyi={C\bibinitperiod}}}%
        {{hash=80c1ae64f988c62c812604864802eaac}{%
           family={{H-Vetinari}},
           familyi={H\bibinitperiod}}}%
        {{hash=4a22828b76006f42d747b699d2ef5167}{%
           family={Hoyer},
           familyi={H\bibinitperiod},
           given={Stephan},
           giveni={S\bibinitperiod}}}%
        {{hash=b84b55910fa969a7b4c3f827b60d7177}{%
           family={Dong},
           familyi={D\bibinitperiod},
           given={Kaiqi},
           giveni={K\bibinitperiod}}}%
        {{hash=c10c0fcb094b1fb5f266bd68daa14806}{%
           family={Overmeire},
           familyi={O\bibinitperiod},
           given={Wouter},
           giveni={W\bibinitperiod}}}%
        {{hash=0a687b86f653c1bf34018d7a58435a7a}{%
           family={Winkel},
           familyi={W\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{65bc8de17d9fc3f38d448b6bcb2d28a2}
      \strng{fullhash}{90110734d0f22c25c292a79aa6dff346}
      \strng{bibnamehash}{65bc8de17d9fc3f38d448b6bcb2d28a2}
      \strng{authorbibnamehash}{65bc8de17d9fc3f38d448b6bcb2d28a2}
      \strng{authornamehash}{65bc8de17d9fc3f38d448b6bcb2d28a2}
      \strng{authorfullhash}{90110734d0f22c25c292a79aa6dff346}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This is a minor bug-fix release in the 1.0.x series and includes some regression fixes and bug fixes. We recommend that all users upgrade to this version. See the full whatsnew for a list of all the changes. The release will be available on the defaults and conda-forge channels: conda install pandas Or via PyPI: python3 -m pip install --upgrade pandas Please report any issues with the release on the pandas issue tracker.}
      \field{journaltitle}{Zenodo}
      \field{month}{6}
      \field{shorttitle}{pandas-dev/pandas}
      \field{title}{pandas-dev/pandas: {Pandas} 1.0.5}
      \field{urlday}{12}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.5281/zenodo.3898987
      \endverb
      \verb{urlraw}
      \verb https://ui.adsabs.harvard.edu/abs/2020zndo...3898987R
      \endverb
      \verb{url}
      \verb https://ui.adsabs.harvard.edu/abs/2020zndo...3898987R
      \endverb
    \endentry
    \entry{RelaxationlongitudinalmagnetizationSpinlatticerelaxationWikipedia-2024-05-01}{misc}{}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labeltitlesource}{title}
      \field{day}{1}
      \field{month}{5}
      \field{title}{Relaxation longitudinal magnetization - Spin–lattice relaxation - Wikipedia}
      \field{urlday}{7}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb :./references/wiki-Spin%E2%80%93lattice_relaxation.html:html
      \endverb
      \verb{urlraw}
      \verb https://en.wikipedia.org/wiki/Spin%E2%80%93lattice_relaxation#/media/File:Relaxation_longitudinal_magnetization.svg
      \endverb
      \verb{url}
      \verb https://en.wikipedia.org/wiki/Spin%E2%80%93lattice_relaxation#/media/File:Relaxation_longitudinal_magnetization.svg
      \endverb
    \endentry
    \entry{RelaxationtransversemagnetizationSpinspinrelaxationWikipedia-2024-05-01}{misc}{}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labeltitlesource}{title}
      \field{day}{1}
      \field{month}{5}
      \field{title}{Relaxation transverse magnetization - Spin–spin relaxation - Wikipedia}
      \field{urlday}{7}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb :./references/wiki-Spin%E2%80%93spin_relaxation.html:html
      \endverb
      \verb{urlraw}
      \verb https://en.wikipedia.org/wiki/Spin%E2%80%93spin_relaxation#/media/File:Relaxation_transverse_magnetization.svg
      \endverb
      \verb{url}
      \verb https://en.wikipedia.org/wiki/Spin%E2%80%93spin_relaxation#/media/File:Relaxation_transverse_magnetization.svg
      \endverb
    \endentry
    \entry{rombach_high-resolution_2022}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=0921e3810ca1ba112b5f374d82f0735f}{%
           family={Rombach},
           familyi={R\bibinitperiod},
           given={Robin},
           giveni={R\bibinitperiod}}}%
        {{hash=43a95cf5d0fe271fe6d6d0e5803cbfc9}{%
           family={Blattmann},
           familyi={B\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod}}}%
        {{hash=809ae73566d8d76e9931ffde3969f1dc}{%
           family={Lorenz},
           familyi={L\bibinitperiod},
           given={Dominik},
           giveni={D\bibinitperiod}}}%
        {{hash=e61c1cb5e29d764299a12d1ab334cdc2}{%
           family={Esser},
           familyi={E\bibinitperiod},
           given={Patrick},
           giveni={P\bibinitperiod}}}%
        {{hash=e5a040243464f368c0ac690deabc8731}{%
           family={Ommer},
           familyi={O\bibinitperiod},
           given={Bjorn},
           giveni={B\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {New Orleans, LA, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{b5bfcd95459df0d66c58a299cbec3e9a}
      \strng{fullhash}{31a3b0d904c7d14f5af157452068b121}
      \strng{bibnamehash}{b5bfcd95459df0d66c58a299cbec3e9a}
      \strng{authorbibnamehash}{b5bfcd95459df0d66c58a299cbec3e9a}
      \strng{authornamehash}{b5bfcd95459df0d66c58a299cbec3e9a}
      \strng{authorfullhash}{31a3b0d904c7d14f5af157452068b121}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and ﬂexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the ﬁrst time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual ﬁdelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and ﬂexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve new state of the art scores for image inpainting and class-conditional image synthesis and highly competitive performance on various tasks, including unconditional image generation, text-to-image synthesis, and super-resolution, while signiﬁcantly reducing computational requirements compared to pixel-based DMs.}
      \field{booktitle}{2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})}
      \field{isbn}{978-1-66546-946-3}
      \field{month}{6}
      \field{title}{High-{Resolution} {Image} {Synthesis} with {Latent} {Diffusion} {Models}}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \field{pages}{10674\bibrangedash 10685}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/CVPR52688.2022.01042
      \endverb
      \verb{file}
      \verb Rombach et al. - 2022 - High-Resolution Image Synthesis with Latent Diffus.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/SHRPWNXA/Rombach et al. - 2022 - High-Resolution Image Synthesis with Latent Diffus.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9878449/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9878449/
      \endverb
    \endentry
    \entry{ronneberger_u-net_2015}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=8e46da9de9e53ea5d37089897d69cdd9}{%
           family={Ronneberger},
           familyi={R\bibinitperiod},
           given={Olaf},
           giveni={O\bibinitperiod}}}%
        {{hash=168e84ce3582cbc6bac5e2ebc3ef8442}{%
           family={Fischer},
           familyi={F\bibinitperiod},
           given={Philipp},
           giveni={P\bibinitperiod}}}%
        {{hash=b452a32296958371572717940f900884}{%
           family={Brox},
           familyi={B\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
      }
      \name{editor}{4}{}{%
        {{hash=c107bbd317cd780c2aa7006dbe61d83f}{%
           family={Navab},
           familyi={N\bibinitperiod},
           given={Nassir},
           giveni={N\bibinitperiod}}}%
        {{hash=13dfdbfc375d5ae886268dec73d8d8f9}{%
           family={Hornegger},
           familyi={H\bibinitperiod},
           given={Joachim},
           giveni={J\bibinitperiod}}}%
        {{hash=4d166f6210ae1792f8f90d7871b4d234}{%
           family={Wells},
           familyi={W\bibinitperiod},
           given={William\bibnamedelima M.},
           giveni={W\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=2413defb142650e8edf0bcd5608ab789}{%
           family={Frangi},
           familyi={F\bibinitperiod},
           given={Alejandro\bibnamedelima F.},
           giveni={A\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{f23ccc5160c62c7866172335b2c76e11}
      \strng{fullhash}{f23ccc5160c62c7866172335b2c76e11}
      \strng{bibnamehash}{f23ccc5160c62c7866172335b2c76e11}
      \strng{authorbibnamehash}{f23ccc5160c62c7866172335b2c76e11}
      \strng{authornamehash}{f23ccc5160c62c7866172335b2c76e11}
      \strng{authorfullhash}{f23ccc5160c62c7866172335b2c76e11}
      \strng{editorbibnamehash}{7d63d752dc1fd3abad4ee5f250821c1c}
      \strng{editornamehash}{7d63d752dc1fd3abad4ee5f250821c1c}
      \strng{editorfullhash}{33938a515d73fb8b00fd2bd7509d5e86}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.}
      \field{booktitle}{Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2015}
      \field{isbn}{978-3-319-24574-4}
      \field{shorttitle}{U-{Net}}
      \field{title}{U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}}
      \field{year}{2015}
      \field{pages}{234\bibrangedash 241}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1007/978-3-319-24574-4_28
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/YSDCAGJG/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf
      \endverb
      \keyw{Convolutional Layer,Data Augmentation,Deep Network,Ground Truth Segmentation,Training Image}
    \endentry
    \entry{rosenblatt_perceptron_1958}{article}{}
      \name{author}{1}{}{%
        {{hash=1750cd87a34d44119e7a4aab9b8012c6}{%
           family={Rosenblatt},
           familyi={R\bibinitperiod},
           given={F.},
           giveni={F\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {eng}%
      }
      \strng{namehash}{1750cd87a34d44119e7a4aab9b8012c6}
      \strng{fullhash}{1750cd87a34d44119e7a4aab9b8012c6}
      \strng{bibnamehash}{1750cd87a34d44119e7a4aab9b8012c6}
      \strng{authorbibnamehash}{1750cd87a34d44119e7a4aab9b8012c6}
      \strng{authornamehash}{1750cd87a34d44119e7a4aab9b8012c6}
      \strng{authorfullhash}{1750cd87a34d44119e7a4aab9b8012c6}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{issn}{0033-295X}
      \field{journaltitle}{Psychological Review}
      \field{month}{11}
      \field{number}{6}
      \field{shorttitle}{The perceptron}
      \field{title}{The perceptron: a probabilistic model for information storage and organization in the brain}
      \field{volume}{65}
      \field{year}{1958}
      \field{pages}{386\bibrangedash 408}
      \range{pages}{23}
      \verb{doi}
      \verb 10.1037/h0042519
      \endverb
      \keyw{Brain,Humans,Information Storage and Retrieval,Models,Statistical,Neural Networks,Computer,Perception,PERCEPTION}
    \endentry
    \entry{ruder_overview_2017}{misc}{}
      \name{author}{1}{}{%
        {{hash=b468248a20d75c52ee742f4592c2569f}{%
           family={Ruder},
           familyi={R\bibinitperiod},
           given={Sebastian},
           giveni={S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b468248a20d75c52ee742f4592c2569f}
      \strng{fullhash}{b468248a20d75c52ee742f4592c2569f}
      \strng{bibnamehash}{b468248a20d75c52ee742f4592c2569f}
      \strng{authorbibnamehash}{b468248a20d75c52ee742f4592c2569f}
      \strng{authornamehash}{b468248a20d75c52ee742f4592c2569f}
      \strng{authorfullhash}{b468248a20d75c52ee742f4592c2569f}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Multi-task learning (MTL) has led to successes in many applications of machine learning, from natural language processing and speech recognition to computer vision and drug discovery. This article aims to give a general overview of MTL, particularly in deep neural networks. It introduces the two most common methods for MTL in Deep Learning, gives an overview of the literature, and discusses recent advances. In particular, it seeks to help ML practitioners apply MTL by shedding light on how MTL works and providing guidelines for choosing appropriate auxiliary tasks.}
      \field{annotation}{Comment: 14 pages, 8 figures}
      \field{month}{6}
      \field{title}{An {Overview} of {Multi}-{Task} {Learning} in {Deep} {Neural} {Networks}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1706.05098
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/2UYZNWBZ/Ruder - 2017 - An Overview of Multi-Task Learning in Deep Neural .pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/KYGZCLLP/1706.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1706.05098
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1706.05098
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Artificial Intelligence,Statistics - Machine Learning}
    \endentry
    \entry{scheffler_pictorial_1999}{article}{}
      \name{author}{1}{}{%
        {{hash=d32aa293ed7ed32a40025c81e59197f9}{%
           family={Scheffler},
           familyi={S\bibinitperiod},
           given={Klaus},
           giveni={K\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{d32aa293ed7ed32a40025c81e59197f9}
      \strng{fullhash}{d32aa293ed7ed32a40025c81e59197f9}
      \strng{bibnamehash}{d32aa293ed7ed32a40025c81e59197f9}
      \strng{authorbibnamehash}{d32aa293ed7ed32a40025c81e59197f9}
      \strng{authornamehash}{d32aa293ed7ed32a40025c81e59197f9}
      \strng{authorfullhash}{d32aa293ed7ed32a40025c81e59197f9}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Magnetic resonance imaging in biochemical and clinical research requires rapid imaging sequences. Time-resolved imaging of heart movement and the acquisition of a three-dimensional image block within the circulation time of a contrast agent bolus are two typical examples. Rapid imaging sequences are characterized by a very fast train of radiofrequency (rf) and gradient pulses. Between these rf pulses, the excited magnetization is unable to return to its thermal equilibrium. As a consequence, further rf pulses will influence both the remaining transversal and the remaining equilibrium state. The steady-state magnetization of a multi-rf pulse and gradient pulse experiment is thus a mixture or superposition of different transversal and longitudinal states and the acquired image amplitude becomes a complex function of the investigated tissue's relaxation properties. Based on the works of Woessner, Kaiser, and Hennig, this article intends to give a pictorial description of rapid multipulse imaging experiments. It also provides an extension of this theory applied to modern imaging sequences such as TRUE FISP and rf-spoiled techniques. ©1999 John Wiley \& Sons, Inc. Concepts Magn Reson 11: 291–304, 1999}
      \field{issn}{1099-0534}
      \field{journaltitle}{Concepts in Magnetic Resonance}
      \field{number}{5}
      \field{title}{A pictorial description of steady-states in rapid magnetic resonance imaging}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{11}
      \field{year}{1999}
      \field{urldateera}{ce}
      \true{nocite}
      \field{pages}{291\bibrangedash 304}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1002/(SICI)1099-0534(1999)11:5<291::AID-CMR2>3.0.CO;2-J
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/2HGA8NQB/Scheffler - 1999 - A pictorial description of steady-states in rapid .pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/2HD3SBLV/(SICI)1099-0534(1999)115291AID-CMR23.0.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-0534%281999%2911%3A5%3C291%3A%3AAID-CMR2%3E3.0.CO%3B2-J
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-0534%281999%2911%3A5%3C291%3A%3AAID-CMR2%3E3.0.CO%3B2-J
      \endverb
      \keyw{phase–graph description,rapid imaging,refocusing,rf spoiling,steady-state}
    \endentry
    \entry{scheffler_principles_2003}{article}{}
      \name{author}{2}{}{%
        {{hash=d32aa293ed7ed32a40025c81e59197f9}{%
           family={Scheffler},
           familyi={S\bibinitperiod},
           given={Klaus},
           giveni={K\bibinitperiod}}}%
        {{hash=905908644a7eaa19ad8f96b36104b174}{%
           family={Lehnhardt},
           familyi={L\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{eb6016623020320c534af33a1b96959a}
      \strng{fullhash}{eb6016623020320c534af33a1b96959a}
      \strng{bibnamehash}{eb6016623020320c534af33a1b96959a}
      \strng{authorbibnamehash}{eb6016623020320c534af33a1b96959a}
      \strng{authornamehash}{eb6016623020320c534af33a1b96959a}
      \strng{authorfullhash}{eb6016623020320c534af33a1b96959a}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{During the past 5 years balanced steady-state free precession (SSFP) has become increasingly important for diagnostic and functional imaging. Balanced SSFP is characterized by two unique features: it offers a very high signal-to noise ratio and a T2/T1-weighted image contrast. This article focuses on the physical principles, on the signal formation, and on the resulting properties of balanced SSFP. Mechanisms for contrast modification, recent clinical application, and potential extensions of this technique are discussed.}
      \field{issn}{1432-1084}
      \field{journaltitle}{European Radiology}
      \field{month}{11}
      \field{number}{11}
      \field{title}{Principles and applications of balanced {SSFP} techniques}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{13}
      \field{year}{2003}
      \field{urldateera}{ce}
      \field{pages}{2409\bibrangedash 2418}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1007/s00330-003-1957-x
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/JEMGZAVM/Scheffler and Lehnhardt - 2003 - Principles and applications of balanced SSFP techn.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s00330-003-1957-x
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s00330-003-1957-x
      \endverb
      \keyw{Contrast modification,Rapid imaging,Transient phase}
    \endentry
    \entry{noauthor_segmentation_nodate}{misc}{}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labeltitlesource}{title}
      \field{abstract}{The ImageJ wiki is a community-edited knowledge base on topics relating to ImageJ, a public domain program for processing and analyzing scientific images, and its ecosystem of derivatives and variants, including ImageJ2, Fiji, and others.}
      \field{journaltitle}{ImageJ Wiki}
      \field{title}{Segmentation of neuronal structures in {EM} stacks challenge - {ISBI} 2012}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb https://imagej.github.io/events/isbi-2012-segmentation-challenge
      \endverb
      \verb{url}
      \verb https://imagej.github.io/events/isbi-2012-segmentation-challenge
      \endverb
    \endentry
    \entry{sener_diffusion_2001}{article}{}
      \name{author}{1}{}{%
        {{hash=1370a46d7df227f9039dc08ed8ada12d}{%
           family={Sener},
           familyi={S\bibinitperiod},
           given={R.\bibnamedelimi N.},
           giveni={R\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
      }
      \strng{namehash}{1370a46d7df227f9039dc08ed8ada12d}
      \strng{fullhash}{1370a46d7df227f9039dc08ed8ada12d}
      \strng{bibnamehash}{1370a46d7df227f9039dc08ed8ada12d}
      \strng{authorbibnamehash}{1370a46d7df227f9039dc08ed8ada12d}
      \strng{authornamehash}{1370a46d7df227f9039dc08ed8ada12d}
      \strng{authorfullhash}{1370a46d7df227f9039dc08ed8ada12d}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Diffusion-weighted imaging, dependent on motion of water molecules, provides information regarding tissue integrity. Apparent diffusion coefficient (ADC) values in the normal brain parenchyma, and those in a variety of lesions were studied by echo-planar diffusion MRI in 310 cases. Brain disorders were classified based on their ADC values, taking the ADC values of the normal brain white matter as the principal category. In the normal white matter ADC ranges were 0.60–1.05×10−3mm2/s, and the mean ADC value was 0.84±0.11×10−3mm2/s. It was possible to distribute brain disorders, as well as artefacts on diffusion MRI to five major categories: category 1, ADC similar to normal white matter; category 2, ADC lower than normal white matter; category 3, ADC higher than normal white matter; category 4, ADC similar to CSF; and category 5, markedly low or high ADC. Further studies can provide addition of different lesions as well as refinements of these categories.}
      \field{issn}{0895-6111}
      \field{journaltitle}{Computerized Medical Imaging and Graphics}
      \field{month}{7}
      \field{number}{4}
      \field{shorttitle}{Diffusion {MRI}}
      \field{title}{Diffusion {MRI}: apparent diffusion coefficient ({ADC}) values in the normal brain and a classification of brain disorders based on {ADC} values}
      \field{urlday}{8}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{25}
      \field{year}{2001}
      \field{urldateera}{ce}
      \field{pages}{299\bibrangedash 326}
      \range{pages}{28}
      \verb{doi}
      \verb 10.1016/S0895-6111(00)00083-5
      \endverb
      \verb{file}
      \verb ScienceDirect Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/RK9G65YN/S0895611100000835.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S0895611100000835
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S0895611100000835
      \endverb
      \keyw{Apparent diffusion coefficient,Classification of brain disorders,diffusion MRI,Diffusion-weighted MR imaging,Normal brain,diffusion MRI}
    \endentry
    \entry{smith_advances_2004}{article}{}
      \name{author}{17}{}{%
        {{hash=1b067e83d2e7008cdc1841a1e60c00b5}{%
           family={Smith},
           familyi={S\bibinitperiod},
           given={Stephen\bibnamedelima M.},
           giveni={S\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=02d16eb5d8b0d0af1320675587ee5db5}{%
           family={Jenkinson},
           familyi={J\bibinitperiod},
           given={Mark},
           giveni={M\bibinitperiod}}}%
        {{hash=57654ae9231add44292c54a4d8c1b1cb}{%
           family={Woolrich},
           familyi={W\bibinitperiod},
           given={Mark\bibnamedelima W.},
           giveni={M\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{hash=56a749db558d861e966e01fe85120986}{%
           family={Beckmann},
           familyi={B\bibinitperiod},
           given={Christian\bibnamedelima F.},
           giveni={C\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
        {{hash=c946e197e64894a34f519dac9275ae75}{%
           family={Behrens},
           familyi={B\bibinitperiod},
           given={Timothy\bibnamedelimb E.\bibnamedelimi J.},
           giveni={T\bibinitperiod\bibinitdelim E\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=667eb1348fdf01d4e0014e6c88c90b10}{%
           family={Johansen-Berg},
           familyi={J\bibinithyphendelim B\bibinitperiod},
           given={Heidi},
           giveni={H\bibinitperiod}}}%
        {{hash=4ac869af5f89a131d7bf356ad758e4f6}{%
           family={Bannister},
           familyi={B\bibinitperiod},
           given={Peter\bibnamedelima R.},
           giveni={P\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=ae9d61c73f4cf9bb9cf903785463129d}{%
           family={De\bibnamedelima Luca},
           familyi={D\bibinitperiod\bibinitdelim L\bibinitperiod},
           given={Marilena},
           giveni={M\bibinitperiod}}}%
        {{hash=58147d5d08d75cb4ce218ce1f92101aa}{%
           family={Drobnjak},
           familyi={D\bibinitperiod},
           given={Ivana},
           giveni={I\bibinitperiod}}}%
        {{hash=76d0d6d0f4f78ec32c4cd695c40882c2}{%
           family={Flitney},
           familyi={F\bibinitperiod},
           given={David\bibnamedelima E.},
           giveni={D\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=1691953b720f3fce5e85f7d8253a6ede}{%
           family={Niazy},
           familyi={N\bibinitperiod},
           given={Rami\bibnamedelima K.},
           giveni={R\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=5a35f5109e4a965f371ed987824a3380}{%
           family={Saunders},
           familyi={S\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
        {{hash=8481067f6e37ac5d92e78a1bc1412167}{%
           family={Vickers},
           familyi={V\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
        {{hash=4765a779b0edc9336e38fdf66fae8858}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yongyue},
           giveni={Y\bibinitperiod}}}%
        {{hash=4c8464005db0a97d79671dad29517efa}{%
           family={De\bibnamedelima Stefano},
           familyi={D\bibinitperiod\bibinitdelim S\bibinitperiod},
           given={Nicola},
           giveni={N\bibinitperiod}}}%
        {{hash=2100513ce08f756adc030ea6b696baa0}{%
           family={Brady},
           familyi={B\bibinitperiod},
           given={J.\bibnamedelimi Michael},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=882f6df8f9ebbbdbf525bb857df7d320}{%
           family={Matthews},
           familyi={M\bibinitperiod},
           given={Paul\bibnamedelima M.},
           giveni={P\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{ec1ac46be5f6837797580c68d63b77d5}
      \strng{fullhash}{858cd37bcefdf1c48e31f80d87458055}
      \strng{bibnamehash}{ec1ac46be5f6837797580c68d63b77d5}
      \strng{authorbibnamehash}{ec1ac46be5f6837797580c68d63b77d5}
      \strng{authornamehash}{ec1ac46be5f6837797580c68d63b77d5}
      \strng{authorfullhash}{858cd37bcefdf1c48e31f80d87458055}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The techniques available for the interrogation and analysis of neuroimaging data have a large influence in determining the flexibility, sensitivity, and scope of neuroimaging experiments. The development of such methodologies has allowed investigators to address scientific questions that could not previously be answered and, as such, has become an important research area in its own right. In this paper, we present a review of the research carried out by the Analysis Group at the Oxford Centre for Functional MRI of the Brain (FMRIB). This research has focussed on the development of new methodologies for the analysis of both structural and functional magnetic resonance imaging data. The majority of the research laid out in this paper has been implemented as freely available software tools within FMRIB's Software Library (FSL).}
      \field{issn}{1053-8119}
      \field{journaltitle}{NeuroImage}
      \field{month}{1}
      \field{series}{Mathematics in {Brain} {Imaging}}
      \field{title}{Advances in functional and structural {MR} image analysis and implementation as {FSL}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{23}
      \field{year}{2004}
      \field{urldateera}{ce}
      \field{pages}{S208\bibrangedash S219}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1016/j.neuroimage.2004.07.051
      \endverb
      \verb{file}
      \verb ScienceDirect Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/7AHST38F/S1053811904003933.html:text/html;Submitted Version:/home/someusername/workspace/UNet-bSSFP/lit/storage/3IBG7FYI/Smith et al. - 2004 - Advances in functional and structural MR image ana.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S1053811904003933
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S1053811904003933
      \endverb
      \keyw{FMRI,FSL,Structural MR image analysis}
    \endentry
    \entry{sohl-dickstein_deep_2015}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=529bdf392a3471f000ce33ec88c41bd5}{%
           family={Sohl-Dickstein},
           familyi={S\bibinithyphendelim D\bibinitperiod},
           given={Jascha},
           giveni={J\bibinitperiod}}}%
        {{hash=8b4a541c45705890d9759e0bbd2dfd0d}{%
           family={Weiss},
           familyi={W\bibinitperiod},
           given={Eric\bibnamedelima A.},
           giveni={E\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=24b3062319f458bd1a60642d737d4aea}{%
           family={Maheswaranathan},
           familyi={M\bibinitperiod},
           given={Niru},
           giveni={N\bibinitperiod}}}%
        {{hash=05b3e391388084df874ede60f2210c12}{%
           family={Ganguli},
           familyi={G\bibinitperiod},
           given={Surya},
           giveni={S\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Lille, France}%
      }
      \list{publisher}{1}{%
        {JMLR.org}%
      }
      \strng{namehash}{ba6e625a46287ebf30dd9d9f3c07087b}
      \strng{fullhash}{fcce41a9178ec20258209817b78f08ac}
      \strng{bibnamehash}{ba6e625a46287ebf30dd9d9f3c07087b}
      \strng{authorbibnamehash}{ba6e625a46287ebf30dd9d9f3c07087b}
      \strng{authornamehash}{ba6e625a46287ebf30dd9d9f3c07087b}
      \strng{authorfullhash}{fcce41a9178ec20258209817b78f08ac}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.}
      \field{booktitle}{Proceedings of the 32nd {International} {Conference} on {International} {Conference} on {Machine} {Learning} - {Volume} 37}
      \field{month}{7}
      \field{series}{{ICML}'15}
      \field{title}{Deep unsupervised learning using nonequilibrium thermodynamics}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{2256\bibrangedash 2265}
      \range{pages}{10}
    \endentry
    \entry{sonoda_neural_2017}{article}{}
      \name{author}{2}{}{%
        {{hash=2f21ece4e9535a03503a7186e62aec7f}{%
           family={Sonoda},
           familyi={S\bibinitperiod},
           given={Sho},
           giveni={S\bibinitperiod}}}%
        {{hash=1b88ead033e20e6a71e3878c7bf0792b}{%
           family={Murata},
           familyi={M\bibinitperiod},
           given={Noboru},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{f0fadd4265855681690d6c40f79f0493}
      \strng{fullhash}{f0fadd4265855681690d6c40f79f0493}
      \strng{bibnamehash}{f0fadd4265855681690d6c40f79f0493}
      \strng{authorbibnamehash}{f0fadd4265855681690d6c40f79f0493}
      \strng{authornamehash}{f0fadd4265855681690d6c40f79f0493}
      \strng{authorfullhash}{f0fadd4265855681690d6c40f79f0493}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents an investigation of the approximation property of neural networks with unbounded activation functions, such as the rectified linear unit (ReLU), which is the new de-facto standard of deep learning. The ReLU network can be analyzed by the ridgelet transform with respect to Lizorkin distributions. By showing three reconstruction formulas by using the Fourier slice theorem, the Radon transform, and Parseval's relation, it is shown that a neural network with unbounded activation functions still satisfies the universal approximation property. As an additional consequence, the ridgelet transform, or the backprojection filter in the Radon domain, is what the network learns after backpropagation. Subject to a constructive admissibility condition, the trained network can be obtained by simply discretizing the ridgelet transform, without backpropagation. Numerical examples not only support the consistency of the admissibility condition but also imply that some non-admissible cases result in low-pass filtering.}
      \field{issn}{1063-5203}
      \field{journaltitle}{Applied and Computational Harmonic Analysis}
      \field{month}{9}
      \field{number}{2}
      \field{title}{Neural network with unbounded activation functions is universal approximator}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{43}
      \field{year}{2017}
      \field{urldateera}{ce}
      \field{pages}{233\bibrangedash 268}
      \range{pages}{36}
      \verb{doi}
      \verb 10.1016/j.acha.2015.12.005
      \endverb
      \verb{file}
      \verb Eingereichte Version:/home/someusername/workspace/UNet-bSSFP/lit/storage/M7B2F96R/Sonoda und Murata - 2017 - Neural network with unbounded activation functions.pdf:application/pdf;ScienceDirect Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/ZWVQGJXT/S1063520315001748.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S1063520315001748
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S1063520315001748
      \endverb
      \keyw{Admissibility condition,Backprojection filter,Bounded extension to,Integral representation,Lizorkin distribution,Neural network,Radon transform,Rectified linear unit (ReLU),Ridgelet transform,Universal approximation}
    \endentry
    \entry{srivastava_dropout_2014}{article}{}
      \name{author}{5}{}{%
        {{hash=6a147afa4569ce6cf23c0436e65d8486}{%
           family={Srivastava},
           familyi={S\bibinitperiod},
           given={Nitish},
           giveni={N\bibinitperiod}}}%
        {{hash=9a8750ccdb2a4cf14d2655face1ce016}{%
           family={Hinton},
           familyi={H\bibinitperiod},
           given={Geoffrey},
           giveni={G\bibinitperiod}}}%
        {{hash=c5e3a676e2ac1164b3afcd539c131fc9}{%
           family={Krizhevsky},
           familyi={K\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
        {{hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
        {{hash=bd2be300d445e9f6db7808f9533e66cb}{%
           family={Salakhutdinov},
           familyi={S\bibinitperiod},
           given={Ruslan},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{4d6dba595c04c09619c7c1c0038d5b6b}
      \strng{fullhash}{2850768171a28ccacd146c300f66f57d}
      \strng{bibnamehash}{4d6dba595c04c09619c7c1c0038d5b6b}
      \strng{authorbibnamehash}{4d6dba595c04c09619c7c1c0038d5b6b}
      \strng{authornamehash}{4d6dba595c04c09619c7c1c0038d5b6b}
      \strng{authorfullhash}{2850768171a28ccacd146c300f66f57d}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different thinned networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.}
      \field{issn}{1533-7928}
      \field{journaltitle}{Journal of Machine Learning Research}
      \field{number}{56}
      \field{shorttitle}{Dropout}
      \field{title}{Dropout: {A} {Simple} {Way} to {Prevent} {Neural} {Networks} from {Overfitting}}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{15}
      \field{year}{2014}
      \field{urldateera}{ce}
      \field{pages}{1929\bibrangedash 1958}
      \range{pages}{30}
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/DKG3Y59R/Srivastava et al. - 2014 - Dropout A Simple Way to Prevent Neural Networks f.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://jmlr.org/papers/v15/srivastava14a.html
      \endverb
      \verb{url}
      \verb http://jmlr.org/papers/v15/srivastava14a.html
      \endverb
    \endentry
    \entry{torrey_bloch_1956}{article}{}
      \name{author}{1}{}{%
        {{hash=3ab84e3bd7a8f70b547eb9e9d9e5ac8a}{%
           family={Torrey},
           familyi={T\bibinitperiod},
           given={H.\bibnamedelimi C.},
           giveni={H\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \strng{namehash}{3ab84e3bd7a8f70b547eb9e9d9e5ac8a}
      \strng{fullhash}{3ab84e3bd7a8f70b547eb9e9d9e5ac8a}
      \strng{bibnamehash}{3ab84e3bd7a8f70b547eb9e9d9e5ac8a}
      \strng{authorbibnamehash}{3ab84e3bd7a8f70b547eb9e9d9e5ac8a}
      \strng{authornamehash}{3ab84e3bd7a8f70b547eb9e9d9e5ac8a}
      \strng{authorfullhash}{3ab84e3bd7a8f70b547eb9e9d9e5ac8a}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The phenomenological Bloch equations in nuclear magnetic resonance are generalized by the addition of terms due to the transfer of magnetization by diffusion. The revised equations describe phenomena under conditions of inhomogeneity in magnetic field, relaxation rates, or initial magnetization. As an example the equations are solved in the case of the free precession of magnetic moment in the presence of an inhomogeneous magnetic field following the application of a 90° pulse with subsequent applications of a succession of 180° pulses. The spin-echo amplitudes agree with the results of Carr and Purcell from a random walk theory.}
      \field{journaltitle}{Physical Review}
      \field{month}{11}
      \field{note}{Publisher: American Physical Society}
      \field{number}{3}
      \field{title}{Bloch {Equations} with {Diffusion} {Terms}}
      \field{urlday}{8}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{104}
      \field{year}{1956}
      \field{urldateera}{ce}
      \field{pages}{563\bibrangedash 565}
      \range{pages}{3}
      \verb{doi}
      \verb 10.1103/PhysRev.104.563
      \endverb
      \verb{file}
      \verb APS Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/EAW4NFDU/PhysRev.104.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://link.aps.org/doi/10.1103/PhysRev.104.563
      \endverb
      \verb{url}
      \verb https://link.aps.org/doi/10.1103/PhysRev.104.563
      \endverb
    \endentry
    \entry{tournier_diffusion_2011}{article}{}
      \name{author}{3}{}{%
        {{hash=1ba8f047eed52fea90b594febb63b215}{%
           family={Tournier},
           familyi={T\bibinitperiod},
           given={Jacques-Donald},
           giveni={J\bibinithyphendelim D\bibinitperiod}}}%
        {{hash=7c1373e40d611a11dc19fa305c79e50b}{%
           family={Mori},
           familyi={M\bibinitperiod},
           given={Susumu},
           giveni={S\bibinitperiod}}}%
        {{hash=744a2d0842d4b3adb7fe02007e7d1783}{%
           family={Leemans},
           familyi={L\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{b63d4af3b77cfbf245d9192f85715bcc}
      \strng{fullhash}{b63d4af3b77cfbf245d9192f85715bcc}
      \strng{bibnamehash}{b63d4af3b77cfbf245d9192f85715bcc}
      \strng{authorbibnamehash}{b63d4af3b77cfbf245d9192f85715bcc}
      \strng{authornamehash}{b63d4af3b77cfbf245d9192f85715bcc}
      \strng{authorfullhash}{b63d4af3b77cfbf245d9192f85715bcc}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0740-3194}
      \field{journaltitle}{Magnetic Resonance in Medicine}
      \field{month}{6}
      \field{number}{6}
      \field{title}{Diffusion {Tensor} {Imaging} and {Beyond}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{65}
      \field{year}{2011}
      \field{urldateera}{ce}
      \true{nocite}
      \field{pages}{1532\bibrangedash 1556}
      \range{pages}{25}
      \verb{doi}
      \verb 10.1002/mrm.22924
      \endverb
      \verb{file}
      \verb PubMed Central Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/9RXW4U8T/Tournier et al. - 2011 - Diffusion Tensor Imaging and Beyond.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3366862/
      \endverb
      \verb{url}
      \verb https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3366862/
      \endverb
    \endentry
    \entry{ulyanov_instance_2017}{misc}{}
      \name{author}{3}{}{%
        {{hash=a75feb2ef201e838d7c47d52c9dce4bf}{%
           family={Ulyanov},
           familyi={U\bibinitperiod},
           given={Dmitry},
           giveni={D\bibinitperiod}}}%
        {{hash=85ab53268da1006b51b453d57d3566f2}{%
           family={Vedaldi},
           familyi={V\bibinitperiod},
           given={Andrea},
           giveni={A\bibinitperiod}}}%
        {{hash=a48f60762c88685a899455e12615e1df}{%
           family={Lempitsky},
           familyi={L\bibinitperiod},
           given={Victor},
           giveni={V\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{8e981090ca533caa8662c892422ee323}
      \strng{fullhash}{8e981090ca533caa8662c892422ee323}
      \strng{bibnamehash}{8e981090ca533caa8662c892422ee323}
      \strng{authorbibnamehash}{8e981090ca533caa8662c892422ee323}
      \strng{authornamehash}{8e981090ca533caa8662c892422ee323}
      \strng{authorfullhash}{8e981090ca533caa8662c892422ee323}
      \field{sortinit}{U}
      \field{sortinithash}{6901a00e45705986ee5e7ca9fd39adca}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{It this paper we revisit the fast stylization method introduced in Ulyanov et. al. (2016). We show how a small change in the stylization architecture results in a significant qualitative improvement in the generated images. The change is limited to swapping batch normalization with instance normalization, and to apply the latter both at training and testing times. The resulting method can be used to train high-performance architectures for real-time image generation. The code will is made available on github at https://github.com/DmitryUlyanov/texture\_nets. Full paper can be found at arXiv:1701.02096.}
      \field{month}{11}
      \field{note}{arXiv:1607.08022 [cs]}
      \field{shorttitle}{Instance {Normalization}}
      \field{title}{Instance {Normalization}: {The} {Missing} {Ingredient} for {Fast} {Stylization}}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1607.08022
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/62BJUM6U/Ulyanov et al. - 2017 - Instance Normalization The Missing Ingredient for.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/DDKXQP99/1607.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1607.08022
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1607.08022
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{van_der_malsburg_frank_1986}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=dff21045f5ac8a5cb546a24917e5318e}{%
           family={Van\bibnamedelimb Der\bibnamedelima Malsburg},
           familyi={V\bibinitperiod\bibinitdelim D\bibinitperiod\bibinitdelim M\bibinitperiod},
           given={C.},
           giveni={C\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=c92dcede871b3a805a744ce4df2eaed6}{%
           family={Palm},
           familyi={P\bibinitperiod},
           given={Günther},
           giveni={G\bibinitperiod}}}%
        {{hash=83a9d134b8e1d6697bd710a1176471b1}{%
           family={Aertsen},
           familyi={A\bibinitperiod},
           given={Ad},
           giveni={A\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{dff21045f5ac8a5cb546a24917e5318e}
      \strng{fullhash}{dff21045f5ac8a5cb546a24917e5318e}
      \strng{bibnamehash}{dff21045f5ac8a5cb546a24917e5318e}
      \strng{authorbibnamehash}{dff21045f5ac8a5cb546a24917e5318e}
      \strng{authornamehash}{dff21045f5ac8a5cb546a24917e5318e}
      \strng{authorfullhash}{dff21045f5ac8a5cb546a24917e5318e}
      \strng{editorbibnamehash}{a91ed9225cd14bc75d9d1c0c33535911}
      \strng{editornamehash}{a91ed9225cd14bc75d9d1c0c33535911}
      \strng{editorfullhash}{a91ed9225cd14bc75d9d1c0c33535911}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Frank Rosenblatt’s intention with his book, according to his own introduction, is not just to describe a machine, the perceptron, but rather to put forward a theory. He formulates a series of machines. Each machine serves to introduce a new concept.}
      \field{booktitle}{Brain {Theory}}
      \field{isbn}{978-3-642-70911-1}
      \field{shorttitle}{Frank {Rosenblatt}}
      \field{title}{Frank {Rosenblatt}: {Principles} of {Neurodynamics}: {Perceptrons} and the {Theory} of {Brain} {Mechanisms}}
      \field{year}{1986}
      \field{pages}{245\bibrangedash 248}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1007/978-3-642-70911-1_20
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/UD6LQ2BB/Van Der Malsburg - 1986 - Frank Rosenblatt Principles of Neurodynamics Per.pdf:application/pdf
      \endverb
      \keyw{Brain Theory,Small Pattern,Synaptic Plasticity,Synaptic Weight,Syntactical Information}
    \endentry
    \entry{van_leemput_automated_1999}{article}{}
      \name{author}{4}{}{%
        {{hash=137527d92eda499afb15c0728e6198a1}{%
           family={Van\bibnamedelima Leemput},
           familyi={V\bibinitperiod\bibinitdelim L\bibinitperiod},
           given={K.},
           giveni={K\bibinitperiod}}}%
        {{hash=70fc769f94537910fa8adcaa01158f1c}{%
           family={Maes},
           familyi={M\bibinitperiod},
           given={F.},
           giveni={F\bibinitperiod}}}%
        {{hash=25683061b83d6998166538f0c7c362fc}{%
           family={Vandermeulen},
           familyi={V\bibinitperiod},
           given={D.},
           giveni={D\bibinitperiod}}}%
        {{hash=8fc76a4b840d90b32c6c99146d2aec82}{%
           family={Suetens},
           familyi={S\bibinitperiod},
           given={P.},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{0ac84b19ca04da5a07af5c96c083a52d}
      \strng{fullhash}{17f8de908db00445e4a7591d380fed4d}
      \strng{bibnamehash}{0ac84b19ca04da5a07af5c96c083a52d}
      \strng{authorbibnamehash}{0ac84b19ca04da5a07af5c96c083a52d}
      \strng{authornamehash}{0ac84b19ca04da5a07af5c96c083a52d}
      \strng{authorfullhash}{17f8de908db00445e4a7591d380fed4d}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Describes a fully automated method for model-based tissue classification of magnetic resonance (MR) images of the brain. The method interleaves classification with estimation of the model parameters, improving the classification at each iteration. The algorithm is able to segment single- and multi-spectral MR images, corrects for MR signal inhomogeneities, and incorporates contextual information by means of Markov random Fields (MRF's). A digital brain atlas containing prior expectations about the spatial location of tissue classes is used to initialize the algorithm. This makes the method fully automated and therefore it provides objective and reproducible segmentations. The authors have validated the technique on simulated as well as on real MR images of the brain.}
      \field{issn}{1558-254X}
      \field{journaltitle}{IEEE Transactions on Medical Imaging}
      \field{month}{10}
      \field{note}{Conference Name: IEEE Transactions on Medical Imaging}
      \field{number}{10}
      \field{title}{Automated model-based tissue classification of {MR} images of the brain}
      \field{urlday}{12}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{18}
      \field{year}{1999}
      \field{urldateera}{ce}
      \field{pages}{897\bibrangedash 908}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/42.811270
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/abstract/document/811270
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/abstract/document/811270
      \endverb
      \keyw{Biomedical imaging,Brain modeling,Humans,Image analysis,Image segmentation,Iterative methods,Magnetic resonance,Magnetic resonance imaging,Markov random fields}
    \endentry
    \entry{van_nguyen_cross-domain_2015}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=40164312b793ac2bc03467b6ec3f87c9}{%
           family={Van\bibnamedelima Nguyen},
           familyi={V\bibinitperiod\bibinitdelim N\bibinitperiod},
           given={Hien},
           giveni={H\bibinitperiod}}}%
        {{hash=6acd04f23749b5e7581f86bfb0b632e7}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Kevin},
           giveni={K\bibinitperiod}}}%
        {{hash=2f0c1948be53b13647d2d7a1f278b575}{%
           family={Vemulapalli},
           familyi={V\bibinitperiod},
           given={Raviteja},
           giveni={R\bibinitperiod}}}%
      }
      \name{editor}{4}{}{%
        {{hash=c107bbd317cd780c2aa7006dbe61d83f}{%
           family={Navab},
           familyi={N\bibinitperiod},
           given={Nassir},
           giveni={N\bibinitperiod}}}%
        {{hash=13dfdbfc375d5ae886268dec73d8d8f9}{%
           family={Hornegger},
           familyi={H\bibinitperiod},
           given={Joachim},
           giveni={J\bibinitperiod}}}%
        {{hash=4d166f6210ae1792f8f90d7871b4d234}{%
           family={Wells},
           familyi={W\bibinitperiod},
           given={William\bibnamedelima M.},
           giveni={W\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=1a646ae010320b6078bc4ef1eaae06e8}{%
           family={Frangi},
           familyi={F\bibinitperiod},
           given={Alejandro},
           giveni={A\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{326660c664b8d2a81e760822205f8d35}
      \strng{fullhash}{326660c664b8d2a81e760822205f8d35}
      \strng{bibnamehash}{326660c664b8d2a81e760822205f8d35}
      \strng{authorbibnamehash}{326660c664b8d2a81e760822205f8d35}
      \strng{authornamehash}{326660c664b8d2a81e760822205f8d35}
      \strng{authorfullhash}{326660c664b8d2a81e760822205f8d35}
      \strng{editorbibnamehash}{7d63d752dc1fd3abad4ee5f250821c1c}
      \strng{editornamehash}{7d63d752dc1fd3abad4ee5f250821c1c}
      \strng{editorfullhash}{2df59fa6c3dd55532ed381fe2be2f595}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Cross-modality image synthesis has recently gained significant interest in the medical imaging community. In this paper, we propose a novel architecture called location-sensitive deep network (LSDN) for synthesizing images across domains. Our network integrates intensity feature from image voxels and spatial information in a principled manner. Specifically, LSDN models hidden nodes as products of features and spatial responses. We then propose a novel method, called ShrinkConnect, for reducing the computations of LSDN without sacrificing synthesis accuracy. ShrinkConnect enforces simultaneous sparsity to find a compact set of functions that accurately approximates the responses of all hidden nodes. Experimental results demonstrate that LSDN+ShrinkConnect outperforms the state of the art in cross-domain synthesis of MRI brain scans by a significant margin. Our approach is also computationally efficient, e.g. 26× faster than other sparse representation based methods.}
      \field{booktitle}{Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} -- {MICCAI} 2015}
      \field{isbn}{978-3-319-24553-9}
      \field{title}{Cross-{Domain} {Synthesis} of {Medical} {Images} {Using} {Efficient} {Location}-{Sensitive} {Deep} {Network}}
      \field{year}{2015}
      \field{pages}{677\bibrangedash 684}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1007/978-3-319-24553-9_83
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/E5N5DTC2/Van Nguyen et al. - 2015 - Cross-Domain Synthesis of Medical Images Using Eff.pdf:application/pdf
      \endverb
      \keyw{Convolutional Neural Network,Hide Node,Intensity Feature,Principled Manner,Rigid Transformation}
    \endentry
    \entry{vaswani_attention_2017}{inproceedings}{}
      \name{author}{8}{}{%
        {{hash=7f28e84700536646dd6620a0db07ad09}{%
           family={Vaswani},
           familyi={V\bibinitperiod},
           given={Ashish},
           giveni={A\bibinitperiod}}}%
        {{hash=62efade83d70f0323fe248755e6c90c5}{%
           family={Shazeer},
           familyi={S\bibinitperiod},
           given={Noam},
           giveni={N\bibinitperiod}}}%
        {{hash=06649ebab1ea5cac0250746a19764975}{%
           family={Parmar},
           familyi={P\bibinitperiod},
           given={Niki},
           giveni={N\bibinitperiod}}}%
        {{hash=831027ee0ebf22375e2a86afc1881909}{%
           family={Uszkoreit},
           familyi={U\bibinitperiod},
           given={Jakob},
           giveni={J\bibinitperiod}}}%
        {{hash=2fd2982e30ebcec93ec1cf76e0d797fd}{%
           family={Jones},
           familyi={J\bibinitperiod},
           given={Llion},
           giveni={L\bibinitperiod}}}%
        {{hash=27b07e4eacbf4ef7a1438e3badb7dd8d}{%
           family={Gomez},
           familyi={G\bibinitperiod},
           given={Aidan\bibnamedelima N.},
           giveni={A\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=540fcd72e1fa4bbed46604f4e6cff817}{%
           family={Kaiser},
           familyi={K\bibinitperiod},
           given={Łukasz},
           giveni={Ł\bibinitperiod}}}%
        {{hash=95595a0fefb86187cbc36e551017d332}{%
           family={Polosukhin},
           familyi={P\bibinitperiod},
           given={Illia},
           giveni={I\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Red Hook, NY, USA}%
      }
      \list{publisher}{1}{%
        {Curran Associates Inc.}%
      }
      \strng{namehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{fullhash}{cb26e47f6b8133865271fc8483132297}
      \strng{bibnamehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{authorbibnamehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{authornamehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{authorfullhash}{cb26e47f6b8133865271fc8483132297}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.}
      \field{booktitle}{Proceedings of the 31st {International} {Conference} on {Neural} {Information} {Processing} {Systems}}
      \field{isbn}{978-1-5108-6096-4}
      \field{month}{12}
      \field{series}{{NIPS}'17}
      \field{title}{Attention is all you need}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2017}
      \field{urldateera}{ce}
      \field{pages}{6000\bibrangedash 6010}
      \range{pages}{11}
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/APQ34RTA/Vaswani et al. - 2017 - Attention is all you need.pdf:application/pdf
      \endverb
    \endentry
    \entry{vemulapalli_unsupervised_2015}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=2f0c1948be53b13647d2d7a1f278b575}{%
           family={Vemulapalli},
           familyi={V\bibinitperiod},
           given={Raviteja},
           giveni={R\bibinitperiod}}}%
        {{hash=40164312b793ac2bc03467b6ec3f87c9}{%
           family={Van\bibnamedelima Nguyen},
           familyi={V\bibinitperiod\bibinitdelim N\bibinitperiod},
           given={Hien},
           giveni={H\bibinitperiod}}}%
        {{hash=b5248a628c22c4bbec1533e5cab4399e}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Shaohua\bibnamedelima Kevin},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
      }
      \strng{namehash}{ee39a66edbcca0c068b198d208872403}
      \strng{fullhash}{ee39a66edbcca0c068b198d208872403}
      \strng{bibnamehash}{ee39a66edbcca0c068b198d208872403}
      \strng{authorbibnamehash}{ee39a66edbcca0c068b198d208872403}
      \strng{authornamehash}{ee39a66edbcca0c068b198d208872403}
      \strng{authorfullhash}{ee39a66edbcca0c068b198d208872403}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, cross-modal synthesis of subject-specific scans has been receiving significant attention from the medical imaging community. Though various synthesis approaches have been introduced in the recent past, most of them are either tailored to a specific application or proposed for the supervised setting, i.e., they assume the availability of training data from the same set of subjects in both source and target modalities. But, collecting multiple scans from each subject is undesirable. Hence, to address this issue, we propose a general unsupervised cross-modal medical image synthesis approach that works without paired training data. Given a source modality image of a subject, we first generate multiple target modality candidate values for each voxel independently using cross-modal nearest neighbor search. Then, we select the best candidate values jointly for all the voxels by simultaneously maximizing a global mutual information cost function and a local spatial consistency cost function. Finally, we use coupled sparse representation for further refinement of synthesized images. Our experiments on generating T1-MRI brain scans from T2-MRI and vice versa demonstrate that the synthesis capability of the proposed unsupervised approach is comparable to various state-of-the-art supervised approaches in the literature.}
      \field{booktitle}{2015 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})}
      \field{month}{12}
      \field{note}{ISSN: 2380-7504}
      \field{title}{Unsupervised {Cross}-{Modal} {Synthesis} of {Subject}-{Specific} {Scans}}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{630\bibrangedash 638}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1109/ICCV.2015.79
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/home/someusername/workspace/UNet-bSSFP/lit/storage/FMSDVQNY/7410436.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/7410436
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/7410436
      \endverb
      \keyw{Biomedical imaging,Image generation,Image resolution,Magnetic resonance imaging,Nearest neighbor searches,Training,Training data}
    \endentry
    \entry{wang_pretraining_2022}{misc}{}
      \name{author}{7}{}{%
        {{hash=b611a31fdd15fef15397f8328de5bfa2}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Tengfei},
           giveni={T\bibinitperiod}}}%
        {{hash=532f45e63f404c93fcc530704019db4d}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Ting},
           giveni={T\bibinitperiod}}}%
        {{hash=4ac36eed64badd6f195e86aeecd037a7}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Bo},
           giveni={B\bibinitperiod}}}%
        {{hash=015c2685ddea1739e3253fa30381c999}{%
           family={Ouyang},
           familyi={O\bibinitperiod},
           given={Hao},
           giveni={H\bibinitperiod}}}%
        {{hash=f8ff1228cc4422c31e97a0f5e9dc2940}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Dong},
           giveni={D\bibinitperiod}}}%
        {{hash=7928a0b7e3ee0c5a35a82d179201a4d7}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Qifeng},
           giveni={Q\bibinitperiod}}}%
        {{hash=d71a95ac64c07b96c49c292f7d6fce88}{%
           family={Wen},
           familyi={W\bibinitperiod},
           given={Fang},
           giveni={F\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{7790b3713d162f8d9ec622a500cc8d63}
      \strng{fullhash}{5e8782b8b257f7462b0c163e4c259a16}
      \strng{bibnamehash}{7790b3713d162f8d9ec622a500cc8d63}
      \strng{authorbibnamehash}{7790b3713d162f8d9ec622a500cc8d63}
      \strng{authornamehash}{7790b3713d162f8d9ec622a500cc8d63}
      \strng{authorfullhash}{5e8782b8b257f7462b0c163e4c259a16}
      \field{extraname}{1}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose to use pretraining to boost general image-to-image translation. Prior image-to-image translation methods usually need dedicated architectural design and train individual translation models from scratch, struggling for high-quality generation of complex scenes, especially when paired training data are not abundant. In this paper, we regard each image-to-image translation problem as a downstream task and introduce a simple and generic framework that adapts a pretrained diffusion model to accommodate various kinds of image-to-image translation. We also propose adversarial training to enhance the texture synthesis in the diffusion model training, in conjunction with normalized guidance sampling to improve the generation quality. We present extensive empirical comparison across various tasks on challenging benchmarks such as ADE20K, COCO-Stuff, and DIODE, showing the proposed pretraining-based image-to-image translation (PITI) is capable of synthesizing images of unprecedented realism and faithfulness.}
      \field{month}{5}
      \field{title}{Pretraining is {All} {You} {Need} for {Image}-to-{Image} {Translation}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2205.12952
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/67ZJ8N25/Wang et al. - 2022 - Pretraining is All You Need for Image-to-Image Tra.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/88GS42MK/2205.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2205.12952
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2205.12952
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{wang_image_2004}{article}{}
      \name{author}{4}{}{%
        {{hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod}}}%
        {{hash=6192fbf30c45211fdfc67652236bec72}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={A.C.},
           giveni={A\bibinitperiod}}}%
        {{hash=84051ed6c4d99d3ccc763a9bfdfd28a8}{%
           family={Sheikh},
           familyi={S\bibinitperiod},
           given={H.R.},
           giveni={H\bibinitperiod}}}%
        {{hash=071228688c89a654d8f1b7ca8d022a6f}{%
           family={Simoncelli},
           familyi={S\bibinitperiod},
           given={E.P.},
           giveni={E\bibinitperiod}}}%
      }
      \strng{namehash}{ec7f3703fbd419b313e0a329e6241059}
      \strng{fullhash}{4eadc44b73c932989cbd36a77d356aab}
      \strng{bibnamehash}{ec7f3703fbd419b313e0a329e6241059}
      \strng{authorbibnamehash}{ec7f3703fbd419b313e0a329e6241059}
      \strng{authornamehash}{ec7f3703fbd419b313e0a329e6241059}
      \strng{authorfullhash}{4eadc44b73c932989cbd36a77d356aab}
      \field{extraname}{2}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.}
      \field{issn}{1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{month}{4}
      \field{note}{Conference Name: IEEE Transactions on Image Processing}
      \field{number}{4}
      \field{shorttitle}{Image quality assessment}
      \field{title}{Image quality assessment: from error visibility to structural similarity}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{13}
      \field{year}{2004}
      \field{urldateera}{ce}
      \true{nocite}
      \field{pages}{600\bibrangedash 612}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2003.819861
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/home/someusername/workspace/UNet-bSSFP/lit/storage/QRB4EXV2/1284395.html:text/html;IEEE Xplore Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/4IEYMWBE/Wang et al. - 2004 - Image quality assessment from error visibility to.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/1284395
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/1284395
      \endverb
      \keyw{Data mining,Degradation,Humans,Image quality,Indexes,Layout,Quality assessment,Transform coding,Visual perception,Visual system}
    \endentry
    \entry{waskom_seaborn_2021}{article}{}
      \name{author}{1}{}{%
        {{hash=0c809239417dcb9aef9b906eff53933d}{%
           family={Waskom},
           familyi={W\bibinitperiod},
           given={Michael\bibnamedelima L.},
           giveni={M\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{0c809239417dcb9aef9b906eff53933d}
      \strng{fullhash}{0c809239417dcb9aef9b906eff53933d}
      \strng{bibnamehash}{0c809239417dcb9aef9b906eff53933d}
      \strng{authorbibnamehash}{0c809239417dcb9aef9b906eff53933d}
      \strng{authornamehash}{0c809239417dcb9aef9b906eff53933d}
      \strng{authorfullhash}{0c809239417dcb9aef9b906eff53933d}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Waskom, M. L., (2021). seaborn: statistical data visualization. Journal of Open Source Software, 6(60), 3021, https://doi.org/10.21105/joss.03021}
      \field{issn}{2475-9066}
      \field{journaltitle}{Journal of Open Source Software}
      \field{month}{4}
      \field{number}{60}
      \field{shorttitle}{seaborn}
      \field{title}{seaborn: statistical data visualization}
      \field{urlday}{12}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{6}
      \field{year}{2021}
      \field{urldateera}{ce}
      \field{pages}{3021}
      \range{pages}{1}
      \verb{doi}
      \verb 10.21105/joss.03021
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/FM3CBXRA/Waskom - 2021 - seaborn statistical data visualization.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://joss.theoj.org/papers/10.21105/joss.03021
      \endverb
      \verb{url}
      \verb https://joss.theoj.org/papers/10.21105/joss.03021
      \endverb
    \endentry
    \entry{weigel_extended_2015}{article}{}
      \name{author}{1}{}{%
        {{hash=fa947fcb01d8f6e7312e2b8684bec2fd}{%
           family={Weigel},
           familyi={W\bibinitperiod},
           given={Matthias},
           giveni={M\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{fa947fcb01d8f6e7312e2b8684bec2fd}
      \strng{fullhash}{fa947fcb01d8f6e7312e2b8684bec2fd}
      \strng{bibnamehash}{fa947fcb01d8f6e7312e2b8684bec2fd}
      \strng{authorbibnamehash}{fa947fcb01d8f6e7312e2b8684bec2fd}
      \strng{authornamehash}{fa947fcb01d8f6e7312e2b8684bec2fd}
      \strng{authorfullhash}{fa947fcb01d8f6e7312e2b8684bec2fd}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The extended phase graph (EPG) concept represents a powerful tool for depicting and understanding the magnetization response of a broad variety of MR sequences. EPGs focus on echo generation as well as on classification and use a Fourier based magnetization description in terms of “configurations states”. The effect of gradients, radiofrequency (RF) pulses, relaxation, and motion phenomena during the MR sequence is characterized as the action of a few matrix operations on these configuration states. Thus, the EPG method allows for fast and precise quantitation of echo intensities even if several gradients and RF pulses are applied. EPG diagrams aid in the comprehension of different types of echoes and their corresponding echo time. Despite its several benefits in regard to a large number of problems and issues, researchers and users still often refrain from applying EPGs. It seems that “phase graphing” is still seen as a kind of “magic.” The present review investigates the foundation of EPGs and sheds light on prerequisites for adding more advanced phenomena such as diffusion. The links between diagrams and calculations are discussed. A further focus is on limitations and simplifications as well recent extensions within the EPG concept. To make the review complete, representative software for EPG coding is provided. J. Magn. Reson. Imaging 2015;41:266–295.© 2013 Wiley Periodicals, Inc.}
      \field{issn}{1522-2586}
      \field{journaltitle}{Journal of Magnetic Resonance Imaging}
      \field{number}{2}
      \field{shorttitle}{Extended phase graphs}
      \field{title}{Extended phase graphs: {Dephasing}, {RF} pulses, and echoes - pure and simple}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{41}
      \field{year}{2015}
      \field{urldateera}{ce}
      \true{nocite}
      \field{pages}{266\bibrangedash 295}
      \range{pages}{30}
      \verb{doi}
      \verb 10.1002/jmri.24619
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/P42N4AEI/Weigel - 2015 - Extended phase graphs Dephasing, RF pulses, and e.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.24619
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.24619
      \endverb
      \keyw{configuration states,dephasing,extended phase graph,Fourier space,partitioning,phase graph}
    \endentry
    \entry{wu_group_2018}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=b626dcc418c3a5c74cfaa4c5e643a71f}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Yuxin},
           giveni={Y\bibinitperiod}}}%
        {{hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{cdf9f82b747ba630cd44730e2b9982af}
      \strng{fullhash}{cdf9f82b747ba630cd44730e2b9982af}
      \strng{bibnamehash}{cdf9f82b747ba630cd44730e2b9982af}
      \strng{authorbibnamehash}{cdf9f82b747ba630cd44730e2b9982af}
      \strng{authornamehash}{cdf9f82b747ba630cd44730e2b9982af}
      \strng{authorfullhash}{cdf9f82b747ba630cd44730e2b9982af}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Group {Normalization}}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \field{pages}{3\bibrangedash 19}
      \range{pages}{17}
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/NQLNT5ZP/Wu und He - 2018 - Group Normalization.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://openaccess.thecvf.com/content_ECCV_2018/html/Yuxin_Wu_Group_Normalization_ECCV_2018_paper.html
      \endverb
      \verb{url}
      \verb https://openaccess.thecvf.com/content_ECCV_2018/html/Yuxin_Wu_Group_Normalization_ECCV_2018_paper.html
      \endverb
    \endentry
    \entry{yang_mri_2020}{article}{}
      \name{author}{6}{}{%
        {{hash=a6961707d37990a9dfb5ccf34f0df0a2}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Qianye},
           giveni={Q\bibinitperiod}}}%
        {{hash=e992e11c79ae85a8a72d308dc5d467f7}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Nannan},
           giveni={N\bibinitperiod}}}%
        {{hash=b399d4e4b5d6872f53f52c0959c29070}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Zixu},
           giveni={Z\bibinitperiod}}}%
        {{hash=8cd76f9ab996743ebc302f052fe1bf25}{%
           family={Fan},
           familyi={F\bibinitperiod},
           given={Xingyu},
           giveni={X\bibinitperiod}}}%
        {{hash=e6570a38e4f366d3d803a145e79eda93}{%
           family={Chang},
           familyi={C\bibinitperiod},
           given={Eric\bibnamedelima I.-Chao},
           giveni={E\bibinitperiod\bibinitdelim I\bibinithyphendelim C\bibinitperiod}}}%
        {{hash=86acdbbb888fb1622ad5366d9d67dc8f}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Yan},
           giveni={Y\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{b9d1ca51a61573b72be35832a07b8106}
      \strng{fullhash}{b6a1e99d22418d4bd83af03812cccadf}
      \strng{bibnamehash}{b9d1ca51a61573b72be35832a07b8106}
      \strng{authorbibnamehash}{b9d1ca51a61573b72be35832a07b8106}
      \strng{authornamehash}{b9d1ca51a61573b72be35832a07b8106}
      \strng{authorfullhash}{b6a1e99d22418d4bd83af03812cccadf}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a cross-modality generation framework that learns to generate translated modalities from given modalities in MR images. Our proposed method performs Image Modality Translation (abbreviated as IMT) by means of a deep learning model that leverages conditional generative adversarial networks (cGANs). Our framework jointly exploits the low-level features (pixel-wise information) and high-level representations (e.g. brain tumors, brain structure like gray matter, etc.) between cross modalities which are important for resolving the challenging complexity in brain structures. Our framework can serve as an auxiliary method in medical use and has great application potential. Based on our proposed framework, we first propose a method for cross-modality registration by fusing the deformation fields to adopt the cross-modality information from translated modalities. Second, we propose an approach for MRI segmentation, translated multichannel segmentation (TMS), where given modalities, along with translated modalities, are segmented by fully convolutional networks (FCN) in a multichannel manner. Both of these two methods successfully adopt the cross-modality information to improve the performance without adding any extra data. Experiments demonstrate that our proposed framework advances the state-of-the-art on five brain MRI datasets. We also observe encouraging results in cross-modality registration and segmentation on some widely adopted brain datasets. Overall, our work can serve as an auxiliary method in medical use and be applied to various tasks in medical fields.}
      \field{issn}{2045-2322}
      \field{journaltitle}{Scientific Reports}
      \field{month}{2}
      \field{note}{Publisher: Nature Publishing Group}
      \field{number}{1}
      \field{title}{{MRI} {Cross}-{Modality} {Image}-to-{Image} {Translation}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{10}
      \field{year}{2020}
      \field{urldateera}{ce}
      \field{pages}{3753}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1038/s41598-020-60520-6
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/WG7LR9XY/Yang et al. - 2020 - MRI Cross-Modality Image-to-Image Translation.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.nature.com/articles/s41598-020-60520-6
      \endverb
      \verb{url}
      \verb https://www.nature.com/articles/s41598-020-60520-6
      \endverb
      \keyw{Biomedical engineering,Computer science}
    \endentry
    \entry{yarkoni_pybids_2019}{article}{}
      \name{author}{31}{}{%
        {{hash=2ef3de263c81c9443822f0beabf57c61}{%
           family={Yarkoni},
           familyi={Y\bibinitperiod},
           given={Tal},
           giveni={T\bibinitperiod}}}%
        {{hash=f629153ba111aa5f9ad5155beb0dd3e1}{%
           family={Markiewicz},
           familyi={M\bibinitperiod},
           given={Christopher\bibnamedelima J},
           giveni={C\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=7b94b10875bfb78ec76eaa504f324fa0}{%
           family={Vega},
           familyi={V\bibinitperiod},
           given={Alejandro},
           giveni={A\bibinitperiod},
           prefix={de\bibnamedelima la},
           prefixi={d\bibinitperiod\bibinitdelim l\bibinitperiod}}}%
        {{hash=37fd6602fafa336c9f4f082ecd471b6c}{%
           family={Gorgolewski},
           familyi={G\bibinitperiod},
           given={Krzysztof\bibnamedelima J},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=6d7b24355630cc7dfdb76c8bd29ffc8e}{%
           family={Salo},
           familyi={S\bibinitperiod},
           given={Taylor},
           giveni={T\bibinitperiod}}}%
        {{hash=e2fb284cc447dda0b361d24f661475ce}{%
           family={Halchenko},
           familyi={H\bibinitperiod},
           given={Yaroslav\bibnamedelima O},
           giveni={Y\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=91071582c049c3f11573bdfaf42d3fbb}{%
           family={McNamara},
           familyi={M\bibinitperiod},
           given={Quinten},
           giveni={Q\bibinitperiod}}}%
        {{hash=d4ff31f161efe30f263d9604b974a695}{%
           family={DeStasio},
           familyi={D\bibinitperiod},
           given={Krista},
           giveni={K\bibinitperiod}}}%
        {{hash=7e567d51746021a736084a5d361744cd}{%
           family={Poline},
           familyi={P\bibinitperiod},
           given={Jean-Baptiste},
           giveni={J\bibinithyphendelim B\bibinitperiod}}}%
        {{hash=ee93ff616a5bd1a749790366a8982853}{%
           family={Petrov},
           familyi={P\bibinitperiod},
           given={Dmitry},
           giveni={D\bibinitperiod}}}%
        {{hash=ab19b8fd671588bbd527874cec32a692}{%
           family={Hayot-Sasson},
           familyi={H\bibinithyphendelim S\bibinitperiod},
           given={Valérie},
           giveni={V\bibinitperiod}}}%
        {{hash=ba1993a5c9ded96acc214c1369dfd652}{%
           family={Nielson},
           familyi={N\bibinitperiod},
           given={Dylan\bibnamedelima M},
           giveni={D\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=bd940e65f1eefd259815db306985e79c}{%
           family={Carlin},
           familyi={C\bibinitperiod},
           given={Johan},
           giveni={J\bibinitperiod}}}%
        {{hash=8d97d5c95e4c0fa5b6cabb4ab84bf53e}{%
           family={Kiar},
           familyi={K\bibinitperiod},
           given={Gregory},
           giveni={G\bibinitperiod}}}%
        {{hash=131443f71e33a6c4caa0522d0600889d}{%
           family={Whitaker},
           familyi={W\bibinitperiod},
           given={Kirstie},
           giveni={K\bibinitperiod}}}%
        {{hash=2f252ee8b737cfd05345bd2da19e5f41}{%
           family={DuPre},
           familyi={D\bibinitperiod},
           given={Elizabeth},
           giveni={E\bibinitperiod}}}%
        {{hash=a05d4c6e41a194af5c438524c2bf14e0}{%
           family={Wagner},
           familyi={W\bibinitperiod},
           given={Adina},
           giveni={A\bibinitperiod}}}%
        {{hash=9952f7300d8d340a54ff28e176544198}{%
           family={Tirrell},
           familyi={T\bibinitperiod},
           given={Lee\bibnamedelima S},
           giveni={L\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=c93977299341e213a29312b64c0e3016}{%
           family={Jas},
           familyi={J\bibinitperiod},
           given={Mainak},
           giveni={M\bibinitperiod}}}%
        {{hash=3f769f6f38f10ce050aff0d54f58526e}{%
           family={Hanke},
           familyi={H\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=21ffb9bf6762df0fb232215885be17e1}{%
           family={Poldrack},
           familyi={P\bibinitperiod},
           given={Russell\bibnamedelima A},
           giveni={R\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=bad82335174e52244c1c45aa43507b06}{%
           family={Esteban},
           familyi={E\bibinitperiod},
           given={Oscar},
           giveni={O\bibinitperiod}}}%
        {{hash=e051de4cde02884a9c209f76e9ffc6d4}{%
           family={Appelhoff},
           familyi={A\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
        {{hash=b360ac3dbeabbee5f23f364b89f29885}{%
           family={Holdgraf},
           familyi={H\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod}}}%
        {{hash=539127f260c848353f0d113822338083}{%
           family={Staden},
           familyi={S\bibinitperiod},
           given={Isla},
           giveni={I\bibinitperiod}}}%
        {{hash=0f3fc06fb9fcbb01b9cc0985eaf0a71c}{%
           family={Thirion},
           familyi={T\bibinitperiod},
           given={Bertrand},
           giveni={B\bibinitperiod}}}%
        {{hash=d689826ca45a27f32c51c82380edb25b}{%
           family={Kleinschmidt},
           familyi={K\bibinitperiod},
           given={Dave\bibnamedelima F},
           giveni={D\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
        {{hash=1013aa8f8d2b7651ab1e33c67b3b6291}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={John\bibnamedelima A},
           giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=b431c5378ab0526b9dd794086cab32b5}{%
           family={Visconti\bibnamedelimb di\bibnamedelimb Oleggio\bibnamedelima Castello},
           familyi={V\bibinitperiod\bibinitdelim d\bibinitperiod\bibinitdelim O\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Matteo},
           giveni={M\bibinitperiod}}}%
        {{hash=4f62a6e86627fcc21e4ddbfb3f75d22f}{%
           family={Notter},
           familyi={N\bibinitperiod},
           given={Michael\bibnamedelima P},
           giveni={M\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=5fc986a0d5881ae22b0af085c0879efd}{%
           family={Blair},
           familyi={B\bibinitperiod},
           given={Ross},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{a002aa836e91ccf8e901801e0224fdef}
      \strng{fullhash}{498f0e9cf2eacc98c9048cd1351e2484}
      \strng{bibnamehash}{a002aa836e91ccf8e901801e0224fdef}
      \strng{authorbibnamehash}{a002aa836e91ccf8e901801e0224fdef}
      \strng{authornamehash}{a002aa836e91ccf8e901801e0224fdef}
      \strng{authorfullhash}{498f0e9cf2eacc98c9048cd1351e2484}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{issn}{2475-9066}
      \field{journaltitle}{Journal of open source software}
      \field{number}{40}
      \field{shorttitle}{{PyBIDS}}
      \field{title}{{PyBIDS}: {Python} tools for {BIDS} datasets}
      \field{urlday}{12}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{4}
      \field{year}{2019}
      \field{urldateera}{ce}
      \field{pages}{1294}
      \range{pages}{1}
      \verb{doi}
      \verb 10.21105/joss.01294
      \endverb
      \verb{file}
      \verb PubMed Central Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/N2PDTFK6/Yarkoni et al. - 2019 - PyBIDS Python tools for BIDS datasets.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7409983/
      \endverb
      \verb{url}
      \verb https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7409983/
      \endverb
    \endentry
    \entry{zhang_dive_2023}{misc}{}
      \name{author}{4}{}{%
        {{hash=983273ab2d972b56d8b64d220726b6aa}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Aston},
           giveni={A\bibinitperiod}}}%
        {{hash=599ae457cf41d4ce64e09433edbc964b}{%
           family={Lipton},
           familyi={L\bibinitperiod},
           given={Zachary\bibnamedelima C.},
           giveni={Z\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=c4a02f87e51fc72ab3f841de1a3982a7}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
        {{hash=82d61e31b4f7f82ad59ff887349bdfe3}{%
           family={Smola},
           familyi={S\bibinitperiod},
           given={Alexander\bibnamedelima J.},
           giveni={A\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{7174309e70e2a2bac293d53405348f6b}
      \strng{fullhash}{6bbccfc10d5cec4da080438a1099af8b}
      \strng{bibnamehash}{7174309e70e2a2bac293d53405348f6b}
      \strng{authorbibnamehash}{7174309e70e2a2bac293d53405348f6b}
      \strng{authornamehash}{7174309e70e2a2bac293d53405348f6b}
      \strng{authorfullhash}{6bbccfc10d5cec4da080438a1099af8b}
      \field{extraname}{1}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This open-source book represents our attempt to make deep learning approachable, teaching readers the concepts, the context, and the code. The entire book is drafted in Jupyter notebooks, seamlessly integrating exposition figures, math, and interactive examples with self-contained code. Our goal is to offer a resource that could (i) be freely available for everyone; (ii) offer sufficient technical depth to provide a starting point on the path to actually becoming an applied machine learning scientist; (iii) include runnable code, showing readers how to solve problems in practice; (iv) allow for rapid updates, both by us and also by the community at large; (v) be complemented by a forum for interactive discussion of technical details and to answer questions.}
      \field{month}{8}
      \field{title}{Dive into {Deep} {Learning}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{urldateera}{ce}
      \true{nocite}
      \verb{doi}
      \verb 10.48550/arXiv.2106.11342
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/6UQVDYIR/Zhang et al. - 2023 - Dive into Deep Learning.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/P8FZREAH/2106.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2106.11342
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2106.11342
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Computation and Language}
    \endentry
    \entry{zhang_unreasonable_2018}{misc}{}
      \name{author}{5}{}{%
        {{hash=0c65190dcbd461dee172354f7938ae43}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod}}}%
        {{hash=cae9f806bc99a5f19fadea538fc2db04}{%
           family={Isola},
           familyi={I\bibinitperiod},
           given={Phillip},
           giveni={P\bibinitperiod}}}%
        {{hash=5a663b27298722834a8cf09bb93d8c94}{%
           family={Efros},
           familyi={E\bibinitperiod},
           given={Alexei\bibnamedelima A.},
           giveni={A\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=739ef881fb9e0c2c8d7110c90325d960}{%
           family={Shechtman},
           familyi={S\bibinitperiod},
           given={Eli},
           giveni={E\bibinitperiod}}}%
        {{hash=4954ab8be479c4a3f1496ddfbc21a605}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Oliver},
           giveni={O\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{a186c318a8836d77467280ce6646a302}
      \strng{fullhash}{b4812124f82ca96d3c1cb10ee3db7804}
      \strng{bibnamehash}{a186c318a8836d77467280ce6646a302}
      \strng{authorbibnamehash}{a186c318a8836d77467280ce6646a302}
      \strng{authornamehash}{a186c318a8836d77467280ce6646a302}
      \strng{authorfullhash}{b4812124f82ca96d3c1cb10ee3db7804}
      \field{extraname}{2}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on ImageNet classification has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called "perceptual losses"? What elements are critical for their success? To answer these questions, we introduce a new dataset of human perceptual similarity judgments. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by large margins on our dataset. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations.}
      \field{annotation}{Comment: Accepted to CVPR 2018; Code and data available at https://www.github.com/richzhang/PerceptualSimilarity}
      \field{month}{4}
      \field{note}{arXiv:1801.03924 [cs]}
      \field{title}{The {Unreasonable} {Effectiveness} of {Deep} {Features} as a {Perceptual} {Metric}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1801.03924
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/PXWT2YD5/Zhang et al. - 2018 - The Unreasonable Effectiveness of Deep Features as.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/9RA3SNIH/1801.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1801.03924
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1801.03924
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics}
    \endentry
    \entry{zhou_computation_1988}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=fe6bc778c2b4f965c677b9c0ee3e67c9}{%
           family={{Zhou}},
           familyi={Z\bibinitperiod}}}%
        {{hash=6be15c201e50f7933c2c925eb4ede88c}{%
           family={{Chellappa}},
           familyi={C\bibinitperiod}}}%
      }
      \strng{namehash}{45f22d1dbdcdaa3df8695f5fa752ed5e}
      \strng{fullhash}{45f22d1dbdcdaa3df8695f5fa752ed5e}
      \strng{bibnamehash}{45f22d1dbdcdaa3df8695f5fa752ed5e}
      \strng{authorbibnamehash}{45f22d1dbdcdaa3df8695f5fa752ed5e}
      \strng{authornamehash}{45f22d1dbdcdaa3df8695f5fa752ed5e}
      \strng{authorfullhash}{45f22d1dbdcdaa3df8695f5fa752ed5e}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A method for computing optical flow using a neural network is presented. Usually, the measurement primitives used for computing optical flow from successive image frames are the image-intensity values and their spatial and temporal derivatives, and tokens such as edges, corners, and linear features. Conventional methods based on such primitives suffer from edge sparsity, noise distortion, or sensitivity to rotation. The authors first fit a 2-D polynomial to find a smooth continuous image-intensity function in a window and estimate the subpixel intensity values and their principal curvatures. Under the local rigidity assumption and smoothness constraints, a neural network is then used to implement the computing procedure based on the estimated intensity values and their principal curvatures. Owing to the dense measured primitives, a dense optical flow with subpixel accuracy is obtained with only a few iterations. Since intensity values and their principle curvatures are rotation-invariant, this method can detect both rotating and translating objects in the scene. Experimental results using synthetic image sequences demonstrate the efficacy of the method.{<}{>}}
      \field{booktitle}{{IEEE} 1988 {International} {Conference} on {Neural} {Networks}}
      \field{month}{7}
      \field{title}{Computation of optical flow using a neural network}
      \field{urlday}{9}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{year}{1988}
      \field{urldateera}{ce}
      \field{pages}{71\bibrangedash 78 vol.2}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1109/ICNN.1988.23914
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/home/someusername/workspace/UNet-bSSFP/lit/storage/N4ACSJ9W/23914.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/23914
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/23914
      \endverb
      \keyw{Image processing,Neural networks}
    \endentry
    \entry{zwiers_bidscoin_2022}{article}{}
      \name{author}{3}{}{%
        {{hash=29d7498c0cba8abd26c5e70c0db4536a}{%
           family={Zwiers},
           familyi={Z\bibinitperiod},
           given={Marcel\bibnamedelima Peter},
           giveni={M\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=2e22547a3dd89a3c3ed568eec60e15f9}{%
           family={Moia},
           familyi={M\bibinitperiod},
           given={Stefano},
           giveni={S\bibinitperiod}}}%
        {{hash=05b1c01a0a7d7078ddff198775251440}{%
           family={Oostenveld},
           familyi={O\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {English}%
      }
      \strng{namehash}{33942f00230bffe3e17e7c55dbc837e6}
      \strng{fullhash}{33942f00230bffe3e17e7c55dbc837e6}
      \strng{bibnamehash}{33942f00230bffe3e17e7c55dbc837e6}
      \strng{authorbibnamehash}{33942f00230bffe3e17e7c55dbc837e6}
      \strng{authornamehash}{33942f00230bffe3e17e7c55dbc837e6}
      \strng{authorfullhash}{33942f00230bffe3e17e7c55dbc837e6}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Analyses of brain function and anatomy using shared neuroimaging data is an important development that has acquired the potential to be scaled up with the specification of the new Brain Imaging Data Structure (BIDS) standard. To date, there exists a variety of software tools to help researchers converting their source data to BIDS, but these tools often require programming skills or are tailored to specific institutes, datasets or data formats. Here we introduce BIDScoin, a cross-platform, flexible and user-friendly converter that provides a graphical user interface to help users finding their way in the BIDS standard. BIDScoin does not require programming skills to be set up and used, and supports plugins to extend its functionality. In this paper we show its design and demonstrate how it can be applied to a downloadable tutorial dataset. BIDScoin is distributed as free and open-source software to foster the community driven effort to promote and facilitate the use of the BIDS standard.}
      \field{issn}{1662-5196}
      \field{journaltitle}{Frontiers in Neuroinformatics}
      \field{month}{1}
      \field{note}{Publisher: Frontiers}
      \field{shorttitle}{{BIDScoin}}
      \field{title}{{BIDScoin}: {A} {User}-{Friendly} {Application} to {Convert} {Source} {Data} to {Brain} {Imaging} {Data} {Structure}}
      \field{urlday}{12}
      \field{urlmonth}{5}
      \field{urlyear}{2024}
      \field{volume}{15}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.3389/fninf.2021.770608
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/HZLFYGZF/Zwiers et al. - 2022 - BIDScoin A User-Friendly Application to Convert S.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.frontiersin.org/articles/10.3389/fninf.2021.770608
      \endverb
      \verb{url}
      \verb https://www.frontiersin.org/articles/10.3389/fninf.2021.770608
      \endverb
      \keyw{BIDS 1,conversion 3,data sharing 5,GUI 2,neuroimaging 4,open source software 6,plugin 8,Python 7}
    \endentry
  \enddatalist
\endrefsection
\endinput

