Neural Network with Unbounded Activation Functions is Universal Approximator
Sho Sonoda˚1 and Noboru Murata1 1Faculty of Science and Engineering, Waseda University

arXiv:1505.03654v2 [cs.NE] 29 Nov 2015

Abstract
This paper presents an investigation of the approximation property of neural networks with unbounded activation functions, such as the rectiﬁed linear unit (ReLU), which is the new de-facto standard of deep learning. The ReLU network can be analyzed by the ridgelet transform with respect to Lizorkin distributions. By showing three reconstruction formulas by using the Fourier slice theorem, the Radon transform, and Parseval’s relation, it is shown that a neural network with unbounded activation functions still satisﬁes the universal approximation property. As an additional consequence, the ridgelet transform, or the backprojection ﬁlter in the Radon domain, is what the network learns after backpropagation. Subject to a constructive admissibility condition, the trained network can be obtained by simply discretizing the ridgelet transform, without backpropagation. Numerical examples not only support the consistency of the admissibility condition but also imply that some non-admissible cases result in low-pass ﬁltering.

1 Introduction

Consider approximating a function f : Rm Ñ C by the neural network gJ with an activation function η:RÑC

1

J
ÿ

gJ pxq “ J cj ηpaj ¨ x ´ bjq,

paj, bj, cjq P Rm ˆ R ˆ C

(1)

j

where we refer to paj, bjq as a hidden parameter and cj as an output parameter. Let Ym`1 denote the space of hidden parameters Rm ˆ R. The network gJ can be obtained by discretizing the integral representation
of the neural network

ż

gpxq “

Tpa, bqηpa ¨ x ´ bqdµpa, bq,

(2)

Ym`1

where T : Ym`1 Ñ C corresponds to a continuous version of the output parameter; µ denotes a measure on Ym`1. The right-hand side expression is known as the dual ridgelet transform of T with respect to η

Rη: Tpxq

“

ż
Ym`1

Tpa,

bqηpa

¨

x

´

bq

dadb }a}

.

(3)

By substituting in Tpa, bq the ridgelet transform of f with respect to ψ

ż

Rψf pa, bq :“ f pxqψpa ¨ x ´ bq}a}dx,

(4)

Rm

under some good conditions, namely the admissibility of pψ, ηq and some regularity of f , we can reconstruct f by

Rη:Rψf “ f.

(5)

By discretizing the reconstruction formula, we can verify the approximation property of neural networks with the activation function η.

˚s.sonoda0110@toki.waseda.jp

1

In this study, we investigate the approximation property of neural networks for the case in which η is a Lizorkin distribution, by extensively constructing the ridgelet transform with respect to Lizorkin distributions. The Lizorkin distribution space S01 is such a large space that contains the rectiﬁed linear unit (ReLU) z`, truncated power functions z`k , and other unbounded functions that have at most polynomial growth (but do not have polynomials as such). Table 1 and Figure 1 give some examples of Lizorkin distributions.
Table 1: Zoo of activation functions with which the corresponding neural network can approximate arbitrary functions in L1pRmq in the sense of pointwise convergence (§ 5.2) and in L2pRmq in the sense of mean convergence (§ 5.3). The third column indicates the space WpRq to which an activation function η belong (§ 6.1, 6.2).

activation function

ηpzq

W

unbounded functions truncated power function

#

z`k :“

zk 0

zą0, zď0

k P N0

S01

rectiﬁed linear unit (ReLU) softplus function

z`

S01

σp´1qpzq :“ logp1 ` ezq

OM

bounded but not integrable functions

unit step function (standard) sigmoidal function

z`0 σpzq :“ p1 ` e´zq´1

S01 OM

hyperbolic tangent function

tanhpzq

OM

bump functions

(Gaussian) radial basis function

Gpzq :“ p2πq´1{2 exp `´z2{2˘ S

the ﬁrst derivative of sigmoidal function σ1pzq

S

Dirac’s δ

δpzq

S01

oscillatory functions

the kth derivative of RBF

Gpkqpzq

S

the kth derivative of sigmoidal function σpkqpzq

S

the kth derivative of Dirac’s δ

δpkqpzq

S01

Recall that the derivative of the ReLU z` is the step function z`0 . Formally, the following suggestive formula

ż
Ym`1

Tpa, bqη1pa ¨ x

´

dadb bq }a}

“

ż
Ym`1

BbTpa, bqηpa

¨

x

´

dadb bq }a} ,

(6)

holds, because the integral representation is a convolution in b. This formula suggests that once we have Tsteppa, bq for the step function, which is implicitly known to exist based on some of our preceding studies [1, 2], then we can formally obtain TReLUpa, bq for the ReLU by diﬀerentiating TReLUpa, bq “ BbTsteppa, bq.

1.1 ReLU and Other Unbounded Activation Functions
The ReLU [3, 4, 5, 6] became a new building block of deep neural networks, in the place of traditional bounded activation functions such as the sigmoidal function and the radial basis function (RBF). Compared with traditional units, a neural network with the ReLU is said [3, 7, 8, 9, 6] to learn faster because it has larger gradients that can alleviate the vanishing gradient [3], and perform more eﬃciently because it extracts sparser features. To date, these hypotheses have only been empirically veriﬁed without analytical evaluation.
It is worth noting that in approximation theory, it was already shown in the 1990s that neural networks with such unbounded activation functions have the universal approximation property. To be precise, if the activation function is not a polynomial function, then the family of all neural networks is dense in some

2

Figure 1: Zoo of activation functions: the Gaussian Gpzq (red), the ﬁrst derivative G1pzq (yellow), the second derivative G2pzq (green); a truncated power function z`2 (blue), the ReLU z` (sky blue), the unit step function z`0 (rose).
functional spaces such as LppRmq and C0pRmq. Mhaskar and Micchelli [10] seem to be the ﬁrst to have shown such universality by using the B-spline. Later, Leshno et al. [11] reached a stronger claim by using functional analysis. Refer to Pinkus [12] for more details.
In this study, we initially work through the same statement by using harmonic analysis, or the ridgelet transform. One strength is that our results are very constructive. Therefore, we can construct what the network will learn during backpropagation. Note that for bounded cases this idea is already implicit in [13] and [2], and explicit in [14].
1.2 Integral Representation of Neural Network and Ridgelet Transform
We use the integral representation of neural networks introduced by Murata [1]. As already mentioned, the integral representation corresponds to the dual ridgelet transform. In addition, the ridgelet transform corresponds to the composite of a wavelet transform after the Radon transform. Therefore, neural networks have a profound connection with harmonic analysis and tomography.
As K˚urkov´a [15] noted, the idea of discretizing integral transforms to obtain an approximation is very old in approximation theory. As for neural networks, at ﬁrst, Carroll and Dickinson [16] and Ito [13] regarded a neural network as a Radon transform [17]. Irie and Miyake [18], Funahashi [19], Jones [20], and Barron [21] used Fourier analysis to show the approximation property in a constructive way. K˚urkov´a [15] applied Barron’s error bound to evaluate the complexity of neural networks. Refer to Kainen et al. [22] for more details.
In the late 1990s, Cand`es [23, 24], Rubin [25], and Murata [1] independently proposed the so-called ridgelet transform, which has since been investigated by a number of authors [26, 27, 28, 29, 30, 31].
3

1.3 Variations of Ridgelet Transform
A ridgelet transform Rψ, along with its reconstruction property, is determined by four classes of functions: domain X pRmq, range YpYm`1q, ridgelet ZpRq, and dual ridgelet WpRq.

ψ P ZpRq

Rψ

$

X pRmq Qd f

T P YpYm`1q

(7)

Rη: η P WpRq

The following ladder relations by Schwartz [32] are fundamental for describing the variations of the ridgelet transform:

pfunctionsq

D Ă S Ă DL1 Ă DLp Ă OM Ă E

X

X

X

X

X

X

pdistributionsq E1 Ă OC1 Ă DL1 1 Ă DL1 p Ă S1 Ă D1 ,

(8)

loooooooooooooomoooooooooooooon integrable

looooooooooooooomooooooooooooooon not always bounded

where the meaning of symbols are given below in Table 2. The integral transform T by Murata [1] coincides with the case for Z Ă D and W Ă E X L1. Cand`es
[23, 24] proposed the “ridgelet transform” for Z “ W Ă S. Kostadinova et al. [30, 31] deﬁned the ridgelet transform for the Lizorkin distributions X “ S01 , which is the broadest domain ever known, at the cost of restricting the choice of ridgelet functions to the Lizorkin functions W “ Z “ S0 Ă S.

1.4 Our Goal
Although many researchers have investigated the ridgelet transform [26, 29, 30, 31], in all the settings Z does not directly admit some fundamental activation functions, namely the sigmoidal function and the ReLU. One of the challenges we faced is to deﬁne the ridgelet transform for W “ S01 , which admits the sigmoidal function and the ReLU.

2 Preliminaries
2.1 Notations
Throughout this paper, we consider approximating f : Rm Ñ C by a neural network g with hidden parameters pa, bq. Following Kostadinova et al. [30, 31], we denote by Ym`1 :“ Rm ˆ R the space of parameters pa, bq. As already denoted, we symbolize the domain of a ridgelet transform as X pRmq, the range as YpYm`1q, the space of ridgelets as ZpRq, and the space of dual ridgelets as WpRq.
We denote by Sm´1 the pm´1q-sphere tu P Rm | }u} “ 1u; by R` the open half-line tα P R | α ą 0u; by H the open half-space R` ˆ R. We denote by N and N0 the sets of natural numbers excluding 0 and including 0, respectively.
We denote by r¨ the reﬂection frpxq :“ f p´xq; by ¨ the complex conjugate; by a À b that there exists a constant C ě 0 such that a ď Cb.

2.2 Class of Functions and Distributions

Following Schwartz, we denote the classes of functions and distributions as in Table 2. For Schwartz’s

distributions, we refer to Schwartz [32] and Tr`eves [33]; for Lebesgue spaces, Rudin [34], Brezis [35] and

Yosida [36]; for Lizorkin distributions, Yuan et al. [37] and Holschneider [38].

The space S0pRkq of Lizorkin functions is a closed subspace of SpRkq that consists of elements such that

all

moments

vanish.

That

is,

S0 pRk q

:“

tφ

P

S pRk q

|

ş
Rk

xαφpxqdx

“

0

for

any

α P Nk0 u.

The

dual

space

S01 pRkq, known as the Lizorkin distribution space, is homeomorphic to the quotient space of S1pRkq by the

space of all polynomials PpRkq. That is, S01 pRkq – S1pRkq{PpRkq. Refer to Yuan et al. [37, Prop. 8.1]

4

space

Table 2: Classes of functions and distributions, and corresponding dual spaces.

ApRk q

dual space

A1 pRk q

polynomials of all degree smooth functions rapidly decreasing functions compactly supported smooth functions Lp of Sobolev order 8 p1 ď p ă 8q completion of DpRkq in DL8 pRkq slowly increasing functions – Lizorkin functions

P pRk q E pRk q S pRk q DpRk q DLp pRkq B9 pRk q OM pRk q
S0 pRk q

– compactly supported distributions tempered distributions Schwartz distributions Schwartz dists. p1{p ` 1{q “ 1q Schwartz dists. pp “ 1q – rapidly decreasing distributions Lizorkin distributions

E 1 pRk q S 1 pRk q D1 pRk q DL1 q pRkq DL1 1 pRkq
OC1 pRkq S01 pRkq

for more details. In this work we identify and treat every polynomial as zero in the Lizorkin distribution. That is, for p P S1pRkq, if p P PpRkq then p ” 0 in S01 pRkq.
For Sm´1, we work on the two subspaces DpSm´1q Ă DpRmq and E1pSm´1q Ă E1pRmq. In addition, we identify D “ S “ OM “ E and E1 “ OC1 “ S1 “ DL1 p “ D1.
For H, let EpHq Ă EpR2q and DpHq Ă DpR2q. For T P EpHq, write

Dks,,t Tpα, βq :“ pα ` 1{αqs p1 ` β2qt{2Bαk BβTpα, βq, s, t, k, P N0.

(9)

The space SpHq consists of T P EpHq such that for any s, t, k, P N0, the seminorm below is ﬁnite

sup ˇˇDks,,t Tpα, βqˇˇ ă 8.
pα,βqPH

(10)

The space OMpHq consists of T P EpHq such that for any k, P N0 there exist s, t P N0 such that

ˇˇDk0,,0Tpα, βqˇˇ À pα ` 1{αqsp1 ` β2qt{2.

(11)

The space D1pHq consists of all bounded linear functionals Φ on DpHq such that for every compact set K Ă H, there exists N P N0 such that

ˇ

ˇ

ˇ ˇ ˇ ˇ

ż
K

Tpα,

βqΦpα,

βq

dαdβ α

ˇ ˇ ˇ ˇ

À

ÿ
k, ďN

sup
pα,βqPH

|Dk0,,0Tpα,

βq|,

@T P DpKq,

(12)

where the integral is understood as the action of Φ. The space S1pHq consists of Φ P SpHq for which there exists N P N0 such that

ˇ

ˇ

ˇ ˇ ˇ ˇ

ż
H

Tpα,

βqΦpα,

βq

dαdβ α

ˇ ˇ ˇ ˇ

À

ÿ
s,t,k, ďN

sup
pα,βqPH

ˇˇDks,,t

Tpα,

βqˇˇ,

@T P SpHq.

(13)

2.3 Convolution of Distributions
Table 3 lists the convergent convolutions of distributions and their ranges by Schwartz [32]. In general a convolution of distributions may neither commute φ ˚ ψ ‰ ψ ˚ φ nor associate φ ˚ pψ ˚ ηq ‰
pφ ˚ ψq ˚ η. According to Schwartz [32, Ch.6 Th.7, Ch.7 Th.7], both D1 ˚ E1 ˚ E1 ˚ ¨ ¨ ¨ and S1 ˚ OC1 ˚ OC1 ˚ ¨ ¨ ¨ are commutative and associative.

2.4 Fourier Analysis

The Fourier transform p¨ of f : Rm Ñ C and the inverse Fourier transform q¨ of F : Rm Ñ C are given by

ż

fppξq :“ f pxqe´ix¨ξdx, ξ P Rm

(14)

Rm

Fqpxq

:“

1 p2πqm

ż
Rm

F pξqeix¨ξdξ,

x P Rm.

(15)

5

Table 3: Range of convolution (excerpt from Schwartz [32])

case

A1 A2

A1 ˚ A2

regularization

D

compactly supported distribution E1

D1, DL1 p , E 1 E1, E, D1

E, Lp, D E1, E, D1

regularization Schwartz convolutor Young’s inequality

S

S, S1

S, OM

OC1 S, OC1 , DL1 p , S1 S, OC1 , DL1 p , S1

Lp Lq

Lr p1{r “ 1{p ` 1{q ´ 1q

Young’s inequality

DL1 p DLq , DL1 q

DL1 r p1{r “ 1{p ` 1{q ´ 1q

The Hilbert transform H of f : R Ñ C is given by

Hf psq

:“

i ż8

p.v.

π

´8

f ptq dt, s´t

sPR

(16)

where

p.v.

ş8
´8

denotes

the

principal

value.

We

set

the

coeﬃcients

above

to

satisfy

Hyf pωq “ sgn ω ¨ fppωq,

(17)

H2f psq “ f psq.

(18)

2.5 Radon Transform

The Radon transform R of f : Rm Ñ C and the dual Radon transform R˚ of Φ : Sm´1 ˆ R Ñ C are given by

ż

Rf pu, pq :“

f ppu ` yqdy, pu, pq P Sm´1 ˆ R

(19)

pRuqK

ż

R˚Φpxq :“

Φpu, u ¨ xqdu, x P Rm

(20)

Sm´1

where pRuqK :“ ty P Rm | y ¨ u “ 0u denotes the orthogonal complement of a line Ru Ă Rm; and dy denotes the Lebesgue measure on pRuqK; and du denotes the surface measure on Sm´1.
We use the following fundamental results ([17, 39]) for f P L1pRmq without proof: Radon’s inversion
formula

R˚Λm´1Rf “ 2p2πqm´1f,

(21)

where the backprojection ﬁlter Λm is deﬁned in (24); the Fourier slice theorem

ż

fppωuq “ Rf pu, pqe´ipωdp, pu, ωq P Sm´1 ˆ R

(22)

R

where the left-hand side is the m-dimensional Fourier transform, whereas the right-hand side is the one-

dimensional Fourier transform of the Radon transform; and a corollary of Fubini’s theorem

ż

ż

Rf pu, pqdp “ f pxqdx, a.e. u P Sm´1.

(23)

R

Rm

2.6 Backprojection ﬁlter

For a function Φpu, pq, we deﬁne the backprojection ﬁlter Λm as

$

& ΛmΦpu, pq :“

BpmΦpu, pq,

m even

(24)

% HpBpmΦpu, pq, m odd.

where Hp and Bp denote the Hilbert transform and the partial diﬀerentiation with respect to p, respectively. It is designed as a one-dimensional Fourier multiplier with respect to p Ñ ω such that

Λz mΦpu, ωq “ im|ω|mΦppu, ωq.

(25)

6

3 Classical Ridgelet Transform

3.1 An Overview

The ridgelet transform Rψf of f : Rm Ñ C with respect to ψ : R Ñ C is formally given by

ż

Rψf pa, bq :“ f pxqψpa ¨ x ´ bq}a}sdx, pa, bq P Ym`1 and s ą 0.

(26)

Rm

The factor |a|s is simply posed for technical convenience. After the next section we set s “ 1, which
simpliﬁes some notations (e.g., Theorem 4.2). Murata [1] originally posed s “ 0, which is suitable for the
Euclidean formulation. Other authors such as Cand`es [24] used s “ 1{2, Rubin [25] used s “ m, and
Kostadinova et al. [30] used s “ 1 . When f P L1pRmq and ψ P L8pRq, by using H¨older’s inequality, the ridgelet transform is absolutely
convergent at every pa, bq P Ym`1.

ż

ˇˇf pxqψpa ¨ x ´ bq}a}sˇˇdx ď }f }L1pRmq ¨ }ψ}L8pRq ¨ }a}s ă 8.

(27)

Rm

In particular when s “ 0, the estimate is independent of a and thus Rψf P L8pYm`1q. Furthermore, R is a bounded bilinear operator L1pRmq ˆ L8pRq Ñ L8pYm`1q.
The dual ridgelet transform Rη:T of T : Ym`1 Ñ C with respect to η : R Ñ C is formally given by

ż

Rη:Tpxq :“

Tpa, bqηpa ¨ x ´ bq}a}´sdadb, x P Rm.

(28)

Ym`1

The integral is absolutely convergent when η P L8pRq and T P L1pYm`1; }a}´sdadbq at every x P Rm,

ż
ˇˇTpa, bqηpa ¨ x ´ bqˇˇ}a}´sdadb ď }T}L1pYm`1;}a}´sdadbq ¨ }η}L8pRq ă 8,
Ym`1

(29)

and thus R: is a bounded bilinear operator L1pYm`1; }a}´sdadbq ˆ L8pRq Ñ L8pRmq. Two functions ψ and η are said to be admissible when

Kψ,η

:“

p2πqm´1

ż8
´8

ψppζ qηppζ |ζ |m

q

dζ

,

(30)

is ﬁnite and not zero. Provided that ψ, η, and f belong to some good classes, and ψ and η are admissible, then the reconstruction formula

Rη:Rψf “ Kη,ψf,

(31)

holds.

3.2 Ridgelet Transform in Other Expressions
It is convenient to write the ridgelet transform in “polar” coordinates as

Rψ f

pu,

α,

βq

“

ż
Rm

f

pxqψ

ˆ

u

¨

x´ α

β

˙

1 αs

dx,

(32)

where “polar” variables are given by

u :“ a{}a}, α :“ 1{}a}, β :“ b{}a}.

(33)

Emphasizing the connection with wavelet analysis, we deﬁne the “radius” α as reciprocal. Provided there
is no likelihood of confusion, we use the same symbol Ym`1 for the parameter space, regardless of whether it is parametrized by pa, bq P Rm ˆ R or pu, α, βq P Sm´1 ˆ R` ˆ R.
For a ﬁxed pu, α, βq P Ym`1, the ridgelet function

ψu,α,β

pxq

:“

ψ

ˆ

u

¨

x´ α

β

˙

1 αs

,

x P Rm

(34)

7

behaves as a constant function on pRuqK, and as a dilated and translated wavelet function on Ru. That is, by using the orthogonal decomposition x “ pu ` y with p P R and y P pRuqK,

ψu,α,β pxq

“

ψ ˆ u ¨ ppu ` yq ´ β ˙ α

1 αs

“

ψˆp ´ β˙ α

1 αs

b 1pyq.

(35)

By using the decomposition above and Fubini’s theorem, and assuming that the ridgelet transform is absolutely convergent, we have the following equivalent expressions

˜

¸

ż Rψf pu, α, βq “
R

ż
f ppu ` yqdy
pRuqK

ψ

ˆ

p

´ α

β

˙

1 αs

dp

(36)

“

ż
R

Rf

pu,

pq

ψ

ˆ

p

´ α

β

˙

1 αs

dp

ż “ α1´sRf pu, αz ` βq ψpzqdz

R

´

¯

´p¯ 1

“ Rf pu, ¨q ˚ ψĂα pβq, ψαppq :“ ψ α αs

“

1 2π

ż
R

fppωuqψppαωqα1´s eiωβ dω,

(37) (weak form) (38) (convolution form) (39) (Fourier slice th. [30]) (40)

where R denotes the Radon transform (19); the Fourier form follows by applying the identity Fω´1Fp “ Id to the convolution form. These reformulations reﬂect a well-known claim [28, 30] that ridgelet analysis is
wavelet analysis in the Radon domain.

3.3 Dual Ridgelet Transform in Other Expressions

Provided the dual ridgelet transform (28) is absolutely convergent, some changes of variables lead to other expressions.

żż

Rη:Tpxq “

Tpa, bqηpa ¨ x ´ bq}a}´sdb da

Rm R

ż8ż ż

“

Tpru, bqηpru ¨ x ´ bqdb du rm´s´1dr

0 Sm´1 R

“

ż
Sm´1

ż8
0

ż
R

T

ˆ

u α

,

β˙ α

η

ˆ

u

¨

x´ α

β

˙

dβdαdu αm´s`2

ż ż8ż

dzdαdu

“
Sm´1 0

R T pu, α, u ¨ x ´ αzq ηpzq αm´s`1 ,

(41) (42) (polar expression) (43) (weak form) (44)

where every integral is understood to be an iterated integral; the second equation follows by substituting

pr, uq Ð p}a}, a{}a}q and using the coarea formula for polar coordinates; the third equation follows by

substituting pα, βq Ð p1{r, b{rq and using Fubini’s theorem; in the fourth equation with a slight abuse of

notation, we write Tpu, α, βq :“ Tpu{α, β{αq.

Furthermore, write ηαppq :“ ηpp{αq{αt. Recall that the dual Radon transform R˚ is given by (20) and

the

Mellin

transform M [38] is

given

by

Mf pzq

:“

ş8
0

f pαqαz´1dα,

z P C.

Then,

Rη:Tpxq “ R˚ rMrTpu, α, ¨q ˚ ηαsps ` t ´ m ´ 1qs pxq.

(45)

Note that the composition of the Mellin transform and the convolution is the dual wavelet transform [38]. Thus, the dual ridgelet transform is the composition of the dual Radon transform and the dual wavelet transform.

4 Ridgelet Transform with respect to Distributions
Using the weak expressions (38) and (44), we deﬁne the ridgelet transform with respect to distributions. Henceforth, we focus on the case for which the index s in (26) equals 1.

8

4.1 Deﬁnition and Well-Deﬁnedness

Deﬁnition 4.1 (Ridgelet Transform with respect to Distributions). The ridgelet transform Rψf of a function f P X pRmq with respect to a distribution ψ P ZpRq is given by

ż

Rψf pu, α, βq :“ Rf pu, αz ` βq ψpzqdz, pu, α, βq P Ym`1

(46)

R

where ş ¨ ψpzqdz is understood as the action of a distribution ψ.
R
Obviously, this “weak” deﬁnition coincides with the ordinary strong one when ψ coincides with a locally integrable function pL1locq. With a slight abuse of notation, the weak deﬁnition coincides with the convolution form

´

¯

Rψf pu, α, βq “ Rf pu, ¨q ˚ ψĂα pβq, pu, α, βq P Ym`1

(47)

where ψαppq :“ ψ pp{αq {α; the convolution ¨ ˚ ¨, dilation ¨α, reﬂection r¨, and complex conjugation ¨ are understood as operations for Schwartz distributions.
Theorem 4.2 (Balancing Theorem). The ridgelet transform R : X pRmq ˆ ZpRq Ñ YpYm`1q is well deﬁned as a bilinear map when X and Z are chosen from Table 4.

Table 4: Combinations of classes for which the ridgelet transform is well deﬁned as a bilinear map. The ﬁrst and third columns list domains X pRmq of f and ZpRq of ψ, respectively. The second column lists the range of the Radon transform Rf pu, pq for which we reused the same symbol X as it coincides. The fourth, ﬁfth, and sixth columns list the range of the ridgelet transform with respect to β, pα, βq, and pu, α, βq, respectively.

f pxq Rf pu, pq

ψpzq

Rψf pu, α, βq

X pRmq X pSm´1 ˆ Rq ZpRq

BpRq

ApHq YpYm`1q

D E1 S OC1 L1 DL1 1

D E1 S OC1 L1 DL1 1

D1 D1 S1 S1 Lp X C0 DL1 p

E D1 OM S1 Lp X C0 DL1 p

E D1 OM S1 S1 S1

E D1 OM S1 S1 S1

The proof is provided in A. Note that each Z is (almost) the largest in the sense that the convolution
B “ X ˚ Z converges. Thus, Table 4 suggests that there is a trade-oﬀ relation between X and Z, that is, as X increases, Z decreases and vice versa.
Extension of the ridgelet transform of non-integrable functions requires more sophisticated approaches,
because a direct computation of the Radon transform may diverge. For instance, Kostadinova et al. [30] extend X “ S01 by using a duality technique. In § 5.3 we extend the ridgelet transform to L2pRmq, by using the bounded extension procedure.

Proposition 4.3 (Continuity of the Ridgelet Transform L1pRmq Ñ L8pYm`1q). Fix ψ P SpRq. The ridgelet transform Rψ : L1pRmq Ñ L8pYm`1q is bounded.
Proof. Fix an arbitrary f P L1pRmq and ψ P SpRq. Recall that this case is absolutely convergent. By using the convolution form,

ˇ´

¯ˇ

ess sup ˇ ˇ

Rf pu, ¨q ˚ ψĂα

pβqˇˇ ď }f }L1pRmq ¨ ess sup |ψαpβq|

(48)

pu,α,βq

pα,βq

ď }f }L1pRmq ¨ ess sup |r ¨ ψprβq| ă 8,

(49)

pr,βq

where

the

ﬁrst

inequality

follows

by

using

Young’s

inequality

and

applying

ş
R

|Rf

pu,

pq|dp

“

}f }1;

the

second inequality follows by changing the variable r Ð 1{α, and the resultant is ﬁnite because ψ decays

rapidly.

9

The ridgelet transform Rψ is injective when ψ is admissible, because if ψ is admissible then the
reconstruction formula holds and thus Rψ has the inverse. However, Rψ is not always injective. For instance, take a Laplacian f :“ ∆g of some function g P SpRmq and a polynomial ψpzq “ z ` 1, which satisﬁes ψp2q ” 0. According to Table 4, Rψf exists as a smooth function because f P SpRmq and ψ P S1pRq. In this case Rψf “ 0, which means Rψ is not injective. That is,

´

¯

Rψf pu, α, βq “ R∆gpu, ¨q ˚ ψĂα pβq

(50)

´

¯

“ B2Rgpu, ¨q ˚ ψĂα pβq

(51)

´

¯

“ Rgpu, ¨q ˚ B2ψĂα pβq

(52)

“ pRgpu, ¨q ˚ 0q pβq

(53)

“ 0,

(54)

where the second equality follows by the intertwining relation R∆gpu, pq “ Bp2Rgpu, pq [17]. Clearly the non-injectivity stems from the choice of ψ. In fact, as we see in the next section, no polynomial can be
admissible and thus Rψ is not injective for any polynomial ψ.

4.2 Dual Ridgelet Transform with respect to Distributions

Deﬁnition 4.4 (Dual Ridgelet Transform with respect to Distributions). The dual ridgelet transform Rη:T of T P YpYm`1q with respect to η P WpRq is given by

Rη: Tpxq

“

lim
δÑ8 εÑ0

ż
Sm´1

żδ
ε

ż
R

T

pu,

α,

u

¨

x

´

αzq

ηpzq

dzdαdu αm

,

x P Rm

(55)

where ş ¨ηpzqdz is understood as the action of a distribution η.
R
If the dual ridgelet transform Rη: exists, then it coincides with the dual operator [36] of the ridgelet transform Rη.
Theorem 4.5. Let X and Z be chosen from Table 4. Fix ψ P Z. Assume that Rψ : X pRmq Ñ YpYm`1q is injective and that Rψ: : Y1pYm`1q Ñ X 1pRmq exists. Then Rψ: is the dual operator pRψq1 : Y1pYm`1q Ñ X 1pRmq of Rψ.
Proof. By assumption Rψ is densely deﬁned on X pRmq and injective. Therefore, by a classical result on the existence of the dual operator [36, VII. 1. Th. 1, pp.193], there uniquely exists a dual operator pRψq1 : Y1pYm`1q Ñ X 1pRmq. On the other hand, for f P X pRmq and T P YpYm`1q,

ż

A

E

xRψf, TyYm`1 “

f pxqψpa ¨ x ´ bqTpa, bqdxdadb “
Rm ˆYm`1

f, Rψ: T

.
Rm

(56)

By the uniqueness of the dual operator, we can conclude pRψq1 “ Rψ: .

5 Reconstruction Formula for Weak Ridgelet Transform
In this section we discuss the admissibility condition and the reconstruction formula, not only in the Fourier domain as many authors did [23, 24, 1, 30, 31], but also in the real domain and in the Radon domain. Both domains are key to the constructive formulation. In § 5.1 we derive a constructive admissibility condition. In § 5.2 we show two reconstruction formulas. The ﬁrst of these formulas is obtained by using the Fourier slice theorem and the other by using the Radon transform. In § 5.3 we will extend the ridgelet transform to L2.

5.1 Admissibility Condition

Deﬁnition 5.1 (Admissibility Condition). A pair pψ, ηq P SpRq ˆ S1pRq is said to be admissible when there exists a neighborhood Ω Ă R of 0 such that ηp P L1locpΩzt0uq, and the integral

˜

¸

Kψ,η :“ p2πqm´1

ż

ż

`

Ωzt0u RzΩ

ψppζ qηppζ |ζ |m

q

dζ

,

(57)

10

converges

and

is

not

zero,

where

ş
Ωzt0u

and

ş
RzΩ

are

understood

as

Lebesgue’s

integral

and

the

action

of

ηp, respectively.

Using the Fourier transform in W requires us to assume that W Ă S1.

The

second

integral

ş
RzΩ

is

always

ﬁnite

because

|ζ |´m

P

OMpRzΩq

and

thus

|ζ |´m ψppζ q

decays

rapidly;

therefore, by deﬁnition the action of a tempered distribution η always converges. The convergence of the

p

ﬁrst

integral

ş
Ωzt0u

does

not

depend

on

the

choice

of

Ω

because

for

every

two

neighborhoods

Ω

and

Ω1

of

0,

the

residual

ş
ΩzΩ1

is

always

ﬁnite.

Hence,

the

convergence

of

Kψ,η

does

not

depend

on

the

choice

of

Ω.

The removal of 0 from the integral is essential because a product of two singular distributions, which

is indeterminate in general, can occur at 0. See examples below. In C, we have to treat |ζ|´m as a locally

integrable function, rather than simply a regularized distribution such as Hadamard’s ﬁnite part. If the

integrand

coincides

with

a

function

at

0,

then

obviously

ş
Rzt0u

“

ş.
R

If

η p

is

supported

in

the

singleton

t0u

then

η

cannot

be

admissible

because

Kψ,η

“

0

for

any

ψ

P

S pRq.

According to Rudin [34, Ex. 7.16], it happens if and only if η is a polynomial. Therefore, it is natural

to take W “ S1{P – S01 rather than W “ S1. That is, in S01 pRq, we identify a polynomial η P PpRq as 0 P S1pRq. The integral Kψ,η is well-deﬁned for S01 pRq. Namely Kψ,η is invariant under the addition of a
polynomial Q to η

Kψ,η “ Kψ,η`Q.

(58)

Example 5.2 (Modiﬁcation of Schwartz [32, Ch.5 Th.6]). Let ηpzq “ z and ψpzq “ ΛGpzq with Gpzq “ expp´z2{2q. Then,

ηppζq “ δpζq and ψppζq “ |ζ| ¨ Gpζq.

(59)

In this case the product of the two distributions is not associative

ż

1

p.v.
R

|ζ |

ˆ p|ζ| ¨ Gpζq ˆ δpζqq dζ

“ 0,

(60)

żˆ 1

˙

R p.v. |ζ| ˆ |ζ| ¨ Gpζq ˆ δpζqdζ “ Gp0q ‰ 0.

(61)

On the other hand (57) is well deﬁned

Kψ,η

“

ż
0ă|ζ|ă1

|ζ |

¨

Gpζ q |ζ |

ˆ

0 dζ

`

ż
1ď|ζ|

|ζ |

¨ Gpζq |ζ |

δpζ

qdζ

“

0.

(62)

Example 5.3. Let ηpzq “ z`0 ` p2πq´1 exp iz and ψpzq “ ΛGpzq. Then,

i

ηppζq “ ζ ` δpζq ` δpζ ´ 1q and ψppζq “ |ζ| ¨ Gpζq.

(63)

The product of the two distributions is not associative

ż

1ˆ

ˆi

˙˙

p.v.
R

|ζ |

ˆ

|ζ| ¨ Gpζq ˆ

ζ ` δpζq ` δpζ ´ 1q

dζ “ Gp1q,

(64)

żˆ 1

˙ ˆi

˙

R p.v. |ζ| ˆ |ζ| ¨ Gpζq ˆ ζ ` δpζq ` δpζ ´ 1q dζ “ Gp0q ` Gp1q ‰ 0.

(65)

On the other hand, (57) is well deﬁned

Kψ,η

ż
“
0ă|ζ|ă1

|ζ |

¨

Gpζq ˆ |ζ |

iζ ´1

dζ

`

ż
1ď|ζ|

|ζ |

¨

Gpζ

q

ˆ p.v.

|ζ |

i ζ

˙ ` δpζq ` δpζ ´ 1q dζ

“ 8 ` Gp1q.

(66)

Observe that formally the integrand uppζq :“ ψppζqηppζq|ζ|´m is a solution of |ζ|muppζq “ ψppζqηppζq. By
taking the Fourier inversion, we have Λmu “ ψr ˚ η. To be exact, ηp may contain a point mass at the origin, such as Dirac’s δ.

11

Theorem 5.4. (Structure Theorem for Admissible Pairs) Let pψ, ηq P SpRq ˆ S1pRq. Assume that there exists k P N0 such that

k

ηppζq “ ÿ cjδpjqpζq, ζ P t0u.

(67)

j“0

Assume that there exists a neighborhood Ω of 0 such that ηp P C0pΩzt0uq. Then ψ and η are admissible if and only if there exists u P OMpRq such that

˜

k

¸

ż

Λmu “ ψr ˚ η ´ ÿ cjzj

and

uppζqdζ ‰ 0,

(68)

j“0

Rzt0u

where Λ is the backprojection ﬁlter deﬁned in (24). In addition, limζÑ`0 |uppζq| ă 8 and limζÑ´0 |uppζq| ă 8.

The proof is provided in B. Note that the continuity implies local integrability. If ψ has

moments with

ě

k,

namely

ş
R

ψpzqzj dz

“

0

for

j

ď

, then the condition reduces to

Λmu “ ψr ˚ η,

ˇ

ˇ

ˇż

ˇ

ż

ˇ upzqdzˇ ă 8 and

ˇ

ˇ

uppζqdζ ‰ 0.

ˇR

ˇ

R

vanishing (69)

As a consequence of Theorem 5.4, we can construct admissible pairs as below.

Corollary 5.5 (Construction of Admissible Pairs). Given η P S01 pRq. Assume that there exists a neighborhood Ω of 0 and k P N0 such that ζk ¨ ηppζq P C0pΩq. Take ψ0 P SpRq such that

ż

ζk ψx0pζqηppζqdζ ‰ 0.

(70)

R

Then

ψ :“ Λmψ0pkq,

(71)

is admissible with η.

The proof is obvious because u :“ ψĄ0pkq ˚ η satisﬁes the conditions in Theorem 5.4.

5.2 Reconstruction Formula

Theorem 5.6 (Reconstruction Formula). Let f P L1pRmq satisfy fp P L1pRmq and let pψ, ηq P SpRqˆS01 pRq be admissible. Then the reconstruction formula

Rη:Rψf pxq “ Kψ,ηf pxq,

(72)

holds for almost every x P Rm. The equality holds for every point where f is continuous.

The proof is provided in C. The admissibility condition can be easily inverted to pψ, ηq P S01 ˆ S. However, extensions to S01 ˆ S01 and S ˆ D1 may not be easy. This is because the multiplication S01 ¨ S01 is not always commutative, nor associative, and the Fourier transform is not always deﬁned over D1 [32].
The following theorem is another suggestive reconstruction formula that implies wavelet analysis in the
Radon domain works as a backprojection ﬁlter. In other words, the admissibility condition requires pψ, ηq to construct the ﬁlter Λm. Note that similar techniques are obtained for “wavelet measures” by Rubin
[29, 25].

Theorem 5.7 (Reconstruction Formula via Radon Transform). Let f P L1pRmq be suﬃciently smooth and pψ, ηq P SpRq ˆ S1pRq be admissible. Assume that there exists a real-valued smooth and integrable
function u such that

ż

Λmu “ ψr ˚ η and

uppζqdζ “ ´1.

(73)

R

Then,

Rη:Rψf pxq “ R˚Λm´1Rf pxq “ 2p2πqm´1f pxq,

(74)

holds for almost every x P Rm.

12

The proof is provided in D. Note that here we imposed a stronger condition on u than the u P L1pRzt0uq we imposed in Theorem 5.4.
Recall intertwining relations ([17, Lem.2.1, Th.3.1, Th.3.7])

m´1
p´∆q 2

R˚

“

Λm´1R,

and

m´1
Rp´∆q 2

“ R˚Λm´1.

(75)

Therefore, we have the following.

Corollary 5.8.

Rη: Rψ

“

R˚Λm´1R

“

p´∆q

m´1 2

R˚

R

“

R˚

Rp´∆q

m´1 2

.

(76)

5.3 Extension to L2

By p¨, ¨q and } ¨ }2, with a slight abuse of notation, we denote the inner product of L2pRmq and L2pYm`1q. Here we endow Ym`1 with a ﬁxed measure α´mdαdβdu, and omit writing it explicitly as L2pYm`1; . . . q.
We say that ψ is self-admissible if ψ is admissible in itself, i.e. the pair pψ, ψq is admissible. The following
relation is immediate by the duality.

Theorem 5.9 (Parseval’s Relation and Plancherel’s Identity). Let pψ, ηq P S ˆ S1 be admissible with, for simplicity, Kψ,η “ 1. For f, g P L1 X L2pRmq,

pRψf, Rηgq “ `Rη:Rψf, g˘ “ pf, gq .

Parseval’s Relation

(77)

In particular, if ψ is self-admissible, then

}Rψf }2 “ }f }2.

Plancherel’s identity

(78)

Recall Proposition 4.3 that the ridgelet transform is a bounded linear operator on L1pRmq. If ψ P SpRq is self-admissible, then we can extend the ridgelet transform to L2pRmq, by following the bounded extension procedure [40, 2.2.4]. That is, for f P L2pRmq, take a sequence fn P L1 X L2pRmq such that fn Ñ f in L2.
Then by Plancherel’s identity,

}fn ´ fm}2 “ }Rψfn ´ Rψfm}2, @n, m P N.

(79)

The right-hand side is a Cauchy sequence in L2pYm`1q as n, m Ñ 8. By the completeness, there uniquely exists the limit T8 P L2pYm`1q of Rψfn. We regard T8 as the ridgelet transform of f and deﬁne Rψf :“ T8.
Theorem 5.10 (Bounded Extension of Ridgelet Transform on L2). Let ψ P SpRq be self-admissible with Kψ,ψ“1. The ridgelet transform on L1 X L2pRmq admits a unique bounded extension to L2pRmq, with satisfying }Rψf }2 “ }f }2.

We say that pψ, ηq and pψ‹, η‹q are equivalent, if two admissible pairs pψ, ηq and pψ‹, η‹q deﬁne the same convolution ψr ˚ η “ ψĂ‹ ˚ η‹ in common. If pψ, ηq and pψ‹, η‹q are equivalent, then obviously

pRψf, Rηgq “ pRψ‹ f, Rη‹ gq .

(80)

We say that an admissible pair pψ, ηq is admissibly decomposable, when there exist self-admissible pairs pψ‹, ψ‹q and pη‹, η‹q such that pψ‹, η‹q is equivalent to pψ, ηq. If pψ, ηq is admissibly decomposable with pψ‹, η‹q, then by the Schwartz inequality

pRψf, Rηgq ď }Rψ‹ f }2}Rη‹ g}2.

(81)

Theorem 5.11 (Reconstruction Formula in L2). Let f P L2pRmq and pψ, ηq P S ˆ S1 be admissibly decomposable with Kψ,η “ 1. Then,

Rη:Rψf Ñ f, in L2.

(82)

The proof is provided in E. Even when ψ is not self-admissible and thus Rψ cannot be deﬁned on L2pRmq, the reconstruction operator Rη:Rψ can be deﬁned with the aid of η.

13

6 Neural Network with Unbounded Activation Functions
In this section we instantiate the universal approximation property for the variants of neural networks. Recall that a neural network coincides with the dual ridgelet transform of a function. Henceforth, we rephrase a dual ridgelet function as an activation function. According to the reconstruction formulas (Theorem 5.6, 5.7, and 5.11), we can determine whether a neural network with an activation function η is a universal approximator by checking the admissibility of η.
Table 1 lists some Lizorkin distributions for potential activation functions. In § 6.1 we verify that they belong to S01 pRq and some of them belong to OMpRq and SpRq, which are subspaces of S01 pRq. In § 6.2 we show that they are admissible with some ridgelet function ψ P SpRq; therefore, each of their corresponding neural networks is a universal approximator.

6.1 Examples of Lizorkin Distributions
We proved the class properties by using the following propositions.
Proposition 6.1 (Tempered Distribution S1pRq [40, Ex. 2.3.5]). Let g P L1locpRq. If |gpzq| À p1 ` |z|qk for some k P N0, then g P S1pRq.
Proposition 6.2 (Slowly Increasing Function OMpRq [40, Def. 2.3.15]). Let g P EpRq. If for any α P N0, |Bαgpxq| À p1 ` |z|qkα for some kα P N0, then g P OMpRq. Example 6.3. Truncated power functions z`k pk P N0q, which contain the ReLU z` and the step function z`0 , belong to S01 pRq. Proof. For any P N0 there exists a constant C such that |B pz`k q| ď C p1`|z|qk´ . Hence, z`k P S01 pRq. Example 6.4. The sigmoidal function σpzq and the softplus σp´1qpzq belong to OMpRq. The derivatives σpkqpzq pk P Nq belong to SpRq. Hyperbolic tangent tanhpzq belongs to OMpRq.
The proof is provided in F
Example 6.5 ([40, Ex.2.2.2]). RBF Gpzq and their derivatives Gpkqpzq belong to SpRq. Example 6.6 ([40, Ex.2.3.5]). Dirac’s δpzq and their derivatives δpkqpzq belong to S1pRq.

6.2 Kψ,η when ψ is a derivative of the Gaussian
Given an activation function η P S01 pRq, according to Corollary 5.5 we can construct an admissible ridgelet function ψ P SpRq by letting

ψ :“ Λmψ0,

(83)

where ψ0 P SpRq satisﬁes

A Eż

ηp, ψx0 :“

ψx0pζqηppζqdζ ‰ 0, ˘8.

(84)

Rzt0u

Here we consider the case when ψ0 is given by

ψ0 “ Gp q,

(85)

for

some P N0, where G denotes The Fourier transform of the

the Gaussian Gpzq :“ expp´z2{2q. Gaussian is given by Gp pζq “ expp´ζ2{2q

“

? 2π Gpζq.

The Hilbert

transform of the Gaussian, which we encounter by computing ψ “ ΛmG when m is odd, is given by

2i ˆ z ˙

HGpzq

“

?F π

? 2

,

where

F pzq

is

the

Dawson

function

F pzq

:“

expp´z2q

şz
0

exppw2qdw.

Example 6.7. z`k pk P N0q is admissible with ψ “ ΛmGp `k`1q p P N0q iﬀ Kψ,η “ 0.

(86) is even. If odd, then

14

Proof. It follows from the fact that, according to Gel’fand and Shilov [41, § 9.3],

zx`k pζq

“

k! piζ qk`1

`

πik δ pkq pζ q,

k P N0.

Example 6.8. ηpzq “ δpkqpzq pk P N0q is admissible with ψ “ ΛmG iﬀ k is even. If odd, then Kψ,η “ 0.
In contrast to polynomial functions, Dirac’s δ can be an admissible activation function.
Example 6.9. ηpzq “ Gpkqpzq pk P N0q is admissible with ψ “ ΛmG iﬀ k is even. If odd, then Kψ,η “ 0. Example 6.10. ηpzq “ σpkqpzq pk P N0q is admissible with ψ “ ΛmG iﬀ k is odd. If odd, then Kψ,η “ 0. σp´1q is admissible with ψ “ ΛmG2.

The proof is provided in F.

7 Numerical Examples of Reconstruction
We performed some numerical experiments on reconstructing a one-dimensional signal and a two-dimensional image, with reference to our theoretical diagnoses for admissibility in the previous section. Table 5 lists the diagnoses of pΛmψ0, ηq we employ in this section. The symbols ’`,’ ’0,’ and ’8’ in each cell indicate that Kψ,η of the corresponding pψ, ηq converges to a non-zero constant (`), converges to zero (0), and diverges (8). Hence, by Theorem 5.6, if the cell pψ, ηq indicates ’`’ then a neural network with an activation function η is a universal approximator.

Table 5: Theoretical diagnoses for admissibility of ψ “ Λmψ0 and η. ’`’ indicates that pψ, ηq is admissible. ’0’ and ’8’ indicate that Kψ,η vanishes and diverges, respectively, and thus pψ, ηq is not admissible.

activation function

η

ψ “ ΛmG ψ “ ΛmG1 ψ “ ΛmG2

derivative of sigmoidal ft. σ1

`

0

`

sigmoidal function

σ

8

`

0

softplus

σp´1q

8

8

`

Dirac’s δ

δ

`

0

`

unit step function

z`0

8

`

0

ReLU

z`

8

8

`

linear function

z

0

0

0

RBF

G

`

0

`

7.1 Sinusoidal Curve

We studied a one-dimensional signal f pxq “ sin 2πx deﬁned on x P r´1, 1s. The ridgelet functions functions ψ “ Λψ0 were chosen from derivatives of the Gaussian ψ0 “ Gp q, p “ 0, 1, 2q. The activation functions η were chosen from among the softplus σp´1q, the sigmoidal function σ and its derivative σ1, the ReLU z`, unit step function z`0 , and Dirac’s δ. In addition, we examined the case when the activation function is simply a linear function: ηpzq “ z, which cannot be admissible because the Fourier transform of
polynomials is supported at the origin in the Fourier domain.
The signal was sampled from r´1, 1s with ∆x “ 1{100. We computed the reconstruction formula

żż

dadb

R

Rψf pa, bqηpax ´ bq
R

|a|

,

(87)

15

by simply discretizing pa, bq P r´30, 30s ˆ r´30, 30s by ∆a “ ∆b “ 1{10. That is,

N

ÿ

Rψf pa, bq « f pxnqψpa ¨ xn ´ bq|a|∆x, xn “ x0 ` n∆x

(88)

n“0

Rη: R f

pxq

«

I ,J
ÿ
pi,jq“p0,0q

Rψ f

pai,

bj

qηpai

¨

x

´

bj

q

∆a∆b |ai|

,

ai “ a0 ` i∆a, bj “ b0 ` j∆b

(89)

where x0 “ ´1, a0 “ ´30, b0 “ ´30, and N “ 200, pI, Jq “ p600, 600q.

ψ “ ΛG

ψ “ ΛG1

ψ “ ΛG2

Figure 2: Ridgelet transform Rψf pa, bq of f pxq “ sin 2πx deﬁned on r´1, 1s with respect to ψ.
Figure 2 depicts the ridgelet transform Rψf pa, bq. As the order of ψ “ ΛGp q increases, the localization of Rψf increases. As shown in Figure 3, every Rψf can be reconstructed to f with some admissible activation function η. It is somewhat intriguing that the case ψ “ ΛG2 can be reconstructed with two diﬀerent activation functions.
Figures 3, 4, and 5 tile the results of reconstruction with sigmoidal functions, truncated power functions, and a linear function. The solid line is a plot of the reconstruction result; the dotted line draws the original signal. In each of the ﬁgures, the theoretical diagnoses and experimental results are almost consistent and reasonable.
In Figure 3, at the bottom left, the reconstruction signal with the softplus seems incompletely reconstructed, in spite of Table 5 indicating ’8’. Recall that σz p´1qpζq has a pole ζ´2; thus, we can understand this cell in terms of σp´1q ˚ ΛG working as an integrator, that is, a low-pass ﬁlter.
In Figure 4, in the top row, all the reconstructions with Dirac’s δ fail. These results seem to contradict the theory. However, it simply reﬂects the implementation diﬃculty of realizing Dirac’s δ, because δpzq is a “function” that is almost constantly zero, except for the origin. Nevertheless, z “ ax ´ b rarely happens to be exactly zero, provided a, b, and x are discretized. This is the reason why this row fails. At the bottom left, the ReLU seems to lack sharpness for reconstruction. Here we can again understand that z` ˚ ΛG worked as a low-pass ﬁlter. It is worth noting that the unit step function and the ReLU provide a sharper reconstruction than the sigmoidal function and the softplus.
In Figure 5, all the reconstructions with a linear function fail. This is consistent with the theory that polynomials cannot be admissible as their Fourier transforms are singular at the origin.

16

ψ “ ΛG

ψ “ ΛG1

ψ “ ΛG2

1.0

1.0

1.0

0.5

0.5

0.5

η “ σ1

0.0

y

0.0

y

0.0

y

−0.5

−0.5

−0.5

−1.0

−1.0

−1.0

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

1.0

1.0

1.0

0.5

0.5

0.5

η“σ

0.0

y

0.0

y

0.0

y

−0.5

−0.5

−0.5

−1.0

−1.0

−1.0

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

1.0

1.0

1.0

0.5

0.5

0.5

η “ σp´1q

0.0

y

0.0

y

0.0

y

−0.5

−0.5

−0.5

−1.0

−1.0

−1.0

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

Figure 3: Reconstruction with the derivative of sigmoidal function σ1, sigmoidal function σ, and softplus σp´1q. The solid line is a plot of the reconstruction result; the dotted line plots the original signal.

17

ψ “ ΛG

ψ “ ΛG1

ψ “ ΛG2

1.0

1.0

1.0

0.5

0.5

0.5

η“δ

0.0

y

0.0

y

0.0

y

−0.5

−0.5

−0.5

−1.0

−1.0

−1.0

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

1.0

1.0

1.0

0.5

0.5

0.5

η “ z0`

0.0

y

0.0

y

0.0

y

−0.5

−0.5

−0.5

−1.0

−1.0

−1.0

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

1.0

1.0

1.0

0.5

0.5

0.5

η “ z`

0.0

y

0.0

y

0.0

y

−0.5

−0.5

−0.5

−1.0

−1.0

−1.0

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

Figure 4: Reconstruction with truncated power functions — Dirac’s δ, unit step z`0 , and ReLU z`. The solid line is a plot of the reconstruction result; the dotted line plots the original signal.

ψ “ ΛG

ψ “ ΛG1

ψ “ ΛG2

1.0

1.0

1.0

0.5

0.5

0.5

ηpzq “ z

0.0

y

0.0

y

0.0

y

−0.5

−0.5

−0.5

−1.0

−1.0

−1.0

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

−1.0

−0.5

0.0

0.5

1.0

x

Figure 5: Reconstruction with linear function ηpzq “ z. The solid line is a plot the reconstruction result; the dotted line plots the original signal.

18

7.2 Shepp-Logan phantom
We next studied a gray-scale image Shepp-Logan phantom [42]. The ridgelet functions ψ “ Λ2ψ0 were chosen from the th derivatives of the Gaussian ψ0 “ Gp q, p “ 0, 1, 2q. The activation functions η were chosen from the RBF G (instead of Dirac’s δ), the unit step function z`0 , and the ReLU z`.
The original image was composed of 256 ˆ 256 pixels. We treated it as a two-dimensional signal f pxq deﬁned on r´1, 1s2. We computed the reconstruction formula

żż

dadb

R

Rψf pa, bqηpa ¨ x ´ bq
R2

}a}

,

(90)

by discretizing pa, bq P r´300, 300s2 ˆ r´30, 30s by ∆a “ p1, 1q and ∆b “ 1. Figure 6 lists the results of the reconstruction. As observed in the one-dimensional case, the results
are fairly consistent with the theory. Again, at the bottom left, the reconstructed image seems dim. Our understanding is that it was caused by low-pass ﬁltering.

ψ “ Λ2G

ψ “ Λ2G1

ψ “ Λ2G2

η“G

η “ z0`

η “ z`

Figure 6: Reconstruction with RBF G, unit step z`0 , and ReLU z`. 19

8 Concluding Remarks

We have shown that neural networks with unbounded non-polynomial activation functions have the uni-
versal approximation property. Because the integral representation of the neural network coincides with
the dual ridgelet transform, our goal reduces to constructing the ridgelet transform with respect to distri-
butions. Our results cover a wide range of activation functions: not only the traditional RBF, sigmoidal function, and unit step function, but also truncated power functions z`k , which contain the ReLU and even Dirac’s δ. In particular, we concluded that a neural network can approximate L1 X C0 functions in the pointwise sense, and L2 functions in the L2 sense, when its activation “function” is a Lizorkin distribution (S01 ) that is admissible. The Lizorkin distribution is a tempered distribution (S1) that is not a polynomial. As an important consequence, what a neural network learns is a ridgelet transform of the target function f .
In other words, during backpropagation the network indirectly searches for an admissible ridgelet function,
by constructing a backprojection ﬁlter.
Using the weak form expression of the ridgelet transform, we extensively deﬁned the ridgelet transform
with respect to distributions. Theorem 4.2 guarantees the existence of the ridgelet transform with respect
to distributions. Table 4 suggests that for the convolution of distributions to converge, the class X of domain and the class Z of ridgelets should be balanced. Proposition 4.3 states that Rψ : L1pRmq Ñ S1pYm`1q is a bounded linear operator. Theorem 4.5 states that the dual ridgelet transform coincides with a dual operator. Provided the reconstruction formula holds, that is, when the ridgelets are admissible, the
ridgelet transform is injective and the dual ridgelet transform is surjective.
For an unbounded η P ZpRq to be admissible, it cannot be a polynomial and it can be associated with a backprojection ﬁlter. If η P ZpRq is a polynomial then the product of distributions in the admissibility condition should be indeterminate. Therefore, ZpRq excludes polynomials. Theorem 5.4 rephrases the admissibility condition in the real domain. As a direct consequence, Corollary 5.5 gives a constructive
suﬃciently admissible condition.
After investigating the construction of the admissibility condition, we showed that formulas can be reconstructed on L1pRmq in two ways. Theorem 5.6 uses the Fourier slice theorem. Theorem 5.7 uses approximations to the identity and reduces to the inversion formula of the Radon transform. Theorem 5.7
as well as Corollary 5.8 suggest that the admissibility condition requires pψ, ηq to construct a backprojection ﬁlter.
In addition, we have extended the ridgelet transform on L1pRmq to L2pRmq. Theorem 5.9 states that Parseval’s relation, which is a weak version of the reconstruction formula, holds on L1 X L2pRmq. Theorem 5.10 follows the bounded extension of Rψ from L1 X L2pRmq to L2pRmq. Theorem 5.11 gives the reconstruction formula in L2pRmq.
By showing that z`k and other activation functions belong to S01 , and that they are admissible with some derivatives of the Gaussian, we proved the universal approximation property of a neural network with an
unbounded activation function. Numerical examples were consistent with our theoretical diagnoses on the
admissibility. In addition, we found that some non-admissible combinations worked as a low-pass ﬁlter; for example, pψ, ηq “ pΛmrGaussians, ReLUq and pψ, ηq “ pΛmrGaussians, softplus).
We plan to perform the following interesting investigations in future.

1. Given an activation function η P S01 pRq, which is the “best” ridgelet function ψ P SpRq?

In fact, for a given activation function η, we have plenty of choices. By Corollary 5.5, all

elements of

!ˇ

)

Aη :“

Λmψ0

ˇ ˇ

ψ0

P

S pRq

such

that

xηp, ψx0y

is

ﬁnite

and

nonzero.

,

(91)

are admissible with η.

2. How are ridgelet functions related to deep neural networks?

Because ridgelet analysis is so fruitful, we aim to develop “deep” ridgelet analysis. One of the essential leaps from shallow to deep is that the network output expands from scalar to vector because a deep structure is a cascade of multi-input multi-output layers. In this regard, we expect Corollary 5.8 to play a key role. By using the intertwining relations, we can “cascade” the reconstruction operators as below

Rη: Rψ Rη: Rψ

“

R˚Λk´1Rp´∆qm´1´

k` 2

R˚Λ

´1R.

p0 ď k,

ď mq

(92)

This equation suggests that the cascade of ridgelet transforms coincides with a composite of backprojection ﬁltering in the Radon domain and diﬀerentiation in the real domain. We conjecture that this point of view can be expected to facilitate analysis of the deep structure.

20

Acknowledge
The authors would like to thank the anonymous reviewers for fruitful comments and suggestions to improve the quality of the paper. The authors would like to express their appreciation toward Dr. Hideitsu Hino for his kind support with writing the paper. This work was supported by JSPS KAKENHI Grand Number 15J07517.
References
[1] N. Murata, An Integral representation of functions using three-layered betworks and their approximation bounds, Neural Networks 9 (6) (1996) 947–956. doi:10.1016/0893-6080(96)00000-7. URL http://www.sciencedirect.com/science/article/pii/0893608096000007
[2] S. Sonoda, N. Murata, Sampling hidden parameters from oracle distribution, in: 24th Int. Conf. Artif. Neural Networks, Vol. 8681, Springer International Publishing, Hamburg, Germany, 2014, pp. 539–546. doi:10.1007/978-3-319-11179-7{\_}68.
[3] X. Glorot, A. Bordes, Y. Bengio, Deep sparse rectiﬁer neural networks, in: 14th Int. Conf. Artif. Intell. Stat. (AISTATS 2011), Vol. 15, JMLR W&CP, Fort Lauderdale, FL, USA, 2011, pp. 315–323. URL http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf
[4] I. Goodfellow, D. Warde-Farley, M. Mirza, A. Courville, Y. Bengio, Maxout networks, in: 30th Int. Conf. Mach. Learn., Vol. 28, JMLR W&CP, 2013, pp. 1319–1327. URL http://jmlr.csail.mit.edu/proceedings/papers/v28/goodfellow13.pdf
[5] G. E. Dahl, T. N. Sainath, G. E. Hinton, Improving deep neural networks for LVCSR using rectiﬁed linear units and dropout, in: Acoust. Speech Signal Process. (ICASSP), 2013 IEEE Int. Conf., IEEE, 2013, pp. 8609–8613. doi:10.1109/ICASSP.2013.6639346.
[6] A. L. Maas, A. Y. Hannun, A. Y. Ng, Rectiﬁer nonlinearities improve neural network acoustic models, in: ICML 2013 Work. Deep Learn. Audio, Speech, Lang. Process., Atlanta, 2013. URL https://sites.google.com/site/deeplearningicml2013/relu_hybrid_icml2013_final. pdf
[7] K. Jarrett, K. Kavukcuoglu, M. Ranzato, Y. LeCun, What is the best multi-stage architecture for object recognition?, in: Comput. Vision, 2009 IEEE 12th Int. Conf., Kyoto, 2009, pp. 2146–2153. doi:10.1109/ICCV.2009.5459469.
[8] A. Krizhevsky, I. Sutskever, G. E. Hinton, ImageNet classiﬁcation with deep convolutional neural networks, in: F. Pereira, C. J. C. Burges, L. Bottou, K. Q. Weinberger (Eds.), Adv. Neural Inf. Process. Syst. 25, Curran Associates, Inc., 2012, pp. 1097–1105. URL http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-netw pdf
[9] M. D. Zeiler, M. Ranzato, R. Monga, M. Z. Mao, K. Yang, Q. Viet Le, P. Nguyen, A. W. Senior, V. Vanhoucke, J. Dean, G. E. Hinton, On rectiﬁed linear units for speech processing, in: Acoust. Speech Signal Process. (ICASSP), 2013 IEEE Int. Conf., IEEE, Vancouver, BC, 2013, pp. 3517–3521. doi:10.1109/ICASSP.2013.6638312.
[10] H. Mhaskar, C. A. Micchelli, Approximation by superposition of sigmoidal and radial basis functions, Adv. Appl. Math. 13 (3) (1992) 350–373. doi:10.1016/0196-8858(92)90016-P. URL http://www.sciencedirect.com/science/article/pii/019688589290016P
[11] M. Leshno, V. Y. Lin, A. Pinkus, S. Schocken, Multilayer feedforward networks with a nonpolynomial activation function can approximate any function, Neural Networks 6 (6) (1993) 861–867. doi: 10.1016/S0893-6080(05)80131-5. URL http://www.sciencedirect.com/science/article/pii/S0893608005801315
[12] A. Pinkus, Approximation theory of the MLP model in neural networks, Acta Numer. 8 (1999) 143– 195. doi:10.1017/S0962492900002919.
21

[13] Y. Ito, Representation of functions by superpositions of a step or sigmoid function and their applications to neural network theory, Neural Networks 4 (3) (1991) 385–394. doi:10.1016/0893-6080(91) 90075-G. URL http://www.sciencedirect.com/science/article/pii/089360809190075G
[14] P. C. Kainen, V. K˚urkov´a, A. Vogt, A Sobolev-type upper bound for rates of approximation by linear combinations of Heaviside plane waves, J. Approx. Theory 147 (1) (2007) 1–10. doi:10.1016/j.jat. 2006.12.009. URL http://linkinghub.elsevier.com/retrieve/pii/S0021904507000081
[15] V. K˚urkov´a, Complexity estimates based on integral transforms induced by computational units, Neural Netw. 33 (2012) 160–7. doi:10.1016/j.neunet.2012.05.002. URL http://www.sciencedirect.com/science/article/pii/S0893608012001311
[16] S. M. Carroll, B. W. Dickinson, Construction of neural nets using the Radon transform, in: Int. Jt. Conf. Neural Networks, 1989. IJCNN., Vol. 1, IEEE, 1989, pp. 607–611. doi:10.1109/IJCNN.1989. 118639.
[17] S. Helgason, Integral Geometry and Radon Transforms, Springer-Verlag New York, 2011. doi:10. 1007/978-1-4419-6055-9.
[18] B. Irie, S. Miyake, Capabilities of three-layered perceptrons, in: IEEE Int. Conf. Neural Networks, IEEE, 1988, pp. 641–648. doi:10.1109/ICNN.1988.23901.
[19] K.-I. Funahashi, On the approximate realization of continuous mappings by neural networks, Neural Networks 2 (3) (1989) 183–192. doi:10.1016/0893-6080(89)90003-8. URL http://www.sciencedirect.com/science/article/pii/0893608089900038
[20] L. K. Jones, A simple lemma on greedy approximation in Hilbert space and convergence rates for projection pursuit regression and neural network training, Ann. Stat. 20 (1) (1992) 608–613. doi: 10.1214/aos/1176348546.
[21] A. R. Barron, Universal approximation bounds for superpositions of a sigmoidal function, IEEE Trans. Inf. Theory 39 (3) (1993) 930–945. doi:10.1109/18.256500.
[22] P. C. Kainen, V. K˚urkov´a, M. Sanguineti, Approximating multivariable functions by feedforward neural nets, in: M. Bianchini, M. Maggini, L. C. Jain (Eds.), Handb. Neural Inf. Process., Vol. 49 of Intelligent Systems Reference Library, Springer Berlin Heidelberg, 2013, pp. 143–181. doi:10.1007/ 978-3-642-36657-4.
[23] E. J. Cand`es, Harmonic analysis of neural networks, Appl. Comput. Harmon. Anal. 6 (2) (1999) 197–218. doi:10.1006/acha.1998.0248. URL http://www.sciencedirect.com/science/article/pii/S1063520398902482
[24] E. J. Cand`es, Ridgelets: theory and applications, Ph.D. thesis, Standford University (1998).
[25] B. Rubin, The Calder´on reproducing formula, windowed X-ray transforms, and radon transforms in Lp-spaces, J. Fourier Anal. Appl. 4 (2) (1998) 175–197. doi:10.1007/BF02475988. URL http://dx.doi.org/10.1007/BF02475988
[26] D. L. Donoho, Tight frames of k-plane ridgelets and the problem of representing objects that are smooth away from d-dimensional singularities in Rn, Proc. Natl. Acad. Sci. United States Am. 96 (5) (1999) 1828–1833. doi:10.1073/pnas.96.5.1828.
[27] D. L. Donoho, Ridge functions and orthonormal ridgelets, J. Approx. Theory 111 (2) (2001) 143–179. doi:10.1006/jath.2001.3568. URL http://www.sciencedirect.com/science/article/pii/S0021904501935683
[28] J.-L. Starck, F. Murtagh, J. M. Fadili, The ridgelet and curvelet transforms, in: Sparse Image Signal Process. Wavelets, Curvelets, Morphol. Divers., Cambridge University Press, 2010, pp. 89–118. doi: 10.1017/CBO9780511730344.006. URL http://www.cambridge.org/9780521119139
22

[29] B. Rubin, Convolutionbackprojection method for the k-plane transform, and Calder´on’s identity for ridgelet transforms, Appl. Comput. Harmon. Anal. 16 (3) (2004) 231–242. doi:10.1016/j.acha. 2004.03.003. URL http://www.sciencedirect.com/science/article/pii/S1063520304000168
[30] S. Kostadinova, S. Pilipovi´c, K. Saneva, J. Vindas, The ridgelet transform of distributions, Integr. Transform. Spec. Funct. 25 (5) (2014) 344–358. doi:10.1080/10652469.2013.853057.
[31] S. Kostadinova, S. Pilipovi´c, K. Saneva, J. Vindas, The Ridgelet Transform and Quasiasymptotic Behavior of Distributions, Oper. Theory Adv. Appl. 245 (2015) 185–197. doi:10.1007/ 978-3-319-14618-8{\_}13.
[32] L. Schwartz, Th´eorie des Distributions, nouvelle Edition, Hermann, Paris, 1966.
[33] F. Tr`eves, Tological Vector Spaces, Distributions and Kernels, Academic Press, 1967.
[34] W. Rudin, Functional Analysis, 2nd Edition, Higher Mathematics Series, McGraw-Hill Education, 1991.
[35] H. Brezis, Functional Analysis, Sobolev Spaces and Partial Diﬀerential Equations, 1st Edition, Universitext, Springer-Verlag New York, 2011. doi:10.1007/978-0-387-70914-7.
[36] K. Yosida, Functional Analysis, 6th Edition, Springer-Verlag Berlin Heidelberg, 1995. doi:10.1007/ 978-3-642-61859-8.
[37] W. Yuan, W. Sickel, D. Yang, Morrey and Campanato Meet Besov, Lizorkin and Triebel, Lecture Notes in Mathematics, Springer Berlin Heidelberg, 2010. doi:10.1007/978-3-642-14606-0.
[38] M. Holschneider, Wavelets: An Analysis Tool, Oxford mathematical monographs, The Clarendon Press, 1995.
[39] A. Hertle, Continuity of the radon transform and its inverse on Euclidean space, Math. Zeitschrift 184 (2) (1983) 165–192. doi:10.1007/BF01252856. URL http://dx.doi.org/10.1007/BF01252856
[40] L. Grafakos, Classical Fourier Analysis, 2nd Edition, Graduate Texts in Mathematics, Springer New York, 2008. doi:10.1007/978-0-387-09432-8.
[41] I. M. Gel’fand, G. E. Shilov, Generalized Functions, Vol. 1: Properties and Operations, Academic Press, New York, 1964.
[42] L. A. Shepp, B. F. Logan, The Fourier reconstruction of a head section, Nucl. Sci. IEEE Trans. 21 (3) (1974) 21–43. doi:10.1109/TNS.1974.6499235.
[43] E. M. Stein, Singular Integrals and Diﬀerentiability Properties of Functions, Princeton Mathematical Series (PMS), Princeton University Press, 1970.

A Proof of Theorem 4.2

A ridgelet transform Rψf pu, α, βq is the convolution of a Radon transform Rf pu, pq and a dilated distribution ψαppq in the sense of a Schwartz distribution. That is,

´

¯

f pxq ÞÑ Rf pu, pq ÞÑ Rf pu, ¨q ˚ ψĂα pβq “ Rψf pu, α, βq.

(93)

We verify that the ridgelet transform is well deﬁned in a stepwise manner. Provided there is no danger of confusion, in the following steps we denote by X the classes D, E1, S, OC1 , L1, or DL1 1 .

Step 1: Class X pSm´1 ˆ Rq of Rf pu, pq Hertle’s results found [39, Th 4.6, Cor 4.8] that the Radon transform is the continuous injection

R : X pRmq ãÑ X pSm´1 ˆ Rq,

(94)

where X “ D, E1, S, OC1 , L1, or DL1 1 ; if f P X pRmq then Rf P X pSm´1 ˆ Rq, which determines the second column. Our possible choice of the domain X is restricted to them.

23

Step 2: Class BpRq of Rψf pu, α, βq with respect to β

´

¯

Fix α ą 0. Recall that Rψf pu, α, βq “ Rf pu, ¨q ˚ ψĂα pβq in the sense of Schwartz distributions. By the

nuclearity of X [33, § 51], the kernel theorem

X pSm´1 ˆ Rq – X pSm´1qbp X pRq,

(95)

holds. Therefore, we can omit u P Sm´1 in the considerations for pα, βq P H. According to Schwartz’s
results shown in Table 3, for the convolution g ˚ ψ of g P X pRq and ψ P ZpRq to converge in BpRq, we can assign the largest possible class Z for each X as in the third column. Note that for X “ L1 we even assumed the continuity Z “ Lp X C0, which is technically required in Step 3. Obviously for Z “ D1, S1, Lp X C0, or DL1 p , if ψ P ZpRq then ψα P ZpRq. Therefore, we can determine the fourth column by evaluating X ˚ Z according to Table 3.

Step 3: Class ApHq of Rψf pu, α, βq with respect to pα, βq Fix u0 P Sm´1 and assume f P X pRmq. Write gppq :“ Rf pu0, pq and

ż

Wrψ; gspα, βq :“ gpαz ` βqψpzqdz,

(96)

R

then Rψf pu0, α, βq “ Wrψ; gspα, βq for every pα, βq P H. By the kernel theorem, g P X pRq.

Case 3a: pX “ D and Z “ D1 then B “ E and A “ Eq We begin by considering the case in the ﬁrst row. Observe that

ż

ż

BαWrψ; gspα, βq “ Bα gpαz ` βqψpzqdz “ g1pαz ` βqz ¨ ψpzqdz “ Wrz ¨ ψ; g1spα, βq, (97)

R

R

ż

ż

BβWrψ; gspα, βq “ Bβ gpαz ` βqψpzqdz “ g1pαz ` βqψpzqdz “ Wrψ; g1spα, βq,

(98)

R

R

and thus that for every k, P N0,

Bαk BβWrψ; gspα, βq “ Wrzk ¨ ψ; gpk` qspα, βq.

(99)

Obviously if g P DpRq and ψ P D1pRq then gpk` q P DpRq and zk ¨ ψ P D1pRq, respectively, and thus Bαk BβWrψ; gspα, βq exists at every pα, βq P H. Therefore, we can conclude that if g P DpRq and ψ P D1pRq then Wrψ; gs P EpHq.

Case 3b: pX “ E1 and Z “ D1 then B “ D1 and A “ D1q Let g P E1pRq and ψ P D1pRq. We show that Wrψ; gs P D1pHq, that is, for every compact set K Ă H, there
exists N P N0 such that

ˇ

ˇ

ˇ ˇ ˇ ˇ

ż
K

Tpα,

β qW rψ;

gspα,

βq

dαdβ α

ˇ ˇ ˇ ˇ

À

ÿ
k, ďN

sup
pα,βqPH

|Bαk BβTpα,

βq|,

@T P DpKq.

(100)

Fix an arbitrary compact set K Ă H and a smooth function T P DpKq, which is supported in K. Take two compact sets A Ă R` and B Ă R such that K Ă A ˆ B. By the assumption that g P E1pRq and ψ P D1pRq, there exist k, P N0 such that

ˇ

ˇ

ˇż

ˇ

ˇ ˇ

upzqgpzqdzˇ À ˇ

sup |upkqpzq|,

@u P EpRq

ˇR

ˇ zPsupp g

ˇ

ˇ

ˇż

ˇ

ˇ vpzqψpzqdzˇ À sup |vp qpzq|, @v P DpBq.

ˇ

ˇ

ˇR

ˇ zPR

(101) (102)

24

Observe that for every ﬁxed α, Tpα, ¨q ˚ gr P D1pRq. Then, by applying (101) and (102) incrementally,

ˇ

ˇ

ˇ

ˇ

ˇż

ż

dαdβ ˇ ż 8 ˇ ż ż

ˇ dα

ˇ ˇ

Tpα, βq

gpαz ` βqψpzqdz

ˇR

R

α

ˇ ˇ

ď

ˇ

0

ˇ ˇ ˇ

R

Tpα, β
R

´

αzqψpzqdz

¨ gpβqdβˇˇ ˇ

α

ˇ

ˇ

À

ż8
0

sup
βPsupp

g

ˇ ˇ ˇ ˇ

ż
R

Bβk Tpα,

β

´

ˇ αzqψpzqdzˇˇ
ˇ

dα α

ż8

ˇ

ˇ

À

sup

sup ˇˇBβk`

Tpα, β

´

αzqˇα ˇ

´1dα

0 βPsupp g z

żˇ

ˇ

“ sup ˇˇBβk` Tpα, βqˇˇα ´1dα

A βPB

ˇ

ˇż

ď sup ˇˇBβk` Tpα, βqˇˇ ¨ α ´1dα,

pα,βqPK

A

(103) (104) (105) (106) (107)

where the third inequality follows by repeatedly applying BzrTpα, β ´ αzqs “ p´αqBβTpα, β ´ αzq; the fourth inequality follows by the compactness of the support of T. Thus, we conclude that Wrψ; gs P D1pHq.

Case 3c: pX “ S and Z “ S1 then B “ OM and A “ OMq Let g P SpRq and ψ P S1pRq. Recall the case when X “ D. Obviously, for every k, P N0, gpk` q P SpRq and zk ¨ ψ P S1pRq, respectively, which implies Wrψ; gs P EpHq. Now we even show that Wrψ; gs P OMpHq,
that is, for every k, P N0 there exist s, t P N0 such that

ˇˇBαk BβWrψ; gspα, βqˇˇ À pα ` 1{αqsp1 ` β2qt{2.

(108)

Recall that by (99), we can regard Bαk BβWrψ; gspα, βq as Bα0 Bβ0 Wrψ0; g0spα, βq, by setting g0 :“ gpk` q P SpRq and ψ0 :“ zk ¨ ψ P S1pRq. Henceforth we focus on the case when k “ “ 0. Since ψ P S1pRq, there
exists N P N0 such that

ˇ

ˇ

ˇż ˇ

ˇ upzqψpzqdzˇ À

ÿ

sup |zsuptqpzq|,

ˇ

ˇ

@u P SpRq.

ˇR

ˇ s,tďN zPR

(109)

By substituting upzq Ð gpαz ` βq, we have

ˇ

ˇ

ˇż ˇ ˇ

ˇ gpαz ` βqψpzqdzˇˇ À

ÿ

sup |zsBzt gpαz ` βq|

ˇR

ˇ s,tďN zPR

“

ÿ
s,tďN

sup
pPR

ˇ ˇ ˇ ˇ ˇ

ˆ

p

´ α

β

˙s

ˇ
ˇ αtgptqppqˇ
ˇ
ˇ

À ÿ αt´sβs sup |psgptqppq|

s,tďN

pPR

À pα ` 1{αqN p1 ` β2qN{2,

(110) (111) (112) (113)

where the second equation follows by substituting p Ð αz ` β; the fourth inequality follows because every
supp |psgtppq| is ﬁnite by assumption that g P SpRq. Therefore, we can conclude that if g P SpRq and ψ P S1pRq then Wrψ; gs P OMpHq.

Case 3d: pX “ OC1 and Z “ S1 then B “ S1 and A “ S1q Let g P OC1 pRq and ψ P S1pRq. We show that Wrψ; gs P S1pHq, that is, there exists N P N0 depending only on ψ and g such that

ˇ

ˇ

ˇ ˇ ˇ ˇ

ż
H

Tpα,

βqW

rψ;

gspα,

βq

dαdβ α

ˇ ˇ ˇ ˇ

À

ÿ
s,t,k, ďN

sup
α,βPH

ˇˇDks,,t

Tpα,

βqˇˇ,

@T P SpHq

(114)

where we deﬁned

Dks,,t Tpα, βq :“ pα ` 1{αqs p1 ` β2qt{2Bαk BβTpα, βq.

(115)

25

Fix an arbitrary T P SpHq. By the assumption that ψ P S1pRq, there exist s, t P N0 such that

ˇ

ˇ

ˇż

ˇ

ˇ ˇ

upzqψpzqdzˇˇ À sup |ztupsqpzq|, @u P SpRq.

ˇR

ˇz

(116)

Observe

that

for

every

ﬁxed

α,

Tpα,

¨q

˚

g r

P

S pRq.

Then

we

can

provide

an

estimate

as

below.

ˇ

ˇ

ˇ

ˇ

ˇż

ż

dαdβ ˇ ż 8 ˇ ż ż

ˇ dα

ˇ Tpα, βq gpαz ` βqψpzqdz ˇ

ˇH

R

α

ˇď ˇ ˇ

0

ˇ ˇ ˇ

R

R

Tpα, βqgpαz

`

βqdβ

¨

ψpzqdzˇ ˇ ˇ

α

(117)

ˇ

ˇ

À

ż
R

sup
z

ˇ ˇzt ˇ
ˇ

ż
R

D0s,,00Tpα,

βqgpsqpαz

`

ˇ βqdβˇ
ˇ ˇ

dα α

(118)

ˇ

ˇ

À

ż
R

sup
p

ˇ ˇpt ˇ
ˇ

ż
R

D0s`,0t,0Tpα,

βqgpsqpp

`

ˇ βqdβˇ
ˇ ˇ

dα α

(119)

ď

ż
R

ż
R

sup
p

ˇˇptgpsqpp

`

βqˇˇˇˇD0s`,0t,0Tpα,

βqˇˇ

dβdα α

(120)

À

ż
R

ż
R

sup
p

ˇˇp1

`

|p

`

β|2qt{2gpsqpp

`

βqˇˇˇˇD0s`,0t,tTpα,

βqˇˇ

dβdα α

(121)

À

ż
H

ˇˇD0s`,0t,tTpα,

βqˇˇ

dβdα α

(122)

ď

sup
pα,βqPH

ˇˇD0s`,0t`ε,t`δ Tpα,

βqˇˇ

ż
H

pα

`

1{αq´ε

p1

`

β2q´δ{2

dβdα ,
α

(123)

where the second inequality follows by repeatedly applying Bzrgpαz ` βqs “ α ¨ g1pαz ` βq and α À α ` 1{α; the third inequality follows by changing the variable p Ð αz and applying pα ` 1{αqs ¨ α´t À pα ` 1{αqs`t; the ﬁfth inequality follows by applying |p| À p1`p2q1{2 and Peetre’s inequality 1`p2 À p1`β2qp1`|p`β|2q; the sixth inequality follows by the assumption that p1 ` p2qt{2gppq is bounded for any t; the last inequality
follows by H¨older’s inequality and the integral is convergent when ε ą 0 and δ ą 1.

Case 3e: pX “ L1 and Z “ Lp X C0 then B “ Lp X C0 and A “ S1q Let g P L1pRq and ψ P Lp X C0pRq. We show that Wrg; ψs P S1pHq, that is, it has at most polynomial
growth at inﬁnity. Because ψ is continuous, g ˚ ψ is continuous. By Lusin’s theorem, there exists a continuous function g‹ such that g‹pxq “ gpxq for almost every x P R; thus, by the continuity of g ˚ ψ,

g‹ ˚ ψpxq “ g ˚ ψpxq, for every x P R.

(124)

By the continuity and the integrability of g‹ and ψ, there exist s, t P R such that |g‹pxq| À p1 ` x2q´s{2, s ą 1, |ψpxq| À p1 ` x2q´t{2, tp ą 1

(125) (126)

Therefore,

ˇ ˇ ˇ ˇ ˇ

ż
R

gpxqψ

ˆ

x

´ α

β

˙

1 α

ˇ ˇ dxˇ ˇ ˇ

À

ˇ ˇ ˇ ˇ ˇ

ż p1
R

`

x2q´s{2

˜ 1

`

ˆ

x

´ α

β

˙2¸´t{2

ˇ
ˇ dxˇα´1
ˇ
ˇ

ˇ

ˇ

ˇż Àˇ

p1

`

x2q´s{2

´ 1

`

px

´

β

q2

¯´t{2

ˇ dxˇp1

`

α2qt{2

α´1

ˇ

ˇ

ˇR

ˇ

À p1 ` β2q´ minps,tq{2pα ` 1{αqt´1,

(127) (128) (129)

which means Wrψ; gs is a locally integrable function that grows at most polynomially at inﬁnity. Note that if pt ´ 1qp ă m ´ 1 then Wrψ; gs P LppH; α´mdαdβq, because |Wrψ; gspα, βq|p behaves as
β´ minps,tqαpt´1qp at inﬁnity.

Case 3f: pX “ DL1 1 and Z “ DL1 p then B “ DL1 p and A “ S1q Let g P DL1 1 pRq and ψ P DL1 p . We estimate (114). Fix an arbitrary T P SpHq. By the assumption that

26

ψ P DL1 p pRq, for every ﬁxed α, Tpα, ¨q ˚ ψ P E X LppRq. Therefore, we can take ψ‹ P E X LppRq such that ψ‹ “ ψ a.e. and Tpα, ¨q ˚ ψ‹ “ Tpα, ¨q ˚ ψ. In the same way, we can take g‹ P E X L1pRq such that g‹ “ g almost everywhere and Tpα, ¨q ˚ g‹ “ Tpα, ¨q ˚ g. Therefore, this case reduces to show that if X “ L1 and Z “ Lp then A “ S1. This coincides with case 3e.
Step 4: Class YpYm`1q of Rψf pu, α, βq The last column pYq is obtained by applying YpYm`1q “ X pSm´1qbp ApHq. Recall that for Sm´1, as it is compact, D “ S “ OM “ E and E1 “ OC1 “ S1 “ DL1 p “ D1. Therefore, we have Y as in the last column of Table 4.

B Proof of Theorem 5.4

Let

pψ, ηq

P

SpRq ˆ S1pRq.

Assume

that

η p

is

singular

at

0.

That

is,

there

exists

k

P

N0

such

that

k
ηppζq “ ÿ cjδpjqpζq, ζ P t0u.
j“0

(130)

Assume

there

exists

a

neighborhood

Ω

of

0

such

that

η p

P

C 0 pΩzt0uq.

Note that the continuity implies

local integrability. We show that ψ and η are admissible if and only if there exists u P OMpRq such that

˜k

¸

ż

Λmu “ ψr ˚ η ´ ÿ cjzj , and

uppζqdζ ‰ 0.

j“0

Rzt0u

(131)

Recall that the Fourier transform OMpRq Ñ OC1 pRq is bijective. Thus, the action of up on the indicator function 1Rzt0upζq is always ﬁnite.

Suﬃciency:

On

Ωzt0u,

η p

coincides

with

a

function.

Thus

the

product

ψppζ qηppζ q|ζ |´m

is

deﬁned

in

the

sense

of

ordinary

functions, and coincides with uppζq. On RzΩ, |ζ|´m is in OMpRzΩq. Thus, the product ψppζqηppζq|ζ|´m is deﬁned in the sense of distributions, which is associative because it contains at most one tempered distribution (S ¨ S1 ¨ OM), and reduces to uppζq. Therefore,

˜

¸

Kψ,η p2πqm´1

“

ż

ż

`

Ωzt0u RzΩ

uppζ qdζ ,

(132)

which is ﬁnite by assumption.

Necessity:

Write

Ω0

:“ Ω X r´1, 1s and

Ω1

:“ RzΩ0.

By

the

assumption

that

ş
Ω0

zt0u

ψppζ

qηppζ

q|ζ

|´m

dζ

is

absolutely

convergent

and

η p

is

continuous

in

Ω0zt0u,

there

exists

ε

ą

0

such

that

ˇ

ˇ

ˇˇψppζqηppζqˇˇ À |ζ|m´1`ε, ζ P Ω0zt0u.

(133)

Therefore, there exists v0 P L1pRq X C0pRzt0uq such that its restriction to Ω0zt0u coincides with

ψppζqηppζq “ |ζ|mv0pζq, ζ P Ω0zt0u.

(134)

By integrability and continuity, v0 P L8pRq. In particular, both limζÑ`0 v0pζq and limζÑ´0 v0pζq are ﬁnite.
However, in Ω1, |ζ|´m P OMpΩ1q. By the construction, ψp ¨ ηp P OC1 pRq. Thus, there exists v1 P OC1 pRq such that

ψppζqηppζq “ |ζ|mv1pζq, ζ P Ω1.

(135)

where the equality is in the sense of distribution. Let

v :“ v0 ¨ 1Ω0 ` v1 ¨ 1Ω1 .

(136)

27

Clearly, v P OC1 pRq because v0 ¨ 1Ω0 P E1pRq and v1 ¨ 1Ω1 P OC1 pRq. Therefore, there exists u P OMpRq such that up “ v and

ψppζqηppζq “ |ζ|muppζq, ζ P Rzt0u.

(137)

By the admissibility condition,

ż

ż

ż

uppζqdζ “

v0pζqdζ ` v1pζqdζ ‰ 0.

Rzt0u

Ω0 zt0u

Ω1

In consideration of the singularity at 0, we have

(138)

˜

k

¸

ψppζq ηppζq ´ ÿ cjδpjqpζq “ |ζ|muppζq, ζ P R.

j“0

(139)

By taking the Fourier inversion in the sense of distributions,

« ˜ k ¸ﬀ ψr ˚ η ´ ÿ cjzj pzq “ Λmupzq, z P R.
j“0

(140)

C Proof of Theorem 5.6

Let f P L1pRmq satisfy fp P L1pRmq and pψ, ηq P SpRq ˆ S01 pRq be admissible. For simplicity, we rescale ψ to satisfy Kψ,η “ 1. Write

We show that

ż żδż

dzdαdu

Ipx; ε, δq :“

Rψf pu, α, u ¨ x ´ αzq ηpzq

Sm´1 ε R

αm

.

(141)

lim Ipx; ε, δq “ f pxq, a.e. x P Rm.
δÑ8 εÑ0

(142)

and the equality holds at every continuous point of f . By using the Fourier slice theorem in the sense of distribution,

ż
R

Rψ f

pu, α, β

´

αzq ηpzqdz

“

1 2π

ż
R

fppωuqψppαωqηppαωqeiωβ dω

“

1 2π

ż
Rzt0u

fppωuquppαωq|αω|m eiωβ dω,

(143) (144)

where |ζ|muppζq :“ ψppζqηppζq pζ ‰ 0q is deﬁned as in Theorem 5.4. Then,

żδ

dα

ε (144) αm

“

1 2π

ż żδ fppωuquppαωq|ω|m eiωβ dαdω
Rzt0u ε

“

1 2π

ż
R

ż

εď

ζ ω

ďδ

uppζ qfppωuqeiωβ |ω|m´1 dζ dω

“

1 2π

ż8ż
0 rεď|ζ|ďrδ

uppζqfppsgnpζqruq exppsgnpζqirβqrm´1dζdr,

(145) (146) (147)

where the second equation follows by changing the variable ζ Ð αω with αm´1dα “ |ω|m´1|ζ|´mdζ; the

third equation follows by changing the variable r Ð |ω| with sgn ω “ sgn ζ. In the following, we substitute

β

Ð

u ¨ x.

Observe

that

in

ş
Sm´1

du,

ż

ż

fpp´ruq expp´iru ¨ xqdu “

fppruq exppiru ¨ xqdu;

Sm´1

Sm´1

(148)

hence, we can omit sgn ζ.

28

Then, by substituting β Ð u ¨ x and changing the variable ξ Ð ru,

ż

Ipx; ε, δq “

(147) du

Sm´1

«

ﬀ

1 ż ż8 “ 2π Sm´1 0

ż
uppζ qdζ
rεď|ζ|ďrδ

fppruqeiru¨xrm´1drdu,

«

ﬀ

1ż “ 2π Rm

ż
uppζ qdζ
}ξ}εď|ζ|ď}ξ}δ

fppξqeiξ¨x dζ dξ.

(149) (150) (151)

Recall

that

u p

P

OC1 pRq;

thus,

its

action

is

continuous.

That

is,

the

limits

and

the

integral

commute.

Therefore,

Rη: Rψ f

pxq

“

lim
δÑ8

I

px;

ε,

δq

εÑ0

«

ﬀ

1ż “ p2πq Rm

ż
uppζ qdζ
Rzt0u

fppξqeiξ¨xdξ

“

1 p2πqm

ż
Rm

fppξqeiξ¨xdξ

“ f pxq, a.e. x P Rm

(152)
(153) (154) (155)

where the last equation follows by the Fourier inversion formula, a consequence of which the equality holds at x0 if f is continuous at x0.

D Proof of Theorem 5.7

Let f P L1pRmq and pψ, ηq P SpRq ˆ S1pRq. Assume that there exists u P E X L1pRq that is real-valued,

Λmu

“

ψr ˚ η

and

ş
R

uppζ

qdζ

“

´1.

Write

ż żδż

dzdαdu

Ipx; ε, δq :“

Rψf pu, α, u ¨ x ´ αzq ηpzq

Sm´1 ε R

αm

.

(156)

We show that

lim Ipx; ε, δq “ R˚Λm´1Rpxq, a.e. x P Rm.
δÑ8 εÑ0

(157)

In the following we write p¨qαppq “ p¨qpp{αq{α. By using the convolution form,

ż

”

´ ¯ı

Rψf pu, α, β ´ αzq ηpzqdz “ Rf pu, ¨q ˚ ψr ˚ η pβq

R

α

“ rRf pu, ¨q ˚ pΛmuqαs pβq.

(158) (159)

Observe that

żδ
ε

pΛmuqα

ppq

dα αm

“

Λm´1

« ż

δ

pΛuq

´

p

¯

ε

α

ﬀ dα
α2

“

Λm´1

«

1 p

ż p{ε

ﬀ

pΛuqpzqdz

p{δ

“

Λm´1

„1 Hu
p

´p¯ ε

´

1 Hu
p

´

p

 ¯

δ

“ Λm´1rkεppq ´ kδppqs,

(160) (161) (162) (163)

where the ﬁrst equality follows by repeatedly applying pΛuqα “ αΛpuαq; the second equality follows by substituting z Ð p{α; the fourth equality follows by deﬁning

1

1 ˆp˙

kpzq

:“

Hu z

pzq

and

kγ ppq

:“

k γ

γ

for γ “ ε, δ.

(164)

29

Therefore, we have

żδ

dα

ε (159) αm “ rRf pu, ¨q ˚ (163)s pβq

“

“Λm´1Rf

pu,

¨q

˚

pkε

´

kδ

‰ q

pβq.

(165) (166)

We

show

that

k

P

L1 X L8pRq

and

ş kpzqdz
R

“

1.

To

begin

with,

k

P

L1pRq

because

there

exist

s, t

ą

0

such that

|kpzq| À |z|´1`s, as |z| Ñ 0 |kpzq| À |z|´1´t, as |z| Ñ 8.

(167) (168)

The ﬁrst claim holds because u is real-valued and thus u is odd, then p

ż

Hup0q “ sgnζ ¨ uppζqdζ

R

ż

ż

“

uppζqdζ ´

uppζ qdζ

p´8,0s

p0,8q

“ 0.

(169) (170) (171)

The second claim holds because u P L1pRq and thus u as well as Hu decays at inﬁnity. Then, by the

continuity

and

the

integrability

of

k,

it

is

bounded.

By

the

assumption

that

ş
R

uppζ

qdζ

“

´1,

ż
R

kpzqdz

“

´

ż
R

Hupzq dz 0´z

“ ´up0q

(172) (173)

“ 1.

(174)

Write

J pu, pq :“ Λm´1Rf pu, pq.

(175)

Because

k

P

L1pRq

and

ş
R

kpzqdz

“

1,

kε

is

an

approximation

of

the

identity

[43,

III,

Th.2].

Then,

lim Jpu, ¨q ˚ kεppq “ Jpu, pq, a.e. pu, pq P Sm´1 ˆ R.
εÑ0

(176)

However, as k P L8pRq,

}J ˚ kδ}L8pSm´1ˆRq ď δ´1}J }L1pSm´1ˆRq}k}L8pRq,

(177)

and thus,

lim Jpu, ¨q ˚ kδppq “ 0, a.e. pu, pq P Sm´1 ˆ R.
δÑ8

(178)

Because it is an approximation to the identity, J ˚ kγ P L1pSm´1 ˆ Rq for 0 ď γ. Hence, there exists a maximal function M pu, pq [43, III, Th.2] such that

sup |pJpu, ¨q ˚ vεqppq| À M pu, pq.
0ăε

(179)

Therefore, |Jpu, ¨q ˚ pvε ´ vδqpu ¨ xq| is uniformly integrable [35, Ex. 4.15.4] on Sm´1. That is, if Ω Ă Sm´1

satisﬁes

ş
Ω

du

ď

A

then

ż

|Jpu, ¨q ˚ kγ|pu ¨ xqdu À A sup |M pu, pq|, @γ ě 0.

Ω

u,p

(180)

Thus, by the Vitali convergence theorem, we have

ż

Rη: Rψ f

pxq

“

lim
δÑ8

εÑ0

rJpu, ¨q ˚ pvε ´ vδqspu ¨ xqdu
Sm´1

ż

“

Jpu, u ¨ xqdu, a.e. x P Rm

Sm´1

“ R˚Λm´1Rf pxq.

(181)
(182) (183)

30

E Proof of Theorem 5.11

Let f P L2pRmq and pψ, ηq be admissible with Kψ,η “ 1. Assume without loss of generality that pψ, ψq and pη, ηq are self-admissible respectively. Write

ż żδż

dzdαdu

Irf ; pε, δqspxq :“

Rψf pu, α, u ¨ x ´ αzq ηpzq

Sm´1 ε R

αm

.

In the following we write Ωrε, δs :“ Sm´1 ˆ rR`zpε, δqs ˆ R Ă Ym`1. We show that

lim
δÑ8

››f

´

Irf ;

pε,

δqs››2

“

0.

εÑ0

Observe that

(184) (185)

››f ´ Irf ; pε, δqs››2 “

sup

ˇ ˇ

pf

´

I

rf

;

pε,

δqs,

gq

ˇ ˇ

}g }2 “1

“

sup

ˇ ˇ

pRψ

f,

Rη

gqΩrε,δs

ˇ ˇ

}g }2 “1

ď

sup
}g }2 “1

ˇˇRψ

f

ˇ ˇL2

pΩrε,δsq

››Rη

g

› ›L2

pYm`1

q

“

sup

ˇˇRψ

f

ˇ ˇL2

pΩrε,δsq

››g››2

}g }2 “1

Ñ 0 ¨ 1, as ε Ñ 0, δ Ñ 8

(186) (187) (188) (189) (190)

where the third inequality follows by the Schwartz inequality; the last limit follows by }Rψf }L2pΩrε,δsq, which shrinks as the domain Ωrε, δs tends to H.

F Proofs of Example 6.4 and Example 6.10
Let σpzq :“ p1 ` e´zq´1. Obviously σpzq P EpRq.

Step 0: Derivatives of σpzq. For every k P N,

σpkqpzq “ Skpσpzqq,

where Skpzq is a polynomial deﬁned by

$

& zp1 ´ zq

k“1

Skpzq :“

% Sk1 ´1pzqS1pzq k ą 1,

which is justiﬁed by induction on k.

Step 1: σ, tanh P OMpRq. Recall that |σpzq| ď 1. Hence, for every k P N,
ˇˇσpkqpzqˇˇ “ |Skpσpzqq| ď max |Skpzq| ă 8.
zPr0,1s
Therefore, every k P N0, σpkqpzq is bounded, which concludes σpzq P OMpRq. Hence, immediately tanh P OMpRq because
tanhpzq “ 2σp2zq ´ 1.

(191) (192)
(193) (194)

Step 2: σpkq P SpRq, k P N. Observe that

σ1pzq “ pe z{2 ` e´z{2q´2.

(195)

31

Hence, σ1pzq decays faster than any polynomial, which means supz |z σ1pzq| ă 8 for any P N0. Then, for every k, P N0,

sup ˇˇz
z

σpk`1qpz

ˇ qˇ

“

sup ˇˇz
z

Sk`1

pσpz

ˇ qqˇ

ď

max |z
z

σ1pzq| ¨

max
z

|Sk1

pσpzqq|

ă

8,

(196)

which concludes σ1 P SpRq. Therefore, σpkq P SpRq for every k P N.

Step 3: σp´1q P OMpRq. Observe that

żz σp´1qpzq “ σpwqdw.
0

(197)

Hence, it is already known that rσp´1qspkq “ σpk´1q P OMpRq for every k P N. We show that σp´1qpzq has at most polynomial growth. Write

ρpzq :“ σp´1qpzq ´ z`.

(198)

Then ρpzq attains at 0 its maximum maxz ρpzq “ log 2, because ρ1pzq ă 0 when z ą 0 and ρ1pzq ą 0 when z ă 0. Therefore,

ˇˇσp´1qpzqˇˇ ď |ρpzq| ` |z`| ď log 2 ` |z|,

(199)

which concludes σp´1qpzq P OM.

Step 4: η “ σpkq is admissible with ψ “ ΛmG when k P N is positive and odd.
Recall that η “ σpkq P SpRq. Hence, xηp, ψx0y “ xη, ψ0y. Observe that if k is odd, then σpkq is an odd function and thus xη, ψ0y “ 0. However, if k is even, then σpkq is an even function and thus xη, ψ0y ‰ 0.

Step 5: σ and σp´1q cannot be admissible with ψ “ ΛmG. This follows by Theorem 5.4, because both

diverge.

ż

ż

´¯

´

¯

Gr ˚ σ pzqdz and

Gr ˚ σp´1q pzqdz,

R

R

(200)

Step 6: σ and σp´1q are admissible with ψ “ ΛmG1 and ψ “ ΛmG2, respectively. Observe that both

u0 :“ GĂ1 ˚ σ “ Gr ˚ σ1 and u´1 :“ GĂ2 ˚ σp´1q “ Gr ˚ σ1, belong to SpRq. Hence, u0 and u´1 satisfy the suﬃcient condition in Theorem 5.4.

(201)

32

