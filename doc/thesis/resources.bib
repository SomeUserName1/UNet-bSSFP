
@incollection{prechelt_early_1998,
	address = {Berlin, Heidelberg},
	title = {Early {Stopping} - {But} {When}?},
	isbn = {978-3-540-49430-0},
	url = {https://doi.org/10.1007/3-540-49430-8_3},
	abstract = {Validation can be used to detect when overfitting starts during supervised training of a neural network; training is then stopped before convergence to avoid the overfitting (“early stopping”). The exact criterion used for validation-based early stopping, however, is usually chosen in an ad-hoc fashion or training is stopped interactively. This trick describes how to select a stopping criterion in a systematic fashion; it is a trick for either speeding learning procedures or improving generalization, whichever is more important in the particular situation. An empirical investigation on multi-layer perceptrons shows that there exists a tradeoff between training time and generalization: From the given mix of 1296 training runs using difierent 12 problems and 24 difierent network architectures I conclude slower stopping criteria allow for small improvements in generalization (here: about 4\% on average), but cost much more training time (here: about factor 4 longer on average).},
	language = {en},
	urldate = {2024-04-10},
	booktitle = {Neural {Networks}: {Tricks} of the {Trade}},
	publisher = {Springer},
	author = {Prechelt, Lutz},
	editor = {Orr, Genevieve B. and Müller, Klaus-Robert},
	year = {1998},
	doi = {10.1007/3-540-49430-8_3},
	keywords = {Early Stopping, Generalization Error, Neural Information Processing System, Training Time, Validation Error},
	pages = {55--69},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/NF7I984X/Prechelt - 1998 - Early Stopping - But When.pdf:application/pdf},
}

@inproceedings{ronneberger_u-net_2015,
	address = {Cham},
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	isbn = {978-3-319-24574-4},
	shorttitle = {U-{Net}},
	doi = {10.1007/978-3-319-24574-4_28},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	year = {2015},
	keywords = {Convolutional Layer, Data Augmentation, Deep Network, Ground Truth Segmentation, Training Image},
	pages = {234--241},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/YSDCAGJG/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf},
}

@misc{pfeiffer_modular_2024,
	title = {Modular {Deep} {Learning}},
	url = {http://arxiv.org/abs/2302.11529},
	doi = {10.48550/arXiv.2302.11529},
	abstract = {Transfer learning has recently become the dominant paradigm of machine learning. Pre-trained models fine-tuned for downstream tasks achieve better performance with fewer labelled examples. Nonetheless, it remains unclear how to develop models that specialise towards multiple tasks without incurring negative interference and that generalise systematically to non-identically distributed tasks. Modular deep learning has emerged as a promising solution to these challenges. In this framework, units of computation are often implemented as autonomous parameter-efficient modules. Information is conditionally routed to a subset of modules and subsequently aggregated. These properties enable positive transfer and systematic generalisation by separating computation from routing and updating modules locally. We offer a survey of modular architectures, providing a unified view over several threads of research that evolved independently in the scientific literature. Moreover, we explore various additional purposes of modularity, including scaling language models, causal inference, programme induction, and planning in reinforcement learning. Finally, we report various concrete applications where modularity has been successfully deployed such as cross-lingual and cross-modal knowledge transfer. Related talks and projects to this survey, are available at https://www.modulardeeplearning.com/.},
	urldate = {2024-04-10},
	publisher = {arXiv},
	author = {Pfeiffer, Jonas and Ruder, Sebastian and Vulić, Ivan and Ponti, Edoardo Maria},
	month = jan,
	year = {2024},
	note = {arXiv:2302.11529 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/Y9T7A5NR/Pfeiffer et al. - 2024 - Modular Deep Learning.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/GV67UMSV/2302.html:text/html},
}

@misc{ruder_overview_2017,
	title = {An {Overview} of {Multi}-{Task} {Learning} in {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1706.05098},
	doi = {10.48550/arXiv.1706.05098},
	abstract = {Multi-task learning (MTL) has led to successes in many applications of machine learning, from natural language processing and speech recognition to computer vision and drug discovery. This article aims to give a general overview of MTL, particularly in deep neural networks. It introduces the two most common methods for MTL in Deep Learning, gives an overview of the literature, and discusses recent advances. In particular, it seeks to help ML practitioners apply MTL by shedding light on how MTL works and providing guidelines for choosing appropriate auxiliary tasks.},
	urldate = {2024-04-10},
	publisher = {arXiv},
	author = {Ruder, Sebastian},
	month = jun,
	year = {2017},
	note = {arXiv:1706.05098 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
	annote = {Comment: 14 pages, 8 figures},
	file = {arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/2UYZNWBZ/Ruder - 2017 - An Overview of Multi-Task Learning in Deep Neural .pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/KYGZCLLP/1706.html:text/html},
}

@article{yang_mri_2020,
	title = {{MRI} {Cross}-{Modality} {Image}-to-{Image} {Translation}},
	volume = {10},
	copyright = {2020 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-60520-6},
	doi = {10.1038/s41598-020-60520-6},
	abstract = {We present a cross-modality generation framework that learns to generate translated modalities from given modalities in MR images. Our proposed method performs Image Modality Translation (abbreviated as IMT) by means of a deep learning model that leverages conditional generative adversarial networks (cGANs). Our framework jointly exploits the low-level features (pixel-wise information) and high-level representations (e.g. brain tumors, brain structure like gray matter, etc.) between cross modalities which are important for resolving the challenging complexity in brain structures. Our framework can serve as an auxiliary method in medical use and has great application potential. Based on our proposed framework, we first propose a method for cross-modality registration by fusing the deformation fields to adopt the cross-modality information from translated modalities. Second, we propose an approach for MRI segmentation, translated multichannel segmentation (TMS), where given modalities, along with translated modalities, are segmented by fully convolutional networks (FCN) in a multichannel manner. Both of these two methods successfully adopt the cross-modality information to improve the performance without adding any extra data. Experiments demonstrate that our proposed framework advances the state-of-the-art on five brain MRI datasets. We also observe encouraging results in cross-modality registration and segmentation on some widely adopted brain datasets. Overall, our work can serve as an auxiliary method in medical use and be applied to various tasks in medical fields.},
	language = {en},
	number = {1},
	urldate = {2024-04-10},
	journal = {Scientific Reports},
	author = {Yang, Qianye and Li, Nannan and Zhao, Zixu and Fan, Xingyu and Chang, Eric I.-Chao and Xu, Yan},
	month = feb,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biomedical engineering, Computer science},
	pages = {3753},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/WG7LR9XY/Yang et al. - 2020 - MRI Cross-Modality Image-to-Image Translation.pdf:application/pdf},
}

@misc{izmailov_averaging_2019,
	title = {Averaging {Weights} {Leads} to {Wider} {Optima} and {Better} {Generalization}},
	url = {http://arxiv.org/abs/1803.05407},
	doi = {10.48550/arXiv.1803.05407},
	abstract = {Deep neural networks are typically trained by optimizing a loss function with an SGD variant, in conjunction with a decaying learning rate, until convergence. We show that simple averaging of multiple points along the trajectory of SGD, with a cyclical or constant learning rate, leads to better generalization than conventional training. We also show that this Stochastic Weight Averaging (SWA) procedure finds much flatter solutions than SGD, and approximates the recent Fast Geometric Ensembling (FGE) approach with a single model. Using SWA we achieve notable improvement in test accuracy over conventional SGD training on a range of state-of-the-art residual networks, PyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, and ImageNet. In short, SWA is extremely easy to implement, improves generalization, and has almost no computational overhead.},
	urldate = {2024-04-10},
	publisher = {arXiv},
	author = {Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
	month = feb,
	year = {2019},
	note = {arXiv:1803.05407 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Appears at the Conference on Uncertainty in Artificial Intelligence (UAI), 2018},
	file = {arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/TLX4R4JU/Izmailov et al. - 2019 - Averaging Weights Leads to Wider Optima and Better.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/UNLTZ6M9/1803.html:text/html},
}

@article{perez-garcia_torchio_2021,
	title = {{TorchIO}: {A} {Python} library for efficient loading, preprocessing, augmentation and patch-based sampling of medical images in deep learning},
	volume = {208},
	issn = {0169-2607},
	shorttitle = {{TorchIO}},
	url = {https://www.sciencedirect.com/science/article/pii/S0169260721003102},
	doi = {10.1016/j.cmpb.2021.106236},
	abstract = {Background and objective
Processing of medical images such as MRI or CT presents different challenges compared to RGB images typically used in computer vision. These include a lack of labels for large datasets, high computational costs, and the need of metadata to describe the physical properties of voxels. Data augmentation is used to artificially increase the size of the training datasets. Training with image subvolumes or patches decreases the need for computational power. Spatial metadata needs to be carefully taken into account in order to ensure a correct alignment and orientation of volumes.
Methods
We present TorchIO, an open-source Python library to enable efficient loading, preprocessing, augmentation and patch-based sampling of medical images for deep learning. TorchIO follows the style of PyTorch and integrates standard medical image processing libraries to efficiently process images during training of neural networks. TorchIO transforms can be easily composed, reproduced, traced and extended. Most transforms can be inverted, making the library suitable for test-time augmentation and estimation of aleatoric uncertainty in the context of segmentation. We provide multiple generic preprocessing and augmentation operations as well as simulation of MRI-specific artifacts.
Results
Source code, comprehensive tutorials and extensive documentation for TorchIO can be found at http://torchio.rtfd.io/. The package can be installed from the Python Package Index (PyPI) running pip install torchio. It includes a command-line interface which allows users to apply transforms to image files without using Python. Additionally, we provide a graphical user interface within a TorchIO extension in 3D Slicer to visualize the effects of transforms.
Conclusion
TorchIO was developed to help researchers standardize medical image processing pipelines and allow them to focus on the deep learning experiments. It encourages good open-science practices, as it supports experiment reproducibility and is version-controlled so that the software can be cited precisely. Due to its modularity, the library is compatible with other frameworks for deep learning with medical images.},
	urldate = {2024-04-10},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Pérez-García, Fernando and Sparks, Rachel and Ourselin, Sébastien},
	month = sep,
	year = {2021},
	keywords = {Data augmentation, Deep learning, Medical image computing, Preprocessing},
	pages = {106236},
	file = {Full Text:/home/someusername/workspace/UNet-bSSFP/lit/storage/4JR9AM48/Pérez-García et al. - 2021 - TorchIO A Python library for efficient loading, p.pdf:application/pdf;ScienceDirect Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/ECUINQPD/S0169260721003102.html:text/html},
}

@misc{cardoso_monai_2022,
	title = {{MONAI}: {An} open-source framework for deep learning in healthcare},
	shorttitle = {{MONAI}},
	url = {http://arxiv.org/abs/2211.02701},
	doi = {10.48550/arXiv.2211.02701},
	abstract = {Artificial Intelligence (AI) is having a tremendous impact across most areas of science. Applications of AI in healthcare have the potential to improve our ability to detect, diagnose, prognose, and intervene on human disease. For AI models to be used clinically, they need to be made safe, reproducible and robust, and the underlying software framework must be aware of the particularities (e.g. geometry, physiology, physics) of medical data being processed. This work introduces MONAI, a freely available, community-supported, and consortium-led PyTorch-based framework for deep learning in healthcare. MONAI extends PyTorch to support medical data, with a particular focus on imaging, and provide purpose-specific AI model architectures, transformations and utilities that streamline the development and deployment of medical AI models. MONAI follows best practices for software-development, providing an easy-to-use, robust, well-documented, and well-tested software framework. MONAI preserves the simple, additive, and compositional approach of its underlying PyTorch libraries. MONAI is being used by and receiving contributions from research, clinical and industrial teams from around the world, who are pursuing applications spanning nearly every aspect of healthcare.},
	urldate = {2024-04-10},
	publisher = {arXiv},
	author = {Cardoso, M. Jorge and Li, Wenqi and Brown, Richard and Ma, Nic and Kerfoot, Eric and Wang, Yiheng and Murrey, Benjamin and Myronenko, Andriy and Zhao, Can and Yang, Dong and Nath, Vishwesh and He, Yufan and Xu, Ziyue and Hatamizadeh, Ali and Myronenko, Andriy and Zhu, Wentao and Liu, Yun and Zheng, Mingxin and Tang, Yucheng and Yang, Isaac and Zephyr, Michael and Hashemian, Behrooz and Alle, Sachidanand and Darestani, Mohammad Zalbagi and Budd, Charlie and Modat, Marc and Vercauteren, Tom and Wang, Guotai and Li, Yiwen and Hu, Yipeng and Fu, Yunguan and Gorman, Benjamin and Johnson, Hans and Genereaux, Brad and Erdal, Barbaros S. and Gupta, Vikash and Diaz-Pinto, Andres and Dourson, Andre and Maier-Hein, Lena and Jaeger, Paul F. and Baumgartner, Michael and Kalpathy-Cramer, Jayashree and Flores, Mona and Kirby, Justin and Cooper, Lee A. D. and Roth, Holger R. and Xu, Daguang and Bericat, David and Floca, Ralf and Zhou, S. Kevin and Shuaib, Haris and Farahani, Keyvan and Maier-Hein, Klaus H. and Aylward, Stephen and Dogra, Prerna and Ourselin, Sebastien and Feng, Andrew},
	month = nov,
	year = {2022},
	note = {arXiv:2211.02701 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: www.monai.io},
	file = {arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/IEJ6VT3D/Cardoso et al. - 2022 - MONAI An open-source framework for deep learning .pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/KZHLS5NT/2211.html:text/html},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	copyright = {2015 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	language = {en},
	number = {7553},
	urldate = {2024-04-10},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computer science, Mathematics and computing},
	pages = {436--444},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/DRLEAYRB/LeCun et al. - 2015 - Deep learning.pdf:application/pdf},
}

@book{goodfellow_deep_2016,
	title = {Deep {Learning}},
	isbn = {978-0-262-33737-3},
	abstract = {An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.“Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.”—Elon Musk, cochair of OpenAI; cofounder and CEO of Tesla and SpaceXDeep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.},
	language = {en},
	publisher = {MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	month = nov,
	year = {2016},
	note = {Google-Books-ID: omivDQAAQBAJ},
	keywords = {Computers / Artificial Intelligence / General, Computers / Computer Science, Computers / Data Science / Machine Learning},
	file = {Goodfellow et al. - 2016 - Deep Learning.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/QT3DRWC4/Goodfellow et al. - 2016 - Deep Learning.pdf:application/pdf},
}

@misc{zhang_dive_2023,
	title = {Dive into {Deep} {Learning}},
	url = {http://arxiv.org/abs/2106.11342},
	doi = {10.48550/arXiv.2106.11342},
	abstract = {This open-source book represents our attempt to make deep learning approachable, teaching readers the concepts, the context, and the code. The entire book is drafted in Jupyter notebooks, seamlessly integrating exposition figures, math, and interactive examples with self-contained code. Our goal is to offer a resource that could (i) be freely available for everyone; (ii) offer sufficient technical depth to provide a starting point on the path to actually becoming an applied machine learning scientist; (iii) include runnable code, showing readers how to solve problems in practice; (iv) allow for rapid updates, both by us and also by the community at large; (v) be complemented by a forum for interactive discussion of technical details and to answer questions.},
	urldate = {2024-04-10},
	publisher = {arXiv},
	author = {Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
	month = aug,
	year = {2023},
	note = {arXiv:2106.11342 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
	annote = {Comment: (HTML) https://D2L.ai (GitHub) https://github.com/d2l-ai/d2l-en/},
	file = {arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/6UQVDYIR/Zhang et al. - 2023 - Dive into Deep Learning.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/P8FZREAH/2106.html:text/html},
}

@article{smith_advances_2004,
	series = {Mathematics in {Brain} {Imaging}},
	title = {Advances in functional and structural {MR} image analysis and implementation as {FSL}},
	volume = {23},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811904003933},
	doi = {10.1016/j.neuroimage.2004.07.051},
	abstract = {The techniques available for the interrogation and analysis of neuroimaging data have a large influence in determining the flexibility, sensitivity, and scope of neuroimaging experiments. The development of such methodologies has allowed investigators to address scientific questions that could not previously be answered and, as such, has become an important research area in its own right. In this paper, we present a review of the research carried out by the Analysis Group at the Oxford Centre for Functional MRI of the Brain (FMRIB). This research has focussed on the development of new methodologies for the analysis of both structural and functional magnetic resonance imaging data. The majority of the research laid out in this paper has been implemented as freely available software tools within FMRIB's Software Library (FSL).},
	urldate = {2024-04-10},
	journal = {NeuroImage},
	author = {Smith, Stephen M. and Jenkinson, Mark and Woolrich, Mark W. and Beckmann, Christian F. and Behrens, Timothy E. J. and Johansen-Berg, Heidi and Bannister, Peter R. and De Luca, Marilena and Drobnjak, Ivana and Flitney, David E. and Niazy, Rami K. and Saunders, James and Vickers, John and Zhang, Yongyue and De Stefano, Nicola and Brady, J. Michael and Matthews, Paul M.},
	month = jan,
	year = {2004},
	keywords = {FMRI, FSL, Structural MR image analysis},
	pages = {S208--S219},
	file = {ScienceDirect Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/7AHST38F/S1053811904003933.html:text/html;Submitted Version:/home/someusername/workspace/UNet-bSSFP/lit/storage/3IBG7FYI/Smith et al. - 2004 - Advances in functional and structural MR image ana.pdf:application/pdf},
}

@article{garyfallidis_dipy_2014,
	title = {Dipy, a library for the analysis of diffusion {MRI} data},
	volume = {8},
	issn = {1662-5196},
	url = {https://www.frontiersin.org/articles/10.3389/fninf.2014.00008},
	doi = {10.3389/fninf.2014.00008},
	abstract = {Diffusion Imaging in Python (Dipy) is a free and open source software projectfor the analysis of data from diffusion magnetic resonance imaging (dMRI)experiments. dMRI is an application of MRI that can be used to measurestructural features of brain white matter. Many methods have been developed touse dMRI data to model the local configuration of white matter nerve fiberbundles and infer the trajectory of bundles connecting different parts of thebrain.Dipy gathers implementations of many different methods in dMRI, including:diffusion signal pre-processing; reconstruction of diffusion distributions inindividual voxels; fiber tractography and fiber track post-processing, analysisand visualization. Dipy aims to provide transparent implementations forall the different steps of dMRI analysis with a uniform programming interface.We have implemented classical signal reconstruction techniques, such as thediffusion tensor model and deterministic fiber tractography. In addition,cutting edge novel reconstruction techniques are implemented, such asconstrained spherical deconvolution and diffusion spectrum imaging withdeconvolution, as well as methods for probabilistic tracking and originalmethods for tractography clustering. Many additional utility functions areprovided to calculate various statistics, informative visualizations, as wellas file-handling routines to assist in the development and use of noveltechniques.In contrast to many other scientific software projects, Dipy is not beingdeveloped by a single research group. Rather, it is an open project thatencourages contributions from any scientist/developer through GitHub and opendiscussions on the project mailing list. Consequently, Dipy today has aninternational team of contributors, spanning seven different academic institutionsin five countries and three continents, which is still growing.},
	language = {English},
	urldate = {2024-04-10},
	journal = {Frontiers in Neuroinformatics},
	author = {Garyfallidis, Eleftherios and Brett, Matthew and Amirbekian, Bagrat and Rokem, Ariel and Van Der Walt, Stefan and Descoteaux, Maxime and Nimmo-Smith, Ian},
	month = feb,
	year = {2014},
	note = {Publisher: Frontiers},
	keywords = {clustering, Deterministic Tractography, diffusion MRI, diffusion tensor, fiber tracking, Free Open Source Software, medical imaging, Medical Visualization, Probabilistic Tractography, python, Spherical Deconvolution},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/IP74J49M/Garyfallidis et al. - 2014 - Dipy, a library for the analysis of diffusion MRI .pdf:application/pdf},
}

@inproceedings{paszke_pytorch_2019,
	title = {{PyTorch}: {An} {Imperative} {Style}, {High}-{Performance} {Deep} {Learning} {Library}},
	volume = {32},
	shorttitle = {{PyTorch}},
	url = {https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html},
	abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs.
In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance.
We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.},
	urldate = {2024-04-10},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	year = {2019},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/7QNTHMYS/Paszke et al. - 2019 - PyTorch An Imperative Style, High-Performance Dee.pdf:application/pdf},
}

@article{falcon_pytorch_2019,
	title = {Pytorch lightning},
	volume = {3},
	url = {https://cir.nii.ac.jp/crid/1370013168774120069},
	urldate = {2024-04-10},
	journal = {GitHub},
	author = {Falcon, William A.},
	year = {2019},
}

@misc{wang_pretraining_2022,
	title = {Pretraining is {All} {You} {Need} for {Image}-to-{Image} {Translation}},
	url = {http://arxiv.org/abs/2205.12952},
	doi = {10.48550/arXiv.2205.12952},
	abstract = {We propose to use pretraining to boost general image-to-image translation. Prior image-to-image translation methods usually need dedicated architectural design and train individual translation models from scratch, struggling for high-quality generation of complex scenes, especially when paired training data are not abundant. In this paper, we regard each image-to-image translation problem as a downstream task and introduce a simple and generic framework that adapts a pretrained diffusion model to accommodate various kinds of image-to-image translation. We also propose adversarial training to enhance the texture synthesis in the diffusion model training, in conjunction with normalized guidance sampling to improve the generation quality. We present extensive empirical comparison across various tasks on challenging benchmarks such as ADE20K, COCO-Stuff, and DIODE, showing the proposed pretraining-based image-to-image translation (PITI) is capable of synthesizing images of unprecedented realism and faithfulness.},
	urldate = {2024-04-10},
	publisher = {arXiv},
	author = {Wang, Tengfei and Zhang, Ting and Zhang, Bo and Ouyang, Hao and Chen, Dong and Chen, Qifeng and Wen, Fang},
	month = may,
	year = {2022},
	note = {arXiv:2205.12952 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Project Page: https://tengfei-wang.github.io/PITI/index.html},
	file = {arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/67ZJ8N25/Wang et al. - 2022 - Pretraining is All You Need for Image-to-Image Tra.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/88GS42MK/2205.html:text/html},
}

@inproceedings{grigoryev_when_2021,
	title = {When, {Why}, and {Which} {Pretrained} {GANs} {Are} {Useful}?},
	url = {https://openreview.net/forum?id=4Ycr8oeCoIh},
	abstract = {The literature has proposed several methods to finetune pretrained GANs on new datasets, which typically results in higher performance compared to training from scratch, especially in the limited-data regime. However, despite the apparent empirical benefits of GAN pretraining, its inner mechanisms were not analyzed in-depth, and understanding of its role is not entirely clear. Moreover, the essential practical details, e.g., selecting a proper pretrained GAN checkpoint, currently do not have rigorous grounding and are typically determined by trial and error. This work aims to dissect the process of GAN finetuning. First, we show that initializing the GAN training process by a pretrained checkpoint primarily affects the model's coverage rather than the fidelity of individual samples. Second, we explicitly describe how pretrained generators and discriminators contribute to the finetuning process and explain the previous evidence on the importance of pretraining both of them. Finally, as an immediate practical benefit of our analysis, we describe a simple recipe to choose an appropriate GAN checkpoint that is the most suitable for finetuning to a particular target task. Importantly, for most of the target tasks, Imagenet-pretrained GAN, despite having poor visual quality, appears to be an excellent starting point for finetuning, resembling the typical pretraining scenario of discriminative computer vision models.},
	language = {en},
	urldate = {2024-04-10},
	author = {Grigoryev, Timofey and Voynov, Andrey and Babenko, Artem},
	month = oct,
	year = {2021},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/DEH66NEP/Grigoryev et al. - 2021 - When, Why, and Which Pretrained GANs Are Useful.pdf:application/pdf},
}

@article{friston_statistical_1994,
	title = {Statistical parametric maps in functional imaging: {A} general linear approach},
	volume = {2},
	copyright = {Copyright © 1995 Wiley-Liss, Inc.},
	issn = {1097-0193},
	shorttitle = {Statistical parametric maps in functional imaging},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.460020402},
	doi = {10.1002/hbm.460020402},
	abstract = {Statistical parametric maps are spatially extended statistical processes that are used to test hypotheses about regionally specific effects in neuroimaging data. The most established sorts of statistical parametric maps (e.g., Friston et al. [1991]: J Cereb Blood Flow Metab 11:690–699; Worsley et al. [1992]: J Cereb Blood Flow Metab 12:900–918) are based on linear models, for example ANCOVA, correlation coefficients and t tests. In the sense that these examples are all special cases of the general linear model it should be possible to implement them (and many others) within a unified framework. We present here a general approach that accomodates most forms of experimental layout and ensuing analysis (designed experiments with fixed effects for factors, covariates and interaction of factors). This approach brings together two well established bodies of theory (the general linear model and the theory of Gaussian fields) to provide a complete and simple framework for the analysis of imaging data. The importance of this framework is twofold: (i) Conceptual and mathematical simplicity, in that the same small number of operational equations is used irrespective of the complexity of the experiment or nature of the statistical model and (ii) the generality of the framework provides for great latitude in experimental design and analysis. © 1995 Wiley-Liss, Inc.},
	language = {en},
	number = {4},
	urldate = {2024-04-10},
	journal = {Human Brain Mapping},
	author = {Friston, K. J. and Holmes, A. P. and Worsley, K. J. and Poline, J.-P. and Frith, C. D. and Frackowiak, R. S. J.},
	year = {1994},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.460020402},
	keywords = {analysis of variance, functional anatomy, functional imaging, Gaussian fields, general linear model, statistical parametric maps, statistics},
	pages = {189--210},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/SPVR5RAK/Friston et al. - 1994 - Statistical parametric maps in functional imaging.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/LV36GSMF/hbm.html:text/html},
}

@article{scheffler_pictorial_1999,
	title = {A pictorial description of steady-states in rapid magnetic resonance imaging},
	volume = {11},
	copyright = {Copyright © 1999 John Wiley \& Sons, Inc.},
	issn = {1099-0534},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-0534%281999%2911%3A5%3C291%3A%3AAID-CMR2%3E3.0.CO%3B2-J},
	doi = {10.1002/(SICI)1099-0534(1999)11:5<291::AID-CMR2>3.0.CO;2-J},
	abstract = {Magnetic resonance imaging in biochemical and clinical research requires rapid imaging sequences. Time-resolved imaging of heart movement and the acquisition of a three-dimensional image block within the circulation time of a contrast agent bolus are two typical examples. Rapid imaging sequences are characterized by a very fast train of radiofrequency (rf) and gradient pulses. Between these rf pulses, the excited magnetization is unable to return to its thermal equilibrium. As a consequence, further rf pulses will influence both the remaining transversal and the remaining equilibrium state. The steady-state magnetization of a multi-rf pulse and gradient pulse experiment is thus a mixture or superposition of different transversal and longitudinal states and the acquired image amplitude becomes a complex function of the investigated tissue's relaxation properties. Based on the works of Woessner, Kaiser, and Hennig, this article intends to give a pictorial description of rapid multipulse imaging experiments. It also provides an extension of this theory applied to modern imaging sequences such as TRUE FISP and rf-spoiled techniques. ©1999 John Wiley \& Sons, Inc. Concepts Magn Reson 11: 291–304, 1999},
	language = {en},
	number = {5},
	urldate = {2024-04-10},
	journal = {Concepts in Magnetic Resonance},
	author = {Scheffler, Klaus},
	year = {1999},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291099-0534\%281999\%2911\%3A5\%3C291\%3A\%3AAID-CMR2\%3E3.0.CO\%3B2-J},
	keywords = {phase–graph description, rapid imaging, refocusing, rf spoiling, steady-state},
	pages = {291--304},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/2HGA8NQB/Scheffler - 1999 - A pictorial description of steady-states in rapid .pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/2HD3SBLV/(SICI)1099-0534(1999)115291AID-CMR23.0.html:text/html},
}

@article{bieri_fundamentals_2013,
	title = {Fundamentals of balanced steady state free precession {MRI}},
	volume = {38},
	copyright = {Copyright © 2013 Wiley Periodicals, Inc.},
	issn = {1522-2586},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.24163},
	doi = {10.1002/jmri.24163},
	abstract = {Balanced steady state free precession (balanced SSFP) has become increasingly popular for research and clinical applications, offering a very high signal-to-noise ratio and a T2/T1-weighted image contrast. This review article gives an overview on the basic principles of this fast imaging technique as well as possibilities for contrast modification. The first part focuses on the fundamental principles of balanced SSFP signal formation in the transient phase and in the steady state. In the second part, balanced SSFP imaging, contrast, and basic mechanisms for contrast modification are revisited and contemporary clinical applications are discussed. J. Magn. Reson. Imaging 2013;38:2–11. © 2013 Wiley Periodicals, Inc.},
	language = {en},
	number = {1},
	urldate = {2024-04-10},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Bieri, Oliver and Scheffler, Klaus},
	year = {2013},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jmri.24163},
	keywords = {contrast, preparation, steady state, transient phase},
	pages = {2--11},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/WAEJGVVN/Bieri and Scheffler - 2013 - Fundamentals of balanced steady state free precess.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/N8MS4SB5/jmri.html:text/html},
}

@article{scheffler_principles_2003,
	title = {Principles and applications of balanced {SSFP} techniques},
	volume = {13},
	issn = {1432-1084},
	url = {https://doi.org/10.1007/s00330-003-1957-x},
	doi = {10.1007/s00330-003-1957-x},
	abstract = {During the past 5 years balanced steady-state free precession (SSFP) has become increasingly important for diagnostic and functional imaging. Balanced SSFP is characterized by two unique features: it offers a very high signal-to noise ratio and a T2/T1-weighted image contrast. This article focuses on the physical principles, on the signal formation, and on the resulting properties of balanced SSFP. Mechanisms for contrast modification, recent clinical application, and potential extensions of this technique are discussed.},
	language = {en},
	number = {11},
	urldate = {2024-04-10},
	journal = {European Radiology},
	author = {Scheffler, Klaus and Lehnhardt, Stefan},
	month = nov,
	year = {2003},
	keywords = {Contrast modification, Rapid imaging, Transient phase},
	pages = {2409--2418},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/JEMGZAVM/Scheffler and Lehnhardt - 2003 - Principles and applications of balanced SSFP techn.pdf:application/pdf},
}

@article{heule_triple_2014,
	title = {Triple echo steady-state ({TESS}) relaxometry},
	volume = {71},
	copyright = {Copyright © 2013 Wiley Periodicals, Inc.},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.24659},
	doi = {10.1002/mrm.24659},
	abstract = {Purpose Rapid imaging techniques have attracted increased interest for relaxometry, but none are perfect: they are prone to static (B0) and transmit (B1) field heterogeneities, and commonly biased by T2/T1. The purpose of this study is the development of a rapid T1 and T2 relaxometry method that is completely (T2) or partly (T1) bias-free. Methods A new method is introduced to simultaneously quantify T1 and T2 within one single scan based on a triple echo steady-state (TESS) approach in combination with an iterative golden section search. TESS relaxometry is optimized and evaluated from simulations, in vitro studies, and in vivo experiments. Results It is found that relaxometry with TESS is not biased by T2/T1, insensitive to B0 heterogeneities, and, surprisingly, that TESS-T2 is not affected by B1 field errors. Consequently, excellent correspondence between TESS and reference spin echo data is observed for T2 in vitro at 1.5 T and in vivo at 3 T. Conclusion TESS offers rapid T1 and T2 quantification within one single scan, and in particular B1-insensitive T2 estimation. As a result, the new proposed method is of high interest for fast and reliable high-resolution T2 mapping, especially of the musculoskeletal system at high to ultra-high fields. Magn Reson Med 71:230–237, 2014. © 2013 Wiley Periodicals, Inc.},
	language = {en},
	number = {1},
	urldate = {2024-04-10},
	journal = {Magnetic Resonance in Medicine},
	author = {Heule, Rahel and Ganter, Carl and Bieri, Oliver},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.24659},
	keywords = {fast imaging, quantification, relaxometry, T1, T2, triple echo steady-state},
	pages = {230--237},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/GL7YSYG6/Heule et al. - 2014 - Triple echo steady-state (TESS) relaxometry.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/TG996RNH/mrm.html:text/html},
}

@article{nguyen_motion-insensitive_2017,
	title = {Motion-insensitive rapid configuration relaxometry},
	volume = {78},
	copyright = {© 2016 International Society for Magnetic Resonance in Medicine},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.26384},
	doi = {10.1002/mrm.26384},
	abstract = {Purpose Triple echo steady state (TESS) uses the lowest steady state configuration modes for rapid relaxometry. Due to its unbalanced gradient scheme, however, TESS is inherently motion-sensitive. The purpose of this work is to merge TESS with a balanced acquisition scheme for motion-insensitive rapid configuration relaxometry, termed MIRACLE. Methods The lowest order steady state free precession (SSFP) configurations are retrieved by Fourier transformation of the frequency response of N frequency-shifted balanced SSFP (bSSFP) scans and subsequently processed for relaxometry, as proposed with TESS. Accuracy of MIRACLE is evaluated from simulations, phantom studies as well as in vivo brain and cartilage imaging at 3T. Results Simulations and phantom results revealed no conceptual flaw, and artifact-free configuration imaging was achieved in vivo. Overall, relaxometry results were accurate in phantoms and in good agreement for cartilage and for in the brain, but apparent low values were observed for brain white matter; reflecting asymmetries in the bSSFP profile. Conclusion Rapid and mapping with MIRACLE offers analogous properties as TESS while successfully mitigating its motion-sensitivity. As a result of the Fourier transformation, relaxometry becomes sensitive to the voxel frequency distribution, which may contain useful physiologic information, such as structural brain integrity. © 2016 International Society for Magnetic Resonance in Medicine. Magn Reson Med 78:518–526, 2017. © 2016 International Society for Magnetic Resonance in Medicine},
	language = {en},
	number = {2},
	urldate = {2024-04-10},
	journal = {Magnetic Resonance in Medicine},
	author = {Nguyen, Damien and Bieri, Oliver},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.26384},
	keywords = {relaxometry, balanced Steady State Free Precession (bSSFP), T1 mapping, T2 mapping},
	pages = {518--526},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/VR83HDLP/Nguyen and Bieri - 2017 - Motion-insensitive rapid configuration relaxometry.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/YX3LH69G/mrm.html:text/html},
}

@article{huisman_diffusion-weighted_2010,
	title = {Diffusion-weighted and diffusion tensor imaging of the brain, made easy},
	volume = {10},
	issn = {1740-5025},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2967146/},
	doi = {10.1102/1470-7330.2010.9023},
	abstract = {Diffusion-weighted and diffusion tensor imaging (DWI/DTI) has revolutionized clinical neuroimaging. Pathology may be detected earlier and with greater specificity than with conventional magnetic resonance imaging sequences. In addition, DWI/DTI allows exploring the microarchitecture of the brain. A detailed knowledge of the basics of DWI/DTI is mandatory to better understand pathology encountered and to avoid misinterpretation of typical DWI/DTI artifacts. This article reviews the basic physics of DWI/DTI exemplified by several classical clinical cases.},
	number = {1A},
	urldate = {2024-04-10},
	journal = {Cancer Imaging},
	author = {Huisman, T.A.G.M.},
	month = oct,
	year = {2010},
	pmid = {20880787},
	pmcid = {PMC2967146},
	pages = {S163--S171},
	file = {PubMed Central Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/DW4YP9RE/Huisman - 2010 - Diffusion-weighted and diffusion tensor imaging of.pdf:application/pdf},
}

@article{tournier_diffusion_2011,
	title = {Diffusion {Tensor} {Imaging} and {Beyond}},
	volume = {65},
	issn = {0740-3194},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3366862/},
	doi = {10.1002/mrm.22924},
	number = {6},
	urldate = {2024-04-10},
	journal = {Magnetic Resonance in Medicine},
	author = {Tournier, Jacques-Donald and Mori, Susumu and Leemans, Alexander},
	month = jun,
	year = {2011},
	pmid = {21469191},
	pmcid = {PMC3366862},
	pages = {1532--1556},
	file = {PubMed Central Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/9RXW4U8T/Tournier et al. - 2011 - Diffusion Tensor Imaging and Beyond.pdf:application/pdf},
}

@incollection{dhollander_diffusion_2016,
	address = {New York, NY},
	title = {From {Diffusion} to the {Diffusion} {Tensor}},
	isbn = {978-1-4939-3118-7},
	url = {https://doi.org/10.1007/978-1-4939-3118-7_4},
	abstract = {The term “diffusion tensor imaging” (DTI) is used on many occasions to informally refer to anything related to diffusion-weighted imaging (DWI). From a formal point of view, however, DTI is the practice of fitting a tensor model to the DWI data. It is one of the simplest ways to model the DWI data that accounts, up to some extent, for the anisotropy in this kind of data. Exploiting this anisotropy is key to obtaining the characteristic directionally encoded color (DEC) maps and tractograms that are typically associated to the practice of DWI in general. Hence, it is not surprising many people use the term “DTI” in very different contexts. In this chapter, we aim to give the reader a feeling for what is really under the hood of the true art of DTI: obtaining these so-called diffusion tensors. What are they actually modeling? And, in this context, what is a tensor anyway? There’s a short and clear answer to this: the diffusion tensor describes the apparent diffusion coefficient (ADC), in function of direction. Hmm… “ADC” you say…?},
	language = {en},
	urldate = {2024-04-10},
	booktitle = {Diffusion {Tensor} {Imaging}: {A} {Practical} {Handbook}},
	publisher = {Springer},
	author = {Dhollander, Thijs},
	editor = {Van Hecke, Wim and Emsell, Louise and Sunaert, Stefan},
	year = {2016},
	doi = {10.1007/978-1-4939-3118-7_4},
	keywords = {Anisotropy, Apparent diffusion coefficient, Eigenvalues, Eigenvectors, Tensor fitting},
	pages = {37--63},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/RKQUQZES/Dhollander - 2016 - From Diffusion to the Diffusion Tensor.pdf:application/pdf},
}

@article{plewes_physics_2012,
	title = {Physics of {MRI}: {A} primer},
	volume = {35},
	issn = {1522-2586},
	shorttitle = {Physics of {MRI}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.23642},
	doi = {10.1002/jmri.23642},
	abstract = {This article is based on an introductory lecture given for the past many years during the “MR Physics and Techniques for Clinicians” course at the Annual Meeting of the ISMRM. This introduction is not intended to be a comprehensive overview of the field, as the subject of magnetic resonance imaging (MRI) physics is large and complex. Rather, it is intended to lay a conceptual foundation by which magnetic resonance image formation can be understood from an intuitive perspective. The presentation is nonmathematical, relying on simple models that take the reader progressively from the basic spin physics of nuclei, through descriptions of how the magnetic resonance signal is generated and detected in an MRI scanner, the foundations of nuclear magnetic resonance (NMR) relaxation, and a discussion of the Fourier transform and its relation to MR image formation. The article continues with a discussion of how magnetic field gradients are used to facilitate spatial encoding and concludes with a development of basic pulse sequences and the factors defining image contrast. J. Magn. Reson. Imaging 2012;35:1038-1054. © 2012 Wiley Periodicals, Inc.},
	language = {en},
	number = {5},
	urldate = {2024-04-10},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Plewes, Donald B. and Kucharczyk, Walter},
	year = {2012},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jmri.23642},
	keywords = {k-space, MRI image formation, MRI physics, NMR relaxation},
	pages = {1038--1054},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/U4BM5R8G/Plewes and Kucharczyk - 2012 - Physics of MRI A primer.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/DN6IQGX7/jmri.html:text/html},
}

@article{weigel_extended_2015,
	title = {Extended phase graphs: {Dephasing}, {RF} pulses, and echoes - pure and simple},
	volume = {41},
	copyright = {© 2014 Wiley Periodicals, Inc.},
	issn = {1522-2586},
	shorttitle = {Extended phase graphs},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.24619},
	doi = {10.1002/jmri.24619},
	abstract = {The extended phase graph (EPG) concept represents a powerful tool for depicting and understanding the magnetization response of a broad variety of MR sequences. EPGs focus on echo generation as well as on classification and use a Fourier based magnetization description in terms of “configurations states”. The effect of gradients, radiofrequency (RF) pulses, relaxation, and motion phenomena during the MR sequence is characterized as the action of a few matrix operations on these configuration states. Thus, the EPG method allows for fast and precise quantitation of echo intensities even if several gradients and RF pulses are applied. EPG diagrams aid in the comprehension of different types of echoes and their corresponding echo time. Despite its several benefits in regard to a large number of problems and issues, researchers and users still often refrain from applying EPGs. It seems that “phase graphing” is still seen as a kind of “magic.” The present review investigates the foundation of EPGs and sheds light on prerequisites for adding more advanced phenomena such as diffusion. The links between diagrams and calculations are discussed. A further focus is on limitations and simplifications as well recent extensions within the EPG concept. To make the review complete, representative software for EPG coding is provided. J. Magn. Reson. Imaging 2015;41:266–295.© 2013 Wiley Periodicals, Inc.},
	language = {en},
	number = {2},
	urldate = {2024-04-10},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Weigel, Matthias},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jmri.24619},
	keywords = {configuration states, dephasing, extended phase graph, Fourier space, partitioning, phase graph},
	pages = {266--295},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/P42N4AEI/Weigel - 2015 - Extended phase graphs Dephasing, RF pulses, and e.pdf:application/pdf},
}

@article{wang_image_2004,
	title = {Image quality assessment: from error visibility to structural similarity},
	volume = {13},
	issn = {1941-0042},
	shorttitle = {Image quality assessment},
	url = {https://ieeexplore.ieee.org/document/1284395},
	doi = {10.1109/TIP.2003.819861},
	abstract = {Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.},
	number = {4},
	urldate = {2024-04-10},
	journal = {IEEE Transactions on Image Processing},
	author = {Wang, Zhou and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
	month = apr,
	year = {2004},
	note = {Conference Name: IEEE Transactions on Image Processing},
	keywords = {Data mining, Degradation, Humans, Image quality, Indexes, Layout, Quality assessment, Transform coding, Visual perception, Visual system},
	pages = {600--612},
	file = {IEEE Xplore Abstract Record:/home/someusername/workspace/UNet-bSSFP/lit/storage/QRB4EXV2/1284395.html:text/html;IEEE Xplore Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/4IEYMWBE/Wang et al. - 2004 - Image quality assessment from error visibility to.pdf:application/pdf},
}

@book{rao_transform_2018,
	title = {The {Transform} and {Data} {Compression} {Handbook}},
	isbn = {978-1-4200-3738-8},
	abstract = {Data compression is one of the main contributing factors in the explosive growth in information technology. Without it, a number of consumer and commercial products, such as DVD, videophone, digital camera, MP3, video-streaming and wireless PCS, would have been virtually impossible. Transforming the data to a frequency or other domain enables even more efficient compression. By illustrating this intimate link, The Transform and Data Compression Handbook serves as a much-needed handbook for a wide range of researchers and engineers.The authors describe various discrete transforms and their applications in different disciplines. They cover techniques, such as adaptive quantization and entropy coding, that result in significant reduction in bit rates when applied to the transform coefficients. With clear and concise presentations of the ideas and concepts, as well as detailed descriptions of the algorithms, the authors provide important insight into the applications and their limitations. Data compression is an essential step towards the efficient storage and transmission of information. The Transform and Data Compression Handbook provides a wealth of information regarding different discrete transforms and demonstrates their power and practicality in data compression.},
	language = {en},
	publisher = {CRC Press},
	author = {Rao, Kamisetty Ramam and Yip, Patrick C.},
	month = oct,
	year = {2018},
	note = {Google-Books-ID: EgvOBQAAQBAJ},
	keywords = {Computers / Computer Science, Computers / Computer Engineering, Computers / General, Technology \& Engineering / Electrical, Technology \& Engineering / Environmental / General, Technology \& Engineering / Telecommunications, psnr},
	file = {Rao and Yip - 2018 - The Transform and Data Compression Handbook.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/9BJEL5YW/Rao and Yip - 2018 - The Transform and Data Compression Handbook.pdf:application/pdf},
}

@misc{zhang_unreasonable_2018,
	title = {The {Unreasonable} {Effectiveness} of {Deep} {Features} as a {Perceptual} {Metric}},
	url = {http://arxiv.org/abs/1801.03924},
	doi = {10.48550/arXiv.1801.03924},
	abstract = {While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on ImageNet classification has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called "perceptual losses"? What elements are critical for their success? To answer these questions, we introduce a new dataset of human perceptual similarity judgments. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by large margins on our dataset. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations.},
	urldate = {2024-04-10},
	publisher = {arXiv},
	author = {Zhang, Richard and Isola, Phillip and Efros, Alexei A. and Shechtman, Eli and Wang, Oliver},
	month = apr,
	year = {2018},
	note = {arXiv:1801.03924 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	annote = {Comment: Accepted to CVPR 2018; Code and data available at https://www.github.com/richzhang/PerceptualSimilarity},
	file = {arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/PXWT2YD5/Zhang et al. - 2018 - The Unreasonable Effectiveness of Deep Features as.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/9RA3SNIH/1801.html:text/html},
}

@misc{chen_med3d_2019,
	title = {{Med3D}: {Transfer} {Learning} for {3D} {Medical} {Image} {Analysis}},
	shorttitle = {{Med3D}},
	url = {http://arxiv.org/abs/1904.00625},
	doi = {10.48550/arXiv.1904.00625},
	abstract = {The performance on deep learning is significantly affected by volume of training data. Models pre-trained from massive dataset such as ImageNet become a powerful weapon for speeding up training convergence and improving accuracy. Similarly, models based on large dataset are important for the development of deep learning in 3D medical images. However, it is extremely challenging to build a sufficiently large dataset due to difficulty of data acquisition and annotation in 3D medical imaging. We aggregate the dataset from several medical challenges to build 3DSeg-8 dataset with diverse modalities, target organs, and pathologies. To extract general medical three-dimension (3D) features, we design a heterogeneous 3D network called Med3D to co-train multi-domain 3DSeg-8 so as to make a series of pre-trained models. We transfer Med3D pre-trained models to lung segmentation in LIDC dataset, pulmonary nodule classification in LIDC dataset and liver segmentation on LiTS challenge. Experiments show that the Med3D can accelerate the training convergence speed of target 3D medical tasks 2 times compared with model pre-trained on Kinetics dataset, and 10 times compared with training from scratch as well as improve accuracy ranging from 3\% to 20\%. Transferring our Med3D model on state-the-of-art DenseASPP segmentation network, in case of single model, we achieve 94.6{\textbackslash}\% Dice coefficient which approaches the result of top-ranged algorithms on the LiTS challenge.},
	urldate = {2024-04-10},
	publisher = {arXiv},
	author = {Chen, Sihong and Ma, Kai and Zheng, Yefeng},
	month = jul,
	year = {2019},
	note = {arXiv:1904.00625 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/EMLGABUP/Chen et al. - 2019 - Med3D Transfer Learning for 3D Medical Image Anal.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/48JUMZ59/1904.html:text/html},
}

@inproceedings{isola_image--image_2017,
	title = {Image-{To}-{Image} {Translation} {With} {Conditional} {Adversarial} {Networks}},
	url = {https://openaccess.thecvf.com/content_cvpr_2017/html/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.html},
	urldate = {2024-04-10},
	author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
	year = {2017},
	pages = {1125--1134},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/7NVTJX39/Isola et al. - 2017 - Image-To-Image Translation With Conditional Advers.pdf:application/pdf},
}

@article{bozinovski_reminder_2020,
	title = {Reminder of the {First} {Paper} on {Transfer} {Learning} in {Neural} {Networks}, 1976},
	volume = {44},
	copyright = {I assign to  Informatica ,  An International Journal of Computing and Informatics  ("Journal") the copyright in the manuscript identified above and any additional material (figures, tables, illustrations, software or other information intended for publication) submitted as part of or as a supplement to the manuscript ("Paper") in all forms and media throughout the world, in all languages, for the full term of copyright, effective when and if the article is accepted for publication. This transfer includes the right to reproduce and/or to distribute the Paper to other journals or digital libraries in electronic and online forms and systems.  I understand that I retain the rights to use the pre-prints, off-prints, accepted manuscript and published journal Paper for personal use, scholarly purposes and internal institutional use.  In certain cases, I can ask for retaining the publishing rights of the Paper. The Journal can permit or deny the request for publishing rights, to which I fully agree.  I declare that the submitted Paper is original, has been written by the stated authors and has not been published elsewhere nor is currently being considered for publication by any other journal and will not be submitted for such review while under review by this Journal.  The Paper contains no material that violates proprietary rights of any other person or entity. I have obtained written permission from copyright owners for any excerpts from copyrighted works that are included and have credited the sources in my article. I have informed the co-author(s) of the terms of this publishing agreement.           Copyright ©  Slovenian Society Informatika},
	issn = {1854-3871},
	url = {https://www.informatica.si/index.php/informatica/article/view/2828},
	doi = {10.31449/inf.v44i3.2828},
	abstract = {This paper describes a work on transfer learning in neural networks carried out in 1970s and early 1980s, which produced its first publication in 1976. In the contemporary research on transfer learning there is a belief that pioneering work on transfer learning took place in early 1990s, and this paper updates that knowledge, pointing out that the transfer learning research started more than a decade earlier. This paper reviews that 1970s research and addresses important issues relevant for the current transfer learning research. It gives a mathematical model and geometric interpretation of transfer learning, and  a measure of transfer learning indicating positive, negative, and no transfer learning. It presents experimental investigation in the mentioned types of transfer learning. And it gives an application of transfer learning in pattern recognition using datasets of images.},
	language = {en},
	number = {3},
	urldate = {2024-04-10},
	journal = {Informatica},
	author = {Bozinovski, Stevo},
	month = sep,
	year = {2020},
	note = {Number: 3},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/KSYBFYVH/Bozinovski - 2020 - Reminder of the First Paper on Transfer Learning i.pdf:application/pdf},
}

@misc{dale_fine-tuning_2024,
	title = {Fine-{Tuning} {Scheduler}},
	url = {https://zenodo.org/records/10780386},
	abstract = {A PyTorch Lightning extension that enhances model experimentation with flexible fine-tuning schedules.},
	urldate = {2024-04-10},
	publisher = {Zenodo},
	author = {Dale, Dan},
	month = mar,
	year = {2024},
	doi = {10.5281/zenodo.10780386},
	keywords = {artificial intelligence, deep learning, fine-tuning, finetuning, machine learning},
	file = {Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/9D7X47Y3/10780386.html:text/html},
}

@inproceedings{peters_tune_2019,
	address = {Florence, Italy},
	title = {To {Tune} or {Not} to {Tune}? {Adapting} {Pretrained} {Representations} to {Diverse} {Tasks}},
	shorttitle = {To {Tune} or {Not} to {Tune}?},
	url = {https://aclanthology.org/W19-4302},
	doi = {10.18653/v1/W19-4302},
	abstract = {While most previous work has focused on different pretraining objectives and architectures for transfer learning, we ask how to best adapt the pretrained model to a given target task. We focus on the two most common forms of adaptation, feature extraction (where the pretrained weights are frozen), and directly fine-tuning the pretrained model. Our empirical results across diverse NLP tasks with two state-of-the-art models show that the relative performance of fine-tuning vs. feature extraction depends on the similarity of the pretraining and target tasks. We explore possible explanations for this finding and provide a set of adaptation guidelines for the NLP practitioner.},
	urldate = {2024-04-10},
	booktitle = {Proceedings of the 4th {Workshop} on {Representation} {Learning} for {NLP} ({RepL4NLP}-2019)},
	publisher = {Association for Computational Linguistics},
	author = {Peters, Matthew E. and Ruder, Sebastian and Smith, Noah A.},
	editor = {Augenstein, Isabelle and Gella, Spandana and Ruder, Sebastian and Kann, Katharina and Can, Burcu and Welbl, Johannes and Conneau, Alexis and Ren, Xiang and Rei, Marek},
	month = aug,
	year = {2019},
	pages = {7--14},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/BWQ94T48/Peters et al. - 2019 - To Tune or Not to Tune Adapting Pretrained Repres.pdf:application/pdf},
}

@inproceedings{howard_universal_2018,
	address = {Melbourne, Australia},
	title = {Universal {Language} {Model} {Fine}-tuning for {Text} {Classification}},
	url = {https://aclanthology.org/P18-1031},
	doi = {10.18653/v1/P18-1031},
	abstract = {Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24\% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100 times more data. We open-source our pretrained models and code.},
	urldate = {2024-04-10},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Howard, Jeremy and Ruder, Sebastian},
	editor = {Gurevych, Iryna and Miyao, Yusuke},
	month = jul,
	year = {2018},
	pages = {328--339},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/4WU8IJDP/Howard and Ruder - 2018 - Universal Language Model Fine-tuning for Text Clas.pdf:application/pdf},
}

@inproceedings{chronopoulou_embarrassingly_2019,
	address = {Minneapolis, Minnesota},
	title = {An {Embarrassingly} {Simple} {Approach} for {Transfer} {Learning} from {Pretrained} {Language} {Models}},
	url = {https://aclanthology.org/N19-1213},
	doi = {10.18653/v1/N19-1213},
	abstract = {A growing number of state-of-the-art transfer learning methods employ language models pretrained on large generic corpora. In this paper we present a conceptually simple and effective transfer learning approach that addresses the problem of catastrophic forgetting. Specifically, we combine the task-specific optimization function with an auxiliary language model objective, which is adjusted during the training process. This preserves language regularities captured by language models, while enabling sufficient adaptation for solving the target task. Our method does not require pretraining or finetuning separate components of the network and we train our models end-to-end in a single step. We present results on a variety of challenging affective and text classification tasks, surpassing well established transfer learning methods with greater level of complexity.},
	urldate = {2024-04-10},
	booktitle = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} and {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Chronopoulou, Alexandra and Baziotis, Christos and Potamianos, Alexandros},
	editor = {Burstein, Jill and Doran, Christy and Solorio, Thamar},
	month = jun,
	year = {2019},
	pages = {2089--2095},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/4UEZKUMU/Chronopoulou et al. - 2019 - An Embarrassingly Simple Approach for Transfer Lea.pdf:application/pdf},
}

@misc{loshchilov_decoupled_2019,
	title = {Decoupled {Weight} {Decay} {Regularization}},
	url = {http://arxiv.org/abs/1711.05101},
	doi = {10.48550/arXiv.1711.05101},
	abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
	urldate = {2024-04-10},
	publisher = {arXiv},
	author = {Loshchilov, Ilya and Hutter, Frank},
	month = jan,
	year = {2019},
	note = {arXiv:1711.05101 [cs, math]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
	annote = {Comment: Published as a conference paper at ICLR 2019},
	file = {arXiv Fulltext PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/8M9AWAN6/Loshchilov and Hutter - 2019 - Decoupled Weight Decay Regularization.pdf:application/pdf;arXiv.org Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/H5Y7MTWT/1711.html:text/html},
}

@article{birk_high-resolution_2022,
	title = {High-resolution neural network-driven mapping of multiple diffusion metrics leveraging asymmetries in the balanced steady-state free precession frequency profile},
	volume = {35},
	copyright = {© 2021 The Authors. NMR in Biomedicine published by John Wiley \& Sons Ltd.},
	issn = {1099-1492},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nbm.4669},
	doi = {10.1002/nbm.4669},
	abstract = {We propose to utilize the rich information content about microstructural tissue properties entangled in asymmetric balanced steady-state free precession (bSSFP) profiles to estimate multiple diffusion metrics simultaneously by neural network (NN) parameter quantification. A 12-point bSSFP phase-cycling scheme with high-resolution whole-brain coverage is employed at 3 and 9.4 T for NN input. Low-resolution target diffusion data are derived based on diffusion-weighted spin-echo echo-planar-imaging (SE-EPI) scans, that is, mean, axial, and radial diffusivity (MD, AD, and RD), fractional anisotropy (FA), as well as the spherical coordinates (azimuth Φ and inclination ϴ) of the principal diffusion eigenvector. A feedforward NN is trained with incorporated probabilistic uncertainty estimation. The NN predictions yielded highly reliable results in white matter (WM) and gray matter structures for MD. The quantification of FA, AD, and RD was overall in good agreement with the reference but the dependence of these parameters on WM anisotropy was somewhat biased (e.g. in corpus callosum). The inclination ϴ was well predicted for anisotropic WM structures, while the azimuth Φ was overall poorly predicted. The findings were highly consistent across both field strengths. Application of the optimized NN to high-resolution input data provided whole-brain maps with rich structural details. In conclusion, the proposed NN-driven approach showed potential to provide distortion-free high-resolution whole-brain maps of multiple diffusion metrics at high to ultrahigh field strengths in clinically relevant scan times.},
	language = {en},
	number = {6},
	urldate = {2024-04-11},
	journal = {NMR in Biomedicine},
	author = {Birk, Florian and Glang, Felix and Loktyushin, Alexander and Birkl, Christoph and Ehses, Philipp and Scheffler, Klaus and Heule, Rahel},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/nbm.4669},
	keywords = {diffusion metrics, high resolution, multiparametric quantitative MRI, neural networks, phase-cycled bSSFP, probabilistic uncertainty estimation},
	pages = {e4669},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/IW6H3LBR/Birk et al. - 2022 - High-resolution neural network-driven mapping of m.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/8ILQ3RCE/nbm.html:text/html},
}

@book{lauterbur,
	title = {Principles of Magnetic Resonance Imaging},
	url = {https://cds.cern.ch/record/1480847/files/0780347234_TOC.pdf},
	urldate = {2024-04-17},
	publisher = {SPIE Optical Engineering Press Bellingham},
	author = {Liang, Zhi-Pei and Lauterbur, Paul C.},
	year = {2000},
	file = {Liang and Lauterbur - 2000 - Principles of magnetic resonance imaging.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/UNGLL97V/Liang and Lauterbur - 2000 - Principles of magnetic resonance imaging.pdf:application/pdf},
}

@book{bernstein_handbook_2004,
	title = {Handbook of {MRI} {Pulse} {Sequences}},
	isbn = {978-0-08-053312-4},
	abstract = {Magnetic Resonance Imaging (MRI) is among the most important medical imaging techniques available today. There is an installed base of approximately 15,000 MRI scanners worldwide. Each of these scanners is capable of running many different "pulse sequences", which are governed by physics and engineering principles, and implemented by software programs that control the MRI hardware. To utilize an MRI scanner to the fullest extent, a conceptual understanding of its pulse sequences is crucial. Handbook of MRI Pulse Sequences offers a complete guide that can help the scientists, engineers, clinicians, and technologists in the field of MRI understand and better employ their scanner. Explains pulse sequences, their components, and the associated image reconstruction methods commonly used in MRI Provides self-contained sections for individual techniques Can be used as a quick reference guide or as a resource for deeper study Includes both non-mathematical and mathematical descriptions Contains numerous figures, tables, references, and worked example problems},
	language = {en},
	publisher = {Elsevier},
	author = {Bernstein, Matt A. and King, Kevin F. and Zhou, Xiaohong Joe},
	month = sep,
	year = {2004},
	note = {Google-Books-ID: d6PLHcyejEIC},
	keywords = {Computers / Data Science / Bioinformatics, Mathematics / Applied, Medical / Diagnostic Imaging / General},
	file = {Bernstein et al. - 2004 - Handbook of MRI Pulse Sequences.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/4ZU5262P/Bernstein et al. - 2004 - Handbook of MRI Pulse Sequences.pdf:application/pdf},
}

@book{nishimura,
	title = {Principles of {Magnetic} {Resonance} {Imaging}},
	abstract = {This book presents the basic principles of magnetic resonance imaging (MRI), focusing on image formation, image content, and performance considerations. Emphasis is on the signal processing elements of MRI, particularly the Fourier transform relationships. Although developed as a teaching text for an electrical engineering course at Stanford University, the material should be accessible to those from other technical fields. The primary chapters (Chapters 1-7) cover the foundational material while the latter chapters (Chapters 8-11) provide brief overviews of extensions and selected topics.},
	language = {English},
	publisher = {Stanford Univ},
	author = {Nishimura, Dwight},
	month = feb,
	year = {2010},
	file = {Nishimura - 2010 - Principles of Magnetic Resonance Imaging.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/TF4RUKCE/Nishimura - 2010 - Principles of Magnetic Resonance Imaging.pdf:application/pdf},
}

@book{halliday,
	title = {Fundamentals of {Physics}},
	isbn = {978-1-118-23071-8},
	abstract = {The 10th edition of Halliday, Resnick and Walkers  Fundamentals of Physics provides the perfect solution for teaching a 2 or 3 semester calculus-based physics course, providing instructors with a tool by which they can teach students how to effectively read scientific material, identify fundamental concepts, reason through scientific questions, and solve quantitative problems. The 10th edition builds upon previous editions by offering new features designed to better engage students and support critical thinking. These include NEW Video Illustrations that bring the subject matter to life, NEW Vector Drawing Questions that test students conceptual understanding, and additional multimedia resources (videos and animations) that provide an alternative pathway through the material for those who struggle with reading scientific exposition.  WileyPLUS sold separately from text.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Halliday, David and Resnick, Robert and Walker, Jearl},
	month = aug,
	year = {2013},
	note = {Google-Books-ID: HybkAwAAQBAJ},
	keywords = {Science / Physics / General},
	file = {Halliday et al. - 2013 - Fundamentals of Physics.pdf:/home/someusername/workspace/UNet-bSSFP/lit/storage/9H5Y5TBF/Halliday et al. - 2013 - Fundamentals of Physics.pdf:application/pdf},
}


@incollection{relaxation,
	title = {Relaxation},
	isbn = {978-1-119-01306-8},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119013068.ch3},
	abstract = {The process by which the protons release the energy that they absorbed from the RF pulse is known as relaxation. Relaxation is a fundamental aspect of MR, as essential as energy absorption, and provides the primary mechanism for image contrast. In resonance absorption, RF energy is absorbed by the protons only when it is broadcast at the correct frequency. Following excitation, relaxation occurs in which the protons release this added energy and return to their original configuration through naturally occurring processes. Two relaxation times can be measured, known as T1 and T2. While both times measure the spontaneous energy transfer by an excited proton, they differ in the final disposition of the energy. The rate of RF pulse application and the efficiency of energy transfer must have the proper balance. Spin-lattice relaxation measures the rate of energy transfer from an excited proton to its surroundings.},
	language = {en},
	urldate = {2024-04-18},
	booktitle = {{MRI} {Basic} {Principles} and {Applications}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {{Brian M. Dale} and {Mark A. Brown} and {PhD,, Richard C. Semelka}},
	year = {2015},
	doi = {10.1002/9781119013068.ch3},
	note = {Section: 3
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119013068.ch3},
	keywords = {MR measurement, RF energy, spin–spin relaxation, T1 relaxation, T2 relaxation},
	pages = {17--25},
	file = {Full Text PDF:/home/someusername/workspace/UNet-bSSFP/lit/storage/8JWTZX3C/2015 - Relaxation.pdf:application/pdf;Snapshot:/home/someusername/workspace/UNet-bSSFP/lit/storage/KMAWZEQS/9781119013068.html:text/html},
}

