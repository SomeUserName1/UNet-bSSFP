\chapter{Discussion}\label{\positionnumber}
As we could see in the results, the predictions are estimates within a reasonable error margin.
At the same time the level of detail is not as good as in the ground truths.
Thus, different strategies are described to decrease model size such that more memory demanding data types can be used for the parameters, such that the processing corresponds more to the nature of data.
In this work the inputs have been treated like 3D images instead of a sequence of complex representations of bulk magnetizations.
Then strategies to adapt the model architectures are discussed to not only match the weights to the complex representation but the processing as a sequence as well --- instead of treating the sequence as channels in an image.

\section{Limitations}
The model described in the methods section has $51 = 5.1 \cdot 10^7$ milion trainable parameters.
\fig{img/parameter-counts.png}{params}{Comparison of the number of parameters of NN models across years.}{1}
This equals to approximately 14 GiB of VRAM on a GPU.
Several ways exist to shrink this rather large model to a smaller one.
The input size is of critical importance, as it co-defines the number of weights in the NN.
Smaller input dimensions result in a smaller amount of weights and thus trainable parameters.
Voxel-wise regression has been performed in~\autocite{birk_high-resolution_2022} with a rather small multi-layer perceptron architecture, with rather small relative errors, but some impreciseness in the overall structure of the predictions, e.g. in and around the ventricles.
In this work, the full volumes have been input to the NN with smaller errors but a lot more computational effort both in terms of calulcations neccessary for one update as well as training duration.
Those two approaches are extremes on a spectrum.
A common approach in deep learning for MRI is to feed the image patch-wise~\autocite{perez-garcia_torchio_2021}.
With this, the amount of structural information passed to the NN can be chosen by the user via the size of the patch as well as the amount of parameters to be trained. \\

Currently, the complex data is flattened into channels as well as the temporal dimension of the input.
Complex weights would allow the model to accept complex inputs a priori.
To take the temporal dimension into account directly --- rather than indirectly, computing maps from each time step in the contracting branch and merging them in the expanding branch --- either of 1D temporal convolutions, recurrent neural networks like LSTMs or vision transformers can be used~\autocite{sherstinsky_fundamentals_2020, kustner_cinenet_2020}.

Here we presented one instance of a neural network per modality.
This lacks the statistical power draw conclusions about which modality is best suitable to predict the diffusion tensor.
To make such a statement, the model needs to be trained with different initializations (as these are random) to make specific statements.
Further, the architecture was chosen based on experiments conducted by the author and common practices and can not be assumed to be the optimal architecture.
Approaches like neural architecture search provide means to infer architectures in a more structured and empirical manner~\autocite{white_neural_2023}. \\

A NN-based approach enables the predictions of the desired quantity from a given input, however, the resulting method is not easily interpretable and does not provide many insights on or an analytical formulation of the relationship between input and output.
Inital work on bSSFP and white matter tracts has been carried out by~\autocite{miller_asymmetries_2010ii, miller_asymmetries_2010i}. \\

The perceptual loss is used to capture high frequency components of the target, however this approach is limited.
It is able to catch some higher frequency components, but fails to caputure all of them.
A patch-based GAN loss as described in~\autocite{isola_image-image_2017} has shown to be suitable for this purpose, however it adds additional trainable parameter to the model and slows training considerably. \\

The data augmentation applied in this work was quite minimal.
Stronger data augmentation can help to increase robustness and generalization of the NN to unseen inputs further~\autocite{goodfellow_deep_2016}. \\

The masks used in this work and especially the probabilistic segementations generated by FSL for evaluation is of poor quality.
Svenja K. is currently regenerating these masks and probabilistic segementations using FreeSurfer improving the quality of the evaluation of the generated results.\\

\section{Future Work}
Besides the above mentioned limitations to be addressed, there are more starting points for future research.
Pretraining has demonstrated to improve the generation results~\autocite{wang_pretraining_2022}. \\

Regarding generative AI for visual modalities, Diffusion Models have shown stunning results, but are even more expensive computationally~\autocite{wang_pretraining_2022}.
An extension of this is the Latent Diffusion Model, which promises to provide both, the high quality generation of targets and reduced computationalcomplexity compared to diffusion models~\autocite{rombach_high-resolution_2022}.
Further, instead of using stable diffusion, flow matching --- a more efficient method using neural ordinary differential equations --- can be used to further increase efficiency of the more costly model~\autocite{tong_improving_2024}. \\

Instead of predicting the diffusion tensor, one option would be to predict the $T_2$-weighted images used for the estimation of the diffusion tensor or the scalars extracted from the diffusion tensor directly as done in~\autocite{birk_high-resolution_2022}. \\

Finally, instead of predicting a single modality from another single modality, a more basic model can be constructed, that is able to do translations from various to various modalities.
Strategies to achieve that can be found in~\autocite{ruder_overview_2017, pfeiffer_modular_2024}.
This would require a foundational model which is then finetuned to a variety of specifc generative tasks.
In the recent years, transformers that work on image data using convolutions have been proposed and may be a good architecture for the foundation model~\autocite{dosovitskiy_image_2021, hatamizadeh_swin_2022}.

\section{Conclusion}

\chapter{Acknowledgements}
Rahel, Flo, Qi, Klaus, josh, max,
